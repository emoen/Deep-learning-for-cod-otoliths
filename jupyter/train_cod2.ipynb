{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "672ee3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e96d70d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "devices:/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image, ExifTags\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import compute_class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "import scipy\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img, ImageDataGenerator\n",
    "from tensorflow.keras.layers import Activation, Dense, GlobalAveragePooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "\n",
    "\n",
    "#import wandb\n",
    "#from wandb.keras import WandbCallback\n",
    "\n",
    "#salmon-scales\n",
    "from train_util import read_images, load_xy, get_checkpoint_tensorboard, create_model_grayscale, get_fresh_weights, base_output, dense1_linear_output, train_validate_test_split\n",
    "\n",
    "print(\"devices:\"+str(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4e5c9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_output(model):\n",
    "    z = model.output\n",
    "    z = GlobalMaxPooling2D()(z)\n",
    "    return z\n",
    "\n",
    "def dense1_linear_output(gray_model):\n",
    "    z = base_output(gray_model)\n",
    "    z = Dense(1, activation='linear')(z)\n",
    "    return z\n",
    "\n",
    "def get_checkpoint_tensorboard(tensorboard_path, checkpoint_path):\n",
    "    \n",
    "    tensorboard = TensorBoard(log_dir=tensorboard_path)\n",
    "    checkpointer = ModelCheckpoint(\n",
    "        filepath = checkpoint_path,\n",
    "        verbose = 1,\n",
    "        save_best_only = True,\n",
    "        save_weights_only = False)\n",
    "    return tensorboard, checkpointer\n",
    "\n",
    "def train_validate_test_split(pairs, validation_set_size = 0.15, test_set_size = 0.15, a_seed = 8):\n",
    "    \"\"\" split pairs into 3 set, train-, validation-, and test-set\n",
    "        1 - (validation_set_size + test_set_size) = % training set size\n",
    "    >>> import pandas as pd\n",
    "    >>> import numpy as np\n",
    "    >>> data = np.array([np.arange(10)]*2).T  # 2 columns for x, y, and one for index\n",
    "    >>> df_ = pd.DataFrame(data, columns=['x', 'y'])\n",
    "    >>> train_x, val_x, test_x = \\\n",
    "             train_validate_test_split( df_, validation_set_size = 0.2, test_set_size = 0.2, a_seed = 1 )\n",
    "    >>> train_x['x'].values\n",
    "    array([0, 3, 1, 7, 8, 5])\n",
    "    >>> val_x['x'].values\n",
    "    array([4, 6])\n",
    "    >>> test_x['x'].values\n",
    "    array([2, 9])\n",
    "    \"\"\"\n",
    "    validation_and_test_set_size = validation_set_size + test_set_size\n",
    "    validation_and_test_split = validation_set_size / (test_set_size+validation_set_size)\n",
    "    df_train_x, df_notTrain_x = train_test_split(pairs, test_size = validation_and_test_set_size, random_state = a_seed)\n",
    "    df_test_x, df_val_x = train_test_split(df_notTrain_x, test_size = validation_and_test_split, random_state = a_seed)\n",
    "    return df_train_x, df_val_x, df_test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7b7a367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IMG_0160.JPG', 'IMG_0161.JPG', 'IMG_0159.JPG', 'IMG_0157.JPG', 'IMG_0162.JPG', 'IMG_0158.JPG']\n",
      "['2013', '2014', '2017', '2015', '2018', '2012', '2016']\n"
     ]
    }
   ],
   "source": [
    "a = os.listdir( '/gpfs/gpfs0/deep/data/Savannah_Professional_Practice2021_06_10_21/CodOtholiths-MachineLearning/Savannah_Professional_Practice/2013/70021/Nr09_age02' )\n",
    "b = os.listdir('/gpfs/gpfs0/deep/data/Savannah_Professional_Practice2021_06_10_21/CodOtholiths-MachineLearning/Savannah_Professional_Practice')\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "027883da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jpg_cods(B4_input_shape = (380, 380, 3), max_dataset_size = 5180, whichExposure='min'):\n",
    "    #    '''\n",
    "    #    reads one .jpg file in each folder in structure of folders\n",
    "    #    returns tensor with images, and 1-1 correspondence with age\n",
    "    #    '''\n",
    "\n",
    "    #max_dataset_size = 5156\n",
    "    #B4_input_shape = (380, 380, 3)\n",
    "    df_cod = pd.DataFrame(columns=['age', 'path', 'ExposureTime'])\n",
    "    image_tensor1 = np.empty(shape=(max_dataset_size,)+B4_input_shape)\n",
    "    image_tensor2 = np.empty(shape=(max_dataset_size,)+B4_input_shape)\n",
    "    image_tensor3 = np.empty(shape=(max_dataset_size,)+B4_input_shape)\n",
    "\n",
    "    base_dir = '/gpfs/gpfs0/deep/data/Savannah_Professional_Practice2021_06_10_21/CodOtholiths-MachineLearning/Savannah_Professional_Practice'\n",
    "    df_cod = pd.DataFrame(columns=['age', 'path', 'ExposureTime'])\n",
    "    base_dirs_posix = Path(base_dir)\n",
    "\n",
    "    error_count=0\n",
    "    add_count = 0\n",
    "    for some_year_dir in base_dirs_posix.iterdir():\n",
    "        count = 0\n",
    "        if not os.path.isdir( some_year_dir ) or \"Extra\" in str(some_year_dir):\n",
    "            continue\n",
    "\n",
    "        #dir structure: /year/station_number/cod_img_by_age/6 jpeg images of one fish\n",
    "        stat_nos = [name for name in os.listdir( some_year_dir ) if os.path.isdir(os.path.join(some_year_dir , name))]\n",
    "        for i in range(0, len(stat_nos)):\n",
    "            cod_path = os.path.join( some_year_dir, stat_nos[i] )\n",
    "            yr_station_codage_path = [os.path.join(cod_path , n) for n in os.listdir( cod_path ) \n",
    "                            if os.path.isdir(os.path.join(cod_path , n))]\n",
    "            cod_age = [n for n in os.listdir( cod_path ) \n",
    "                            if os.path.isdir(os.path.join(cod_path , n))]\n",
    "\n",
    "            assert len(yr_station_codage_path) == len(cod_age)\n",
    "            for j in range(0, len(yr_station_codage_path)):\n",
    "                #print(onlyfiles)\n",
    "                onlyfiles = [f for f in os.listdir( yr_station_codage_path[j] ) \n",
    "                             if os.path.isfile(os.path.join(yr_station_codage_path[j] , f))]\n",
    "\n",
    "                #2013/70028/Nr01_age05/Thumbs.db\n",
    "                #2016/70008/Nr01_age07/Thumbs.db\n",
    "                if len(onlyfiles) != 6: \n",
    "                    #print(str(len(onlyfiles)) + '\\t' + str( yr_station_codage_path[j] ) + \"\\t\" +'\\t'.join(map(str,onlyfiles)))\n",
    "                    error_count +=1\n",
    "                else: \n",
    "                    full_path = [os.path.join(yr_station_codage_path[j] , f) \n",
    "                             for f in os.listdir( yr_station_codage_path[j] ) \n",
    "                         if os.path.isfile(os.path.join(yr_station_codage_path[j] , f))]\n",
    "\n",
    "                    begin_age = cod_age[j].lower().find('age')\n",
    "                    #print(cod_age[j])\n",
    "                    age = cod_age[j][begin_age+3:begin_age+5]\n",
    "                    try:\n",
    "                        age = int(age)\n",
    "                    except ValueError:\n",
    "                        #print(yr_station_codage_path[j])\n",
    "                        #print(cod_age[j])\n",
    "                        #print(age)\n",
    "                        #print(begin_age)\n",
    "                        age = 0\n",
    "\n",
    "                    #print(age)\n",
    "\n",
    "                    full_path.sort()\n",
    "                    exposures_set = set()\n",
    "                    exposures_list = []\n",
    "                    for k in range(0, len(full_path)): #len(full_path) == 6\n",
    "                        img = Image.open(full_path[k])\n",
    "                        exif = {ExifTags.TAGS[k]: v for k, v in img._getexif().items() if k in ExifTags.TAGS}\n",
    "                        #print(exif['ExposureTime'])\n",
    "                        exposures_set.add( exif['ExposureTime'] )\n",
    "                        exposures_list.append( exif['ExposureTime'] )\n",
    "\n",
    "\n",
    "                    #if len(exposures_set) != 3:\n",
    "                        #print(\"\\t\"+str (yr_station_codage_path[j] ) + '\\t' + str(exposures_list) ) \n",
    "                    #    continue\n",
    "                    #else:\n",
    "                    if len(exposures_list) == 6 and len(exposures_set) == 3:\n",
    "\n",
    "                        expo_args = np.argsort(exposures_list).tolist()\n",
    "                        #print( \"exposures_list\"+str(exposures_list) )\n",
    "                        #print(\" argsort: \"+str(expo_args) )\n",
    "\n",
    "                        numpy_images = [0,0,0]\n",
    "                        file_paths = [0,0,0]\n",
    "                        imgs_added = 0\n",
    "                        \n",
    "                        #use if loading to memory\n",
    "                        \"\"\"\n",
    "                        for k in [0,2,4]:\n",
    "                            img = Image.open( full_path[ expo_args[k] ] ) \n",
    "                            pil_img = load_img(full_path[ expo_args[k] ], target_size=B4_input_shape, grayscale=False)\n",
    "                            array_img = img_to_array(pil_img, data_format='channels_last')\n",
    "\n",
    "                            numpy_images[imgs_added] = array_img\n",
    "                            file_paths[imgs_added] = full_path[ expo_args[k] ]\n",
    "                            imgs_added += 1\n",
    "                        \"\"\"\n",
    "                        \n",
    "\n",
    "                        if expo_args != [1, 4, 0, 3, 2, 5]:\n",
    "                            print( \"exposures_list\"+str(exposures_list) )\n",
    "                            print(\" argsort: \"+str(expo_args) )\n",
    "                            #print(file_paths)\n",
    "\n",
    "                        if whichExposure == 'min':\n",
    "                            #use if loading to memory\n",
    "                            pil_img = load_img(full_path[ expo_args[0] ], target_size=B4_input_shape, grayscale=False)\n",
    "                            array_img = img_to_array(pil_img, data_format='channels_last')\n",
    "                            image_tensor1[add_count] = array_img\n",
    "                            add_count += 1\n",
    "                            \n",
    "                            df_cod = df_cod.append({'age':age, 'path':full_path[expo_args[0]], 'light': 1, 'ExposureTime':exposures_list[expo_args[0]]}, ignore_index=True)\n",
    "                        if whichExposure == 'middle':\n",
    "                            #use if loading to memory\n",
    "                            pil_img = load_img(full_path[ expo_args[2] ], target_size=B4_input_shape, grayscale=False)\n",
    "                            array_img = img_to_array(pil_img, data_format='channels_last')\n",
    "                            image_tensor1[add_count] = array_img\n",
    "                            add_count += 1\n",
    "                            \n",
    "                            df_cod = df_cod.append({'age':age, 'path':full_path[expo_args[2]], 'light': 2, 'ExposureTime':exposures_list[expo_args[0]]}, ignore_index=True)\n",
    "                        if whichExposure == 'max':\n",
    "                            #use if loading to memory\n",
    "                            pil_img = load_img(full_path[ expo_args[4] ], target_size=B4_input_shape, grayscale=False)\n",
    "                            array_img = img_to_array(pil_img, data_format='channels_last')\n",
    "                            image_tensor1[add_count] = array_img\n",
    "                            add_count += 1\n",
    "                            \n",
    "                            df_cod = df_cod.append({'age':age, 'path':full_path[expo_args[4]], 'light': 3, 'ExposureTime':exposures_list[expo_args[0]]}, ignore_index=True)\n",
    "\n",
    "                                        \n",
    "\n",
    "    print(\"error_count:\"+str(error_count))\n",
    "\n",
    "    print(\"add_count:\"+str(add_count))\n",
    "\n",
    "    if whichExposure == 'min':\n",
    "        return image_tensor1, df_cod\n",
    "    if whichExposure == 'middle':\n",
    "        return image_tensor2, df_cod\n",
    "    if whichExposure == 'max':\n",
    "        return image_tensor3, df_cod\n",
    "\n",
    "    return None, None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01587f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exposures_list[0.4, 0.2, 0.1, 0.4, 0.2, 0.1]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.4, 0.2, 0.1, 0.4, 0.2, 0.1]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.4, 0.2, 0.1, 0.4, 0.2, 0.1]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.4, 0.2, 0.1, 0.4, 0.2, 0.1]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.4, 0.2, 0.1, 0.4, 0.2, 0.1]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.2, 0.1, 0.4, 0.1, 0.4, 0.2]\n",
      " argsort: [1, 3, 0, 5, 2, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.06666666666666667, 0.25, 0.125, 0.06666666666666667, 0.25, 0.125]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.3, 0.16666666666666666, 0.07692307692307693, 0.3, 0.16666666666666666, 0.07692307692307693]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.3, 0.16666666666666666, 0.07692307692307693, 0.3, 0.16666666666666666, 0.07692307692307693]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.16666666666666666, 0.6, 0.3, 0.16666666666666666, 0.6, 0.3]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.16666666666666666, 0.6, 0.3, 0.16666666666666666, 0.6, 0.3]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.16666666666666666, 0.6, 0.3, 0.16666666666666666, 0.6, 0.3]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.16666666666666666, 0.6, 0.3, 0.16666666666666666, 0.6, 0.3]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.6, 0.3, 0.16666666666666666, 0.6, 0.3, 0.16666666666666666]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.3, 0.16666666666666666, 0.07692307692307693, 0.3, 0.16666666666666666, 0.07692307692307693]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.3, 0.16666666666666666, 0.07692307692307693, 0.3, 0.16666666666666666, 0.07692307692307693]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.3, 0.16666666666666666, 0.07692307692307693, 0.3, 0.16666666666666666, 0.07692307692307693]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.3, 0.16666666666666666, 0.07692307692307693, 0.3, 0.16666666666666666, 0.07692307692307693]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.3, 0.16666666666666666, 0.07692307692307693, 0.3, 0.16666666666666666, 0.07692307692307693]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.3, 0.16666666666666666, 0.07692307692307693, 0.3, 0.16666666666666666, 0.07692307692307693]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.3, 0.16666666666666666, 0.07692307692307693, 0.3, 0.16666666666666666, 0.07692307692307693]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.3, 0.16666666666666666, 0.07692307692307693, 0.3, 0.16666666666666666, 0.07692307692307693]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.3, 0.16666666666666666, 0.07692307692307693, 0.3, 0.16666666666666666, 0.07692307692307693]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.3, 0.16666666666666666, 0.07692307692307693, 0.3, 0.16666666666666666, 0.07692307692307693]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.3, 0.16666666666666666, 0.07692307692307693, 0.3, 0.16666666666666666, 0.07692307692307693]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.3, 0.16666666666666666, 0.07692307692307693, 0.3, 0.16666666666666666, 0.07692307692307693]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.3, 0.16666666666666666, 0.07692307692307693, 0.3, 0.16666666666666666, 0.07692307692307693]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.3, 0.16666666666666666, 0.07692307692307693, 0.3, 0.16666666666666666, 0.07692307692307693]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exposures_list[0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.16666666666666666, 0.6, 0.3, 0.16666666666666666, 0.6, 0.3]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.16666666666666666, 0.6, 0.3, 0.16666666666666666, 0.6, 0.3]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.16666666666666666, 0.6, 0.3, 0.16666666666666666, 0.6, 0.3]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.16666666666666666, 0.6, 0.3, 0.16666666666666666, 0.6, 0.3]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.16666666666666666, 0.6, 0.3, 0.16666666666666666, 0.6, 0.3]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.06666666666666667, 0.03333333333333333, 0.016666666666666666, 0.06666666666666667, 0.03333333333333333, 0.016666666666666666]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "error_count:205\n",
      "add_count:5114\n"
     ]
    }
   ],
   "source": [
    "tensor, df = read_jpg_cods()\n",
    "#img_df = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "778630ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.,  1.,  1.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        ...,\n",
       "        [34., 29., 35.],\n",
       "        [38., 32., 36.],\n",
       "        [39., 34., 38.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        ...,\n",
       "        [32., 30., 33.],\n",
       "        [36., 31., 37.],\n",
       "        [38., 33., 37.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.],\n",
       "        [ 1.,  1.,  1.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        ...,\n",
       "        [31., 29., 32.],\n",
       "        [35., 30., 34.],\n",
       "        [37., 32., 36.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[36., 31., 37.],\n",
       "        [33., 30., 37.],\n",
       "        [33., 30., 37.],\n",
       "        ...,\n",
       "        [ 1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.],\n",
       "        [ 0.,  2.,  1.]],\n",
       "\n",
       "       [[33., 30., 37.],\n",
       "        [34., 31., 38.],\n",
       "        [32., 29., 36.],\n",
       "        ...,\n",
       "        [ 1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.]],\n",
       "\n",
       "       [[36., 31., 37.],\n",
       "        [36., 31., 38.],\n",
       "        [35., 32., 39.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 1.,  1.,  1.],\n",
       "        [ 0.,  2.,  1.]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[5113,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52567f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5114\n"
     ]
    }
   ],
   "source": [
    "#print(tensor[5113])\n",
    "tensor = tensor[0:5114]\n",
    "age = df.age\n",
    "image_tensor = tensor\n",
    "#age\n",
    "#tmp = np.asarray(age)\n",
    "#unique, counts = np.unique(tmp, return_counts=True)\n",
    "#print( dict(zip(unique, counts)) )\n",
    "print(len(age))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "591c0d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>path</th>\n",
       "      <th>ExposureTime</th>\n",
       "      <th>light</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>/gpfs/gpfs0/deep/data/Savannah_Professional_Pr...</td>\n",
       "      <td>0.00625</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>/gpfs/gpfs0/deep/data/Savannah_Professional_Pr...</td>\n",
       "      <td>0.00625</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>/gpfs/gpfs0/deep/data/Savannah_Professional_Pr...</td>\n",
       "      <td>0.00625</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>/gpfs/gpfs0/deep/data/Savannah_Professional_Pr...</td>\n",
       "      <td>0.00625</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>/gpfs/gpfs0/deep/data/Savannah_Professional_Pr...</td>\n",
       "      <td>0.00625</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  age                                               path ExposureTime  light\n",
       "0   2  /gpfs/gpfs0/deep/data/Savannah_Professional_Pr...      0.00625    1.0\n",
       "1   7  /gpfs/gpfs0/deep/data/Savannah_Professional_Pr...      0.00625    1.0\n",
       "2   5  /gpfs/gpfs0/deep/data/Savannah_Professional_Pr...      0.00625    1.0\n",
       "3   1  /gpfs/gpfs0/deep/data/Savannah_Professional_Pr...      0.00625    1.0\n",
       "4   8  /gpfs/gpfs0/deep/data/Savannah_Professional_Pr...      0.00625    1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fde8f7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loadImgToMem=True\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "tensorboard_path= './tensorboard_test3'\n",
    "checkpoint_path = './checkpoints_test3/cod_oto_efficientnetBBB.{epoch:03d}-{val_loss:.2f}.hdf5'\n",
    "a_batch_size = 16\n",
    "B4_input_shape = (380, 380, 3)\n",
    "B5_input_shape = (456, 456, 3)\n",
    "\n",
    "new_shape = B4_input_shape\n",
    "\n",
    "#new_shape = B5_input_shape\n",
    "#B4_input_shape = B5_input_shape\n",
    "\n",
    "#image_tensor, age = read_jpg_cods(B4_input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bf39aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_tensor[5178,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd367d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5114, 380, 380, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86db4410",
   "metadata": {},
   "source": [
    "### Model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ec7b3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_datagen = ImageDataGenerator(\n",
    "#    zca_whitening=False,\n",
    "#    width_shift_range=0.2,\n",
    "#    height_shift_range=0.2, #20,\n",
    "#    #zoom_range=[0.5,1.0],\n",
    "#    rotation_range=360,\n",
    "#    horizontal_flip=False,\n",
    "#    vertical_flip=True,\n",
    "#    rescale=1./255)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    zca_whitening=False,\n",
    "    width_shift_range=0.0,\n",
    "    height_shift_range=0.0,\n",
    "    rotation_range=0,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False) #,\n",
    "    #rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b56de633",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tensorflow 2.2 - wrap generator in tf.data.Dataset   \n",
    "def callGen():\n",
    "    return train_datagen.flow(train_rb_imgs, train_age, batch_size=a_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1cd23628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 380, 380, 3)]     0         \n",
      "_________________________________________________________________\n",
      "rescaling1 (Sequential)      (None, 380, 380, 3)       0         \n",
      "_________________________________________________________________\n",
      "img_augmentation (Sequential (None, 380, 380, 3)       0         \n",
      "_________________________________________________________________\n",
      "efficientnetb4 (Functional)  (None, 12, 12, 1792)      17673823  \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_1 (Glob (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 1793      \n",
      "=================================================================\n",
      "Total params: 17,675,616\n",
      "Trainable params: 17,550,409\n",
      "Non-trainable params: 125,207\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "learning_rate=0.00005\n",
    "learning_rate=0.006\n",
    "adam = optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "early_stopper = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, verbose=0,\n",
    "                                      mode='min',restore_best_weights=True)\n",
    "\n",
    "plateau = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, \n",
    "                                               verbose=0,mode='min')\n",
    "        \n",
    "def binary_accuracy_for_regression(y_true, y_pred):\n",
    "    return K.mean(K.equal(y_true, K.round(y_pred)), axis=-1)\n",
    "\n",
    "classWeight = None\n",
    "\n",
    "######## Define Model ######\n",
    "\"\"\"\n",
    "img_augmentation = Sequential([\n",
    "        layers.RandomRotation(factor=0.15),\n",
    "        layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
    "        layers.RandomFlip(),\n",
    "        layers.RandomContrast(factor=0.1),\n",
    "    ],\n",
    "    name=\"img_augmentation\",\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "rescaleLayer = tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.Rescaling(1./255)],\n",
    "  name=\"rescaling1\")\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "  layers.experimental.preprocessing.RandomRotation(factor=(-0.5, 0.5))],\n",
    "  name=\"img_augmentation\",\n",
    "  # possible width shift, height shift  \n",
    ")\n",
    "\n",
    "rgb_efficientNetB4 = tf.keras.applications.EfficientNetB4(\n",
    "    include_top=False, weights='imagenet', input_shape=B4_input_shape, classes=2)\n",
    "\n",
    "inputLayer = layers.Input( shape = B4_input_shape )\n",
    "x = rescaleLayer(inputLayer)\n",
    "x = data_augmentation(x)\n",
    "x = rgb_efficientNetB4(x)\n",
    "#z = rgb_efficientNetB4.output\n",
    "z = GlobalMaxPooling2D()(x)\n",
    "z = Dense(1, activation='linear')(z)\n",
    "\n",
    "cod = Model( inputs = inputLayer, outputs = z)\n",
    "print( cod.summary() )\n",
    "\n",
    "#z = rgb_efficientNetB4.output\n",
    "#z = GlobalMaxPooling2D()(z)\n",
    "#z = Dense(1, activation='linear')(z)\n",
    "#cod = Model( inputs = inputLayer, outputs = z)\n",
    "#print(cod.summary())\n",
    "\n",
    "cod.compile(loss='mse', optimizer=adam, metrics=['mse', binary_accuracy_for_regression] )\n",
    "tensorboard, checkpointer = get_checkpoint_tensorboard(tensorboard_path, checkpoint_path)\n",
    "K.set_value(cod.optimizer.learning_rate, 0.005)\n",
    "\n",
    "for layer in cod.layers:\n",
    "    layer.trainable = True\n",
    "############################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f473f42a",
   "metadata": {},
   "source": [
    "### KFold out-of-Fold split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2fbdd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3579, 380, 380, 3)\n"
     ]
    }
   ],
   "source": [
    "train_idx, val_idx, test_idx = train_validate_test_split( range(0, len(image_tensor)) )\n",
    "train_idx_oof = train_idx + val_idx #prepare - train+validation set for 5 KFold cv split\n",
    "val_idx = None\n",
    "\n",
    "#if train in memory\n",
    "train_rb_imgs = np.empty(shape=(len(train_idx),)+B4_input_shape)\n",
    "test_rb_imgs = np.empty(shape=(len(test_idx),)+B4_input_shape)\n",
    "train_age = []\n",
    "\n",
    "for i in range(0, len(train_idx)):\n",
    "    train_rb_imgs[i] = image_tensor[train_idx[i]]\n",
    "    train_age.append(age[train_idx[i]])\n",
    "\n",
    "test_age = []\n",
    "for i in range(0, len(test_idx)):\n",
    "    test_rb_imgs[i] = image_tensor[test_idx[i]]\n",
    "    test_age.append(age[test_idx[i]])    \n",
    "    \n",
    "test_rb_imgs = np.multiply(test_rb_imgs, 1./255)    \n",
    "print(train_rb_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9dda9ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-fold\n",
    "a_seed=2021\n",
    "kfold = KFold(n_splits = 5, random_state = a_seed, shuffle = True)\n",
    "\n",
    "#train_oof = image_tensor[train_idx_oof,:,:]\n",
    "#train_oof.shape\n",
    "\n",
    "#train_idx_oof = tr\n",
    "#train_img_tensor = \n",
    "#for fold, (trn_ind, val_ind) in enumerate(kfold.split(train)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1d652c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2863, 380, 380, 3)\n",
      "(716, 380, 380, 3)\n",
      "range train_age3577\n",
      "len train_age:3579\n",
      "len trn_ind:2863\n",
      "len val_ind:716\n",
      "len trn_ind + val_ind:3579\n",
      "<class 'numpy.ndarray'>\n",
      "[6 6 1 ... 3 2 6]\n",
      "(3579,)\n",
      "(2863, 380, 380, 3)\n",
      "<class 'numpy.ndarray'>\n",
      "[6 6 1 ... 3 2 6]\n",
      "(2863,)\n",
      "log_file_name:loss_log/loss_log_0.txt\n",
      "training the fold:0\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 809s 496ms/step - loss: 13.2250 - mse: 13.2240 - binary_accuracy_for_regression: 0.1253 - val_loss: 8.3203 - val_mse: 8.3203 - val_binary_accuracy_for_regression: 0.1187\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 787s 492ms/step - loss: 8.1383 - mse: 8.1379 - binary_accuracy_for_regression: 0.1299 - val_loss: 7.6280 - val_mse: 7.6280 - val_binary_accuracy_for_regression: 0.1648\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 788s 492ms/step - loss: 8.1243 - mse: 8.1244 - binary_accuracy_for_regression: 0.1262 - val_loss: 10.0930 - val_mse: 10.0930 - val_binary_accuracy_for_regression: 0.1117\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 789s 493ms/step - loss: 8.0750 - mse: 8.0753 - binary_accuracy_for_regression: 0.1273 - val_loss: 7.6290 - val_mse: 7.6290 - val_binary_accuracy_for_regression: 0.1648\n",
      "Epoch 5/1000\n",
      "1350/1600 [========================>.....] - ETA: 2:02 - loss: 8.0643 - mse: 8.0647 - binary_accuracy_for_regression: 0.1294"
     ]
    }
   ],
   "source": [
    "# 1. Start a new run\n",
    "#wandb.init(project=\"cod_oto_B4\")\n",
    "# 2. Save model inputs and hyperparameters\n",
    "#config = wandb.config\n",
    "#config.learning_rate = 0.00001\n",
    "\n",
    "the_fold = 0\n",
    "for fold, (trn_ind, val_ind) in enumerate(kfold.split(train_age)):\n",
    "    train_idx = trn_ind\n",
    "    val_idx = val_ind\n",
    "    \n",
    "    X_train, X_val = image_tensor[trn_ind,:,:,:], image_tensor[val_ind,:,:,:]\n",
    "    print(X_train.shape)\n",
    "    print(X_val.shape)\n",
    "    print(\"range train_age\"+str(max(trn_ind)))\n",
    "    print(\"len train_age:\"+str(len(train_age)))\n",
    "    print(\"len trn_ind:\"+str(len(trn_ind)))\n",
    "    print(\"len val_ind:\"+str(len(val_ind)))\n",
    "    print(\"len trn_ind + val_ind:\"+str(len(trn_ind)+len(val_ind)))\n",
    "    print(type(trn_ind))\n",
    "    new_train_age = np.array(train_age)\n",
    "    y_train = new_train_age[trn_ind]\n",
    "    print(y_train)\n",
    "    y_val = new_train_age[val_ind]\n",
    "    #y_train = y_train.tolist()\n",
    "    #y_val = y_val.tolist()\n",
    "    \n",
    "    print(new_train_age.shape)\n",
    "    print(X_train.shape)\n",
    "    print(type(y_train))\n",
    "    print(y_train)\n",
    "    print(y_train.shape)\n",
    "    \n",
    "    #use when imgs in memory\n",
    "    #Tensorflow 2.2 - wrap generator in tf.data.Dataset\n",
    "    def callGen():\n",
    "        return train_datagen.flow(X_train, y_train, batch_size=a_batch_size) #train_age\n",
    "\n",
    "    train_dataset = tf.data.Dataset.from_generator(callGen, \n",
    "                                   (tf.float32, tf.float32)).shuffle(\n",
    "                                        128, reshuffle_each_iteration=True).repeat()\n",
    "\n",
    "\n",
    "    log_file_name = 'loss_log/loss_log_'+str(the_fold)+'.txt'\n",
    "    print( \"log_file_name:\"+str(log_file_name) )\n",
    "    txt_log = open(log_file_name, mode='wt', buffering=1)\n",
    "\n",
    "    save_op_callback = LambdaCallback(\n",
    "      on_epoch_end = lambda epoch, logs: txt_log.write(\n",
    "        str( {'epoch': epoch, 'loss': logs['loss']} ) + '\\n'),\n",
    "      on_train_end = lambda logs: txt_log.close()\n",
    "    )\n",
    "\n",
    "    print(\"training the fold:\"+str(the_fold))\n",
    "    the_fold += 1\n",
    "    history_callback = cod.fit(train_dataset ,\n",
    "        steps_per_epoch=1600,\n",
    "        epochs=1000,\n",
    "        callbacks=[early_stopper, plateau, save_op_callback], #, tensorboard, checkpointer],WandbCallback()\n",
    "        #validation_data = val_dataset,\n",
    "        validation_data = (X_val, y_val), #val_age\n",
    "        class_weight=classWeight,\n",
    "        workers=4,\n",
    "        verbose=1,\n",
    "        use_multiprocessing=True)\n",
    "\n",
    "    #test_metrics = cod.evaluate_generator(test_rb_imgs)\n",
    "    test_metrics = cod.evaluate(x=test_rb_imgs, y=test_age)\n",
    "    print(\"test metric:\"+str(cod.metrics_names))\n",
    "    print(\"test metrics:\"+str(test_metrics))\n",
    "\n",
    "    print(\"precision, recall, f1\")\n",
    "    y_pred_test = cod.predict(test_rb_imgs, verbose=1)\n",
    "    y_pred_test_bool = np.argmax(y_pred_test, axis=1)\n",
    "    y_true_bool = np.argmax(test_age, axis=1)\n",
    "    #np.argmax inverse of to_categorical\n",
    "    argmax_test = np.argmax(test_age, axis=1)\n",
    "    unique, counts = np.unique(argmax_test, return_counts=True)\n",
    "    print(\"test ocurrence of each class:\"+str(dict(zip(unique, counts))))\n",
    "\n",
    "    print(\"cslassification_report\")\n",
    "    print(classification_report(y_true_bool, y_pred_test_bool))\n",
    "    print(\"confusion matrix\")\n",
    "    print(str(confusion_matrix(y_true_bool, y_pred_test_bool)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "edc9e37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 11, 1: 380, 2: 509, 3: 504, 4: 617, 5: 795, 6: 532, 7: 544, 8: 476, 9: 319, 10: 214, 11: 120, 12: 54, 13: 26, 14: 7, 15: 4, 16: 1, 17: 1}\n",
      "{0: 6, 1: 246, 2: 351, 3: 336, 4: 442, 5: 542, 6: 395, 7: 372, 8: 341, 9: 226, 10: 164, 11: 86, 12: 44, 13: 19, 14: 5, 15: 3, 16: 1}\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(age, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "unique, counts = np.unique(train_age, return_counts=True)\n",
    "print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed052be",
   "metadata": {},
   "outputs": [],
   "source": [
    "    ############## salmon_scales\n",
    "    ''\n",
    "    new_shape = (380, 380, 3)\n",
    "    age_cod = age\n",
    "    rb_imgs, all_sea_age, all_smolt_age, all_farmed_class, all_spawn_class, all_filenames = load_xy()\n",
    "    uten_ukjent = len(all_sea_age) - all_sea_age.count(-1.0)\n",
    "    rb_imgs2 = np.empty(shape=(uten_ukjent,)+new_shape)\n",
    "    unique, counts = np.unique(all_sea_age, return_counts=True)\n",
    "    print(\"age distrib:\"+str( dict(zip(unique, counts)) ))\n",
    "\n",
    "    all_sea_age2 = []\n",
    "    found_count = 0\n",
    "    all_filenames2 = []\n",
    "    for i in range(0, len(all_sea_age)):\n",
    "        if all_sea_age[i] > -1:\n",
    "            rb_imgs2[found_count] = rb_imgs[i]\n",
    "            all_sea_age2.append(all_sea_age[i])\n",
    "            found_count += 1\n",
    "            all_filenames2.append(all_filenames[i])\n",
    "\n",
    "    assert found_count == uten_ukjent\n",
    "\n",
    "    age_scales = all_sea_age2\n",
    "    rb_imgs = rb_imgs2\n",
    "\n",
    "    age_scales = np.vstack(age_scales)\n",
    "\n",
    "    train_datagen_scales = ImageDataGenerator(\n",
    "        zca_whitening=False,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2, #20,\n",
    "        #zoom_range=[0.5,1.0],\n",
    "        rotation_range=360,\n",
    "        horizontal_flip=False,\n",
    "        vertical_flip=True,\n",
    "        rescale=1./255)\n",
    "\n",
    "    train_generator_scales = train_datagen_scales.flow(rb_imgs, age_scales, batch_size= a_batch_size)\n",
    "    history_callback_scales = cod.fit(train_generator_scales,\n",
    "        steps_per_epoch=1000,\n",
    "        epochs=20,\n",
    "        #callbacks=[early_stopper, tensorboard, checkpointer],\n",
    "        #validation_data= (val_rb_imgs, val_age),\n",
    "        class_weight=classWeight)\n",
    "    ######################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e68d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    K.set_value(cod.optimizer.learning_rate, 0.00001)\n",
    "    print(\"Learning rate before second fit:\", cod.optimizer.learning_rate.numpy())\n",
    "\n",
    "    history_callback = cod.fit(train_dataset ,\n",
    "        steps_per_epoch=1600,\n",
    "        epochs=150,\n",
    "        callbacks=[early_stopper, tensorboard, checkpointer],\n",
    "        #validation_data = val_dataset,\n",
    "        validation_data = (val_rb_imgs, val_age),\n",
    "        class_weight=classWeight)\n",
    "\n",
    "    #test_metrics = cod.evaluate_generator(test_dataset)\n",
    "    test_metrics = cod.evaluate(x=test_rb_imgs, y=test_age)\n",
    "    print(\"test metric:\"+str(cod.metrics_names))\n",
    "    print(\"test metrics:\"+str(test_metrics))\n",
    "\n",
    "    print(\"precision, recall, f1\")\n",
    "    y_pred_test = cod.predict(test_rb_imgs, verbose=1)\n",
    "    y_pred_test_bool = np.argmax(y_pred_test, axis=1)\n",
    "    y_true_bool = np.argmax(test_age, axis=1)\n",
    "    #np.argmax inverse of to_categorical\n",
    "    argmax_test = np.argmax(test_age, axis=1)\n",
    "    unique, counts = np.unique(argmax_test, return_counts=True)\n",
    "    print(\"test ocurrence of each class:\"+str(dict(zip(unique, counts))))\n",
    "\n",
    "    print(\"cslassification_report\")\n",
    "    print(classification_report(y_true_bool, y_pred_test_bool))\n",
    "    print(\"confusion matrix\")\n",
    "    print(str(confusion_matrix(y_true_bool, y_pred_test_bool)))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
