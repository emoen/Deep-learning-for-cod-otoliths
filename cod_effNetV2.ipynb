{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8ec969d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image, ExifTags\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import compute_class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "import scipy\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img, ImageDataGenerator\n",
    "from tensorflow.keras.layers import Activation, Dense, GlobalAveragePooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "\n",
    "#salmon-scales\n",
    "#from train_util import read_images, load_xy, get_checkpoint_tensorboard, create_model_grayscale, get_fresh_weights, base_output, dense1_linear_output, train_validate_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aaf8bc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting colorama\n",
      "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
      "Installing collected packages: colorama\n",
      "Successfully installed colorama-0.4.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!pip install plotly\n",
    "#!pip install torch\n",
    "#!pip install loguru\n",
    "#!pip install timm #PyTorch Image Models\n",
    "#!pip install albumentations #augmentation\n",
    "#!pip install colorama #color terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3ec8a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import amp\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import timm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from colorama import Fore\n",
    "b_ = Fore.BLUE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559189a4",
   "metadata": {},
   "source": [
    "### Train Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be13b22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONFIG:\n",
    "    seed = 42\n",
    "    model_name = 'tf_efficientnetv2_s_in21k' \n",
    "    train_batch_size = 32\n",
    "    valid_batch_size = 64\n",
    "    img_size = 512\n",
    "    epochs = 5\n",
    "    learning_rate = 1e-4\n",
    "    min_lr = 1e-6\n",
    "    weight_decay = 1e-6\n",
    "    T_max = 10\n",
    "    scheduler = 'CosineAnnealingLR'\n",
    "    n_accumulate = 1\n",
    "    n_fold = 5\n",
    "    target_size = 1\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "def set_seed(seed = 42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "set_seed(CONFIG.seed)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341e0252",
   "metadata": {},
   "source": [
    "### Cod Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "25dbe707",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-effv2-weights/tf_efficientnetv2_s_21k-6337ad01.pth\" to /root/.cache/torch/hub/checkpoints/tf_efficientnetv2_s_21k-6337ad01.pth\n",
      "/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py:143: UserWarning:\n",
      "\n",
      "\n",
      "RTX A6000 with CUDA capability sm_86 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n",
      "If you want to use the RTX A6000 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class codModel(nn.Module):\n",
    "    def __init__(self, model_name, pretrained=True):\n",
    "        super(codModel, self).__init__()\n",
    "        ## not 3 channels: https://fastai.github.io/timmdocs/models\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=3)\n",
    "        self.n_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Linear(self.n_features, CONFIG.target_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.model(x)\n",
    "        return output\n",
    "    \n",
    "model = codModel(CONFIG.model_name)\n",
    "model.to(CONFIG.device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afdf314",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8ee837d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "69e05a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jpg_cods2(B4_input_shape = (380, 380, 3), max_dataset_size = 5180, whichExposure='min'):\n",
    "    #    '''\n",
    "    #    reads one .jpg file in each folder in structure of folders\n",
    "    #    returns tensor with images, and 1-1 correspondence with age\n",
    "    #    '''\n",
    "\n",
    "    #max_dataset_size = 5156\n",
    "    #B4_input_shape = (380, 380, 3)\n",
    "    df_cod = pd.DataFrame(columns=['age', 'path', 'ExposureTime'])\n",
    "    image_tensor1 = np.empty(shape=(max_dataset_size,)+B4_input_shape)\n",
    "    image_tensor2 = np.empty(shape=(max_dataset_size,)+B4_input_shape)\n",
    "    image_tensor3 = np.empty(shape=(max_dataset_size,)+B4_input_shape)\n",
    "\n",
    "    base_dir = '/gpfs/gpfs0/deep/data/Savannah_Professional_Practice2021_06_10_21/CodOtholiths-MachineLearning/Savannah_Professional_Practice'\n",
    "    df_cod = pd.DataFrame(columns=['age', 'path', 'ExposureTime'])\n",
    "    base_dirs_posix = Path(base_dir)\n",
    "\n",
    "    error_count=0\n",
    "    add_count = 0\n",
    "    for some_year_dir in base_dirs_posix.iterdir():\n",
    "        count = 0\n",
    "        ## terminate quickly for testing\n",
    "        if count > 0: \n",
    "            break\n",
    "\n",
    "        if not os.path.isdir( some_year_dir ) or \"Extra\" in str(some_year_dir):\n",
    "            continue\n",
    "\n",
    "        #dir structure: /year/station_number/cod_img_by_age/6 jpeg images of one fish\n",
    "        stat_nos = [name for name in os.listdir( some_year_dir ) if os.path.isdir(os.path.join(some_year_dir , name))]\n",
    "        for i in range(0, len(stat_nos)):\n",
    "            cod_path = os.path.join( some_year_dir, stat_nos[i] )\n",
    "            yr_station_codage_path = [os.path.join(cod_path , n) for n in os.listdir( cod_path ) \n",
    "                            if os.path.isdir(os.path.join(cod_path , n))]\n",
    "            cod_age = [n for n in os.listdir( cod_path ) \n",
    "                            if os.path.isdir(os.path.join(cod_path , n))]\n",
    "\n",
    "            assert len(yr_station_codage_path) == len(cod_age)\n",
    "            for j in range(0, len(yr_station_codage_path)):\n",
    "                #print(onlyfiles)\n",
    "                onlyfiles = [f for f in os.listdir( yr_station_codage_path[j] ) \n",
    "                             if os.path.isfile(os.path.join(yr_station_codage_path[j] , f))]\n",
    "\n",
    "                #2013/70028/Nr01_age05/Thumbs.db\n",
    "                #2016/70008/Nr01_age07/Thumbs.db\n",
    "                if len(onlyfiles) != 6: \n",
    "                    #print(str(len(onlyfiles)) + '\\t' + str( yr_station_codage_path[j] ) + \"\\t\" +'\\t'.join(map(str,onlyfiles)))\n",
    "                    error_count +=1\n",
    "                else: \n",
    "                    full_path = [os.path.join(yr_station_codage_path[j] , f) \n",
    "                             for f in os.listdir( yr_station_codage_path[j] ) \n",
    "                         if os.path.isfile(os.path.join(yr_station_codage_path[j] , f))]\n",
    "\n",
    "                    begin_age = cod_age[j].lower().find('age')\n",
    "                    #print(cod_age[j])\n",
    "                    age = cod_age[j][begin_age+3:begin_age+5]\n",
    "                    try:\n",
    "                        age = int(age)\n",
    "                    except ValueError:\n",
    "                        #print(yr_station_codage_path[j])\n",
    "                        #print(cod_age[j])\n",
    "                        #print(age)\n",
    "                        #print(begin_age)\n",
    "                        age = 0\n",
    "                        continue\n",
    "\n",
    "                    #print(age)\n",
    "\n",
    "                    full_path.sort()\n",
    "                    exposures_set = set()\n",
    "                    exposures_list = []\n",
    "                    for k in range(0, len(full_path)): #len(full_path) == 6\n",
    "                        img = Image.open(full_path[k])\n",
    "                        exif = {ExifTags.TAGS[k]: v for k, v in img._getexif().items() if k in ExifTags.TAGS}\n",
    "                        #print(exif['ExposureTime'])\n",
    "                        exposures_set.add( exif['ExposureTime'] )\n",
    "                        exposures_list.append( exif['ExposureTime'] )\n",
    "\n",
    "\n",
    "                    #if len(exposures_set) != 3:\n",
    "                        #print(\"\\t\"+str (yr_station_codage_path[j] ) + '\\t' + str(exposures_list) ) \n",
    "                    #    continue\n",
    "                    #else:\n",
    "                    if len(exposures_list) == 6 and len(exposures_set) == 3:\n",
    "\n",
    "                        expo_args = np.argsort(exposures_list).tolist()\n",
    "                        #print( \"exposures_list\"+str(exposures_list) )\n",
    "                        #print(\" argsort: \"+str(expo_args) )\n",
    "\n",
    "                        numpy_images = [0,0,0]\n",
    "                        file_paths = [0,0,0]\n",
    "                        imgs_added = 0\n",
    "                        \n",
    "                        #use if loading to memory\n",
    "                        \"\"\"\n",
    "                        for k in [0,2,4]:\n",
    "                            img = Image.open( full_path[ expo_args[k] ] ) \n",
    "                            pil_img = load_img(full_path[ expo_args[k] ], target_size=B4_input_shape, grayscale=False)\n",
    "                            array_img = img_to_array(pil_img, data_format='channels_last')\n",
    "\n",
    "                            numpy_images[imgs_added] = array_img\n",
    "                            file_paths[imgs_added] = full_path[ expo_args[k] ]\n",
    "                            imgs_added += 1\n",
    "                        \"\"\"\n",
    "                        \n",
    "\n",
    "                        if expo_args != [1, 4, 0, 3, 2, 5]:\n",
    "                            print( \"exposures_list\"+str(exposures_list) )\n",
    "                            print(\" argsort: \"+str(expo_args) )\n",
    "                            #print(file_paths)\n",
    "\n",
    "                        if whichExposure == 'min':\n",
    "                            #use if loading to memory\n",
    "                            ##pil_img = load_img(full_path[ expo_args[0] ], target_size=B4_input_shape, grayscale=False)\n",
    "                            ##array_img = img_to_array(pil_img, data_format='channels_last')\n",
    "                            ##image_tensor1[add_count] = array_img\n",
    "                            add_count += 1\n",
    "                            \n",
    "                            df_cod = df_cod.append({'age':age, 'path':full_path[expo_args[0]], 'light': 1, 'ExposureTime':exposures_list[expo_args[0]]}, ignore_index=True)\n",
    "                        if whichExposure == 'middle':\n",
    "                            #use if loading to memory\n",
    "                            ##pil_img = load_img(full_path[ expo_args[2] ], target_size=B4_input_shape, grayscale=False)\n",
    "                            ##array_img = img_to_array(pil_img, data_format='channels_last')\n",
    "                            ##image_tensor1[add_count] = array_img\n",
    "                            add_count += 1\n",
    "                            \n",
    "                            df_cod = df_cod.append({'age':age, 'path':full_path[expo_args[2]], 'light': 2, 'ExposureTime':exposures_list[expo_args[0]]}, ignore_index=True)\n",
    "                        if whichExposure == 'max':\n",
    "                            #use if loading to memory\n",
    "                            ##pil_img = load_img(full_path[ expo_args[4] ], target_size=B4_input_shape, grayscale=False)\n",
    "                            ##array_img = img_to_array(pil_img, data_format='channels_last')\n",
    "                            ##image_tensor1[add_count] = array_img\n",
    "                            add_count += 1\n",
    "                            \n",
    "                            df_cod = df_cod.append({'age':age, 'path':full_path[expo_args[4]], 'light': 3, 'ExposureTime':exposures_list[expo_args[0]]}, ignore_index=True)\n",
    "\n",
    "                                        \n",
    "\n",
    "    print(\"error_count:\"+str(error_count))\n",
    "    print(\"add_count:\"+str(add_count))\n",
    "\n",
    "    '''\n",
    "    if whichExposure == 'min':\n",
    "        return image_tensor1, df_cod.age        \n",
    "    if whichExposure == 'middle':\n",
    "        return image_tensor2, df_cod.age\n",
    "    if whichExposure == 'max':\n",
    "        return image_tensor3, df_cod.age\n",
    "    '''    \n",
    "    return df_cod\n",
    "    #return None, None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6af06b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(380, 380, 3)\n",
      "(380, 380, 3)\n",
      "(380, 380, 3)\n",
      "(380, 380, 3)\n",
      "tensor(2.)\n"
     ]
    }
   ],
   "source": [
    "pil_img = load_img(df.path[0], target_size=B4_input_shape, grayscale=False)\n",
    "array_img = img_to_array(pil_img, data_format='channels_last')\n",
    "image = array_img\n",
    "\n",
    "#image = np.load(df.path[0],allow_pickle=True).astype(np.float32)\n",
    "print(image.shape)\n",
    "image = (image - image.mean(axis=(1,2), keepdims=True)) / image.std(axis=(1,2), keepdims=True)\n",
    "print(image.shape)\n",
    "#image = np.vstack(image).transpose((1, 0))\n",
    "print(image.shape)\n",
    "label = torch.tensor(df.age[0]).float()\n",
    "print(image.shape) #(3, 144400)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8ceb841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class codDataset(Dataset):\n",
    "    def __init__(self, df, transforms=None):\n",
    "        self.df = df\n",
    "        self.file_names = df['path'].values\n",
    "        self.labels = df['age'].values\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        print(\"loading filename:\"+str(self.file_names[index]))\n",
    "        #image = np.load(self.file_names[index]).astype(np.float32)\n",
    "        B4_input_shape = (380, 380, 3)\n",
    "        pil_img = load_img(df.path[0], target_size=B4_input_shape, grayscale=False)\n",
    "        image = img_to_array(pil_img, data_format='channels_last')\n",
    "        \n",
    "        image = (image - image.mean(axis=(1,2), keepdims=True)) / image.std(axis=(1,2), keepdims=True)\n",
    "        #image = np.vstack(image).transpose((1, 0))\n",
    "        label = torch.tensor(self.labels[index]).float()\n",
    "        \n",
    "        if self.transforms:\n",
    "            image = self.transforms(image=image)[\"image\"]\n",
    "            \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "25b5bdcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exposures_list[0.4, 0.2, 0.1, 0.4, 0.2, 0.1]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.4, 0.2, 0.1, 0.4, 0.2, 0.1]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.4, 0.2, 0.1, 0.4, 0.2, 0.1]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.4, 0.2, 0.1, 0.4, 0.2, 0.1]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.4, 0.2, 0.1, 0.4, 0.2, 0.1]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.2, 0.1, 0.4, 0.1, 0.4, 0.2]\n",
      " argsort: [1, 3, 0, 5, 2, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.1, 0.4, 0.2, 0.1, 0.4, 0.2]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.06666666666666667, 0.25, 0.125, 0.06666666666666667, 0.25, 0.125]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.3, 0.16666666666666666, 0.07692307692307693, 0.3, 0.16666666666666666, 0.07692307692307693]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.3, 0.16666666666666666, 0.07692307692307693, 0.3, 0.16666666666666666, 0.07692307692307693]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.16666666666666666, 0.6, 0.3, 0.16666666666666666, 0.6, 0.3]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.16666666666666666, 0.6, 0.3, 0.16666666666666666, 0.6, 0.3]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.16666666666666666, 0.6, 0.3, 0.16666666666666666, 0.6, 0.3]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.16666666666666666, 0.6, 0.3, 0.16666666666666666, 0.6, 0.3]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.6, 0.3, 0.16666666666666666, 0.6, 0.3, 0.16666666666666666]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.3, 0.16666666666666666, 0.07692307692307693, 0.3, 0.16666666666666666, 0.07692307692307693]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.3, 0.16666666666666666, 0.07692307692307693, 0.3, 0.16666666666666666, 0.07692307692307693]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.3, 0.16666666666666666, 0.07692307692307693, 0.3, 0.16666666666666666, 0.07692307692307693]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.3, 0.16666666666666666, 0.07692307692307693, 0.3, 0.16666666666666666, 0.07692307692307693]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.3, 0.16666666666666666, 0.07692307692307693, 0.3, 0.16666666666666666, 0.07692307692307693]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.3, 0.16666666666666666, 0.07692307692307693, 0.3, 0.16666666666666666, 0.07692307692307693]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.3, 0.16666666666666666, 0.07692307692307693, 0.3, 0.16666666666666666, 0.07692307692307693]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.3, 0.16666666666666666, 0.07692307692307693, 0.3, 0.16666666666666666, 0.07692307692307693]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.3, 0.16666666666666666, 0.07692307692307693, 0.3, 0.16666666666666666, 0.07692307692307693]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.3, 0.16666666666666666, 0.07692307692307693, 0.3, 0.16666666666666666, 0.07692307692307693]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.3, 0.16666666666666666, 0.07692307692307693, 0.3, 0.16666666666666666, 0.07692307692307693]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.3, 0.16666666666666666, 0.07692307692307693, 0.3, 0.16666666666666666, 0.07692307692307693]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.3, 0.16666666666666666, 0.07692307692307693, 0.3, 0.16666666666666666, 0.07692307692307693]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.3, 0.16666666666666666, 0.07692307692307693, 0.3, 0.16666666666666666, 0.07692307692307693]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exposures_list[0.16666666666666666, 0.6, 0.3, 0.16666666666666666, 0.6, 0.3]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.16666666666666666, 0.6, 0.3, 0.16666666666666666, 0.6, 0.3]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.16666666666666666, 0.6, 0.3, 0.16666666666666666, 0.6, 0.3]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.16666666666666666, 0.6, 0.3, 0.16666666666666666, 0.6, 0.3]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.16666666666666666, 0.6, 0.3, 0.16666666666666666, 0.6, 0.3]\n",
      " argsort: [0, 3, 2, 5, 1, 4]\n",
      "exposures_list[0.06666666666666667, 0.03333333333333333, 0.016666666666666666, 0.06666666666666667, 0.03333333333333333, 0.016666666666666666]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "exposures_list[0.125, 0.06666666666666667, 0.03333333333333333, 0.125, 0.06666666666666667, 0.03333333333333333]\n",
      " argsort: [2, 5, 1, 4, 0, 3]\n",
      "error_count:205\n",
      "add_count:5110\n",
      "len age:5110\n"
     ]
    }
   ],
   "source": [
    "B4_input_shape = (380, 380, 3)\n",
    "B5_input_shape = (456, 456, 3)\n",
    "\n",
    "df = read_jpg_cods2(B4_input_shape, max_dataset_size = 9180) #5316 #5110\n",
    "\n",
    "print(\"len age:\"+str( len(df.age) ) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96789f86",
   "metadata": {},
   "source": [
    "### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a6bbfa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/albumentations/augmentations/transforms.py:691: FutureWarning:\n",
      "\n",
      "This class has been deprecated. Please use CoarseDropout\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_transforms = {\n",
    "    \"train\": A.Compose([\n",
    "        A.Resize(CONFIG.img_size, CONFIG.img_size),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.ShiftScaleRotate(shift_limit=0.1, \n",
    "                           scale_limit=0.15, \n",
    "                           rotate_limit=60, \n",
    "                           p=0.5),\n",
    "        A.CoarseDropout(p=0.5),\n",
    "        A.Cutout(p=0.5),\n",
    "        ToTensorV2()], p=1.),\n",
    "    \n",
    "    \"valid\": A.Compose([\n",
    "        A.Resize(CONFIG.img_size, CONFIG.img_size),\n",
    "        ToTensorV2()], p=1.)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "940d5e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2\n",
       "1       7\n",
       "2       5\n",
       "3       1\n",
       "4       8\n",
       "       ..\n",
       "5105    4\n",
       "5106    8\n",
       "5107    2\n",
       "5108    4\n",
       "5109    5\n",
       "Name: age, Length: 5110, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.age\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c0a3af",
   "metadata": {},
   "source": [
    "### Kfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f0d717c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0\n",
      "1       1\n",
      "2       1\n",
      "3       2\n",
      "4       3\n",
      "       ..\n",
      "5105    1\n",
      "5106    1\n",
      "5107    1\n",
      "5108    4\n",
      "5109    0\n",
      "Name: kfold, Length: 5110, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:668: UserWarning:\n",
      "\n",
      "The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#df = pd.read_csv(f\"{ROOT_DIR}/train_labels.csv\")\n",
    "skf = StratifiedKFold(n_splits=CONFIG.n_fold, shuffle=True, random_state=CONFIG.seed)\n",
    "y_train = df.age.values\n",
    "\n",
    "for fold, ( train_idx, val_idx) in enumerate( skf.split( X=df, y=df.age.values.tolist() ) ):\n",
    "    df.loc[val_idx , \"kfold\"] = int(fold)\n",
    "    #df.loc[train_idx , \"kfold\"] = int(fold)\n",
    "    \n",
    "df['kfold'] = df['kfold'].astype(int)\n",
    "print(df.kfold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c26320",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c8388220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(fold):\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    \n",
    "    train_dataset = codDataset(df_train, transforms=data_transforms['train'])\n",
    "    valid_dataset = codDataset(df_valid, transforms=data_transforms['valid'])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CONFIG.train_batch_size, \n",
    "                              num_workers=4, shuffle=True, pin_memory=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG.valid_batch_size, \n",
    "                              num_workers=4, shuffle=False, pin_memory=True)\n",
    "    \n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830c6b86",
   "metadata": {},
   "source": [
    "### Prepare dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ef0003bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7fe75c255748>\n"
     ]
    }
   ],
   "source": [
    "train_loader, valid_loader = prepare_data(fold=0)\n",
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37ab3eb",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "68b74a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss()\n"
     ]
    }
   ],
   "source": [
    "#def binary_accuracy_for_regression(y_true, y_pred):\n",
    "#    return K.mean(K.equal(y_true, K.round(y_pred)), axis=-1)\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4432b7c",
   "metadata": {},
   "source": [
    "### Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1a08ea61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n",
    "    model.train()\n",
    "    scaler = amp.GradScaler()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for step, (images, labels) in bar:         \n",
    "        images = images.to(device, dtype=torch.float)\n",
    "        labels = labels.to(device, dtype=torch.float)\n",
    "        \n",
    "        inputs, targets_a, targets_b, lam = mixup_data(images, labels.view(-1, 1))\n",
    "        \n",
    "        inputs = inputs.to(device, dtype=torch.float)\n",
    "        targets_a = targets_a.to(device, dtype=torch.float)\n",
    "        targets_b = targets_b.to(device, dtype=torch.float)\n",
    "        \n",
    "        batch_size = images.size(0)\n",
    "        \n",
    "        with amp.autocast(enabled=True):\n",
    "            outputs = model(inputs)\n",
    "            loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n",
    "            loss = loss / CONFIG.n_accumulate\n",
    "            \n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        if (step + 1) % CONFIG.n_accumulate == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "                \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss/dataset_size\n",
    "        \n",
    "        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss,\n",
    "                        LR=optimizer.param_groups[0]['lr'])\n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cb63a5",
   "metadata": {},
   "source": [
    "### Validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "31712a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def valid_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n",
    "    model.eval()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    TARGETS = []\n",
    "    PREDS = []\n",
    "    \n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for step, (images, labels) in bar:        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        batch_size = images.size(0)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs.view(-1), labels)\n",
    "        \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss/dataset_size\n",
    "        \n",
    "        PREDS.append(outputs.sigmoid().cpu().detach().numpy())\n",
    "        TARGETS.append(labels.view(-1).cpu().detach().numpy())\n",
    "        \n",
    "        bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss,\n",
    "                        LR=optimizer.param_groups[0]['lr'])   \n",
    "    \n",
    "    TARGETS = np.concatenate(TARGETS)\n",
    "    PREDS = np.concatenate(PREDS)\n",
    "    val_auc = roc_auc_score(TARGETS, PREDS)\n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss, val_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63afb20b",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "278c1dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@logger.catch\n",
    "def run(model, optimizer, scheduler, device, num_epochs):    \n",
    "    start = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_epoch_auc = 0\n",
    "    history = defaultdict(list)\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1): \n",
    "        gc.collect()\n",
    "        train_epoch_loss = train_one_epoch(model, optimizer, scheduler, \n",
    "                                           dataloader=train_loader, \n",
    "                                           device=CONFIG.device, epoch=epoch)\n",
    "        \n",
    "        valid_epoch_loss, valid_epoch_auc = valid_one_epoch(model, optimizer, scheduler,\n",
    "                                                            dataloader=valid_loader, \n",
    "                                                            device=CONFIG.device, epoch=epoch)\n",
    "    \n",
    "        history['Train Loss'].append(train_epoch_loss)\n",
    "        history['Valid Loss'].append(valid_epoch_loss)\n",
    "        history['Valid AUC'].append(valid_epoch_auc)\n",
    "        \n",
    "        print(f'Valid AUC: {valid_epoch_auc}')\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        \n",
    "        # deep copy the model\n",
    "        if valid_epoch_auc >= best_epoch_auc:\n",
    "            print(f\"{b_}Validation AUC Improved ({best_epoch_auc} ---> {valid_epoch_auc})\")\n",
    "            best_epoch_auc = valid_epoch_auc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            PATH = \"AUC{:.4f}_epoch{:.0f}.bin\".format(best_epoch_auc, epoch)\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "            print(\"Model Saved\")\n",
    "            \n",
    "        print()\n",
    "    \n",
    "    end = time.time()\n",
    "    time_elapsed = end - start\n",
    "    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "    print(\"Best AUC: {:.4f}\".format(best_epoch_auc))\n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b6db47",
   "metadata": {},
   "source": [
    "### Train fold 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7023c5a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#torch.cuda.is_available() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "353082af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/128 [00:00<?, ?it/s]\n",
      "2021-11-11 14:35:53.201 | ERROR    | __main__:<module>:16 - An error has been caught in function '<module>', process 'MainProcess' (2576), thread 'MainThread' (140636972394304):\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "                └ ModuleSpec(name='ipykernel_launcher', loader=<_frozen_importlib_external.SourceFileLoader object at 0x7fe897647d30>, origin='...\n",
      "  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "         │     └ {'__name__': '__main__', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nThis is separate from the ipykernel pack...\n",
      "         └ <code object <module> at 0x7fe8976a04b0, file \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 5>\n",
      "\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "    │   └ <bound method Application.launch_instance of <class 'ipykernel.kernelapp.IPKernelApp'>>\n",
      "    └ <module 'ipykernel.kernelapp' from '/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py'>\n",
      "\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 664, in launch_instance\n",
      "    app.start()\n",
      "    │   └ <function IPKernelApp.start at 0x7fe89029fd90>\n",
      "    └ <ipykernel.kernelapp.IPKernelApp object at 0x7fe8977dcb38>\n",
      "\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n",
      "    self.io_loop.start()\n",
      "    │    │       └ <function BaseAsyncIOLoop.start at 0x7fe890b090d0>\n",
      "    │    └ <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7fe8902d5748>\n",
      "    └ <ipykernel.kernelapp.IPKernelApp object at 0x7fe8977dcb38>\n",
      "\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tornado/platform/asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "    │    │            └ <function BaseEventLoop.run_forever at 0x7fe894f72840>\n",
      "    │    └ <_UnixSelectorEventLoop running=True closed=False debug=False>\n",
      "    └ <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7fe8902d5748>\n",
      "\n",
      "  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n",
      "    self._run_once()\n",
      "    │    └ <function BaseEventLoop._run_once at 0x7fe894f73d08>\n",
      "    └ <_UnixSelectorEventLoop running=True closed=False debug=False>\n",
      "  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n",
      "    handle._run()\n",
      "    │      └ <function Handle._run at 0x7fe8951c9bf8>\n",
      "    └ <Handle IOLoop.add_future.<locals>.<lambda>(<Future finished result=None>) at /usr/local/lib/python3.6/dist-packages/tornado/...\n",
      "  File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "    │    │          │    └ <member '_args' of 'Handle' objects>\n",
      "    │    │          └ <Handle IOLoop.add_future.<locals>.<lambda>(<Future finished result=None>) at /usr/local/lib/python3.6/dist-packages/tornado/...\n",
      "    │    └ <member '_callback' of 'Handle' objects>\n",
      "    └ <Handle IOLoop.add_future.<locals>.<lambda>(<Future finished result=None>) at /usr/local/lib/python3.6/dist-packages/tornado/...\n",
      "\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 688, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "           │  │    │             │         │       │         └ <Future finished result=None>\n",
      "           │  │    │             │         │       └ <function Runner.handle_yield.<locals>.inner at 0x7fe7575f3b70>\n",
      "           │  │    │             │         └ <class 'functools.partial'>\n",
      "           │  │    │             └ <module 'functools' from '/usr/lib/python3.6/functools.py'>\n",
      "           │  │    └ <function IOLoop._run_callback at 0x7fe890b6bae8>\n",
      "           │  └ <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7fe8902d5748>\n",
      "           └ <Future finished result=None>\n",
      "\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 741, in _run_callback\n",
      "    ret = callback()\n",
      "          └ functools.partial(<function Runner.handle_yield.<locals>.inner at 0x7fe7575f3b70>, <Future finished result=None>)\n",
      "\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 814, in inner\n",
      "    self.ctx_run(self.run)\n",
      "    │    │       │    └ <function Runner.run at 0x7fe890b05840>\n",
      "    │    │       └ <tornado.gen.Runner object at 0x7fe88c80ccf8>\n",
      "    │    └ <function _fake_ctx_run at 0x7fe890b6fae8>\n",
      "    └ <tornado.gen.Runner object at 0x7fe88c80ccf8>\n",
      "\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 162, in _fake_ctx_run\n",
      "    return f(*args, **kw)\n",
      "           │  │       └ {}\n",
      "           │  └ ()\n",
      "           └ <bound method Runner.run of <tornado.gen.Runner object at 0x7fe88c80ccf8>>\n",
      "\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 775, in run\n",
      "    yielded = self.gen.send(value)\n",
      "              │    │   │    └ None\n",
      "              │    │   └ <method 'send' of 'generator' objects>\n",
      "              │    └ <generator object dispatch_queue at 0x7fe88c81a308>\n",
      "              └ <tornado.gen.Runner object at 0x7fe88c80ccf8>\n",
      "\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "          │    └ <function Kernel.process_one at 0x7fe8902df048>\n",
      "          └ <ipykernel.ipkernel.IPythonKernel object at 0x7fe8902d59e8>\n",
      "\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 250, in wrapper\n",
      "    runner = Runner(ctx_run, result, future, yielded)\n",
      "             │      │        │       │       └ <Future finished result=(10, 103, <bound method...7fe8902d59e8>>, (<zmq.eventloo...x7fe8902d5198>, [<zmq.sugar.fr...x7fe89036...\n",
      "             │      │        │       └ <Future pending>\n",
      "             │      │        └ <generator object process_one at 0x7fe7575e58e0>\n",
      "             │      └ <function _fake_ctx_run at 0x7fe890b6fae8>\n",
      "             └ <class 'tornado.gen.Runner'>\n",
      "\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 741, in __init__\n",
      "    self.ctx_run(self.run)\n",
      "    │    │       │    └ <function Runner.run at 0x7fe890b05840>\n",
      "    │    │       └ <tornado.gen.Runner object at 0x7fe75c1f9518>\n",
      "    │    └ <function _fake_ctx_run at 0x7fe890b6fae8>\n",
      "    └ <tornado.gen.Runner object at 0x7fe75c1f9518>\n",
      "\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 162, in _fake_ctx_run\n",
      "    return f(*args, **kw)\n",
      "           │  │       └ {}\n",
      "           │  └ ()\n",
      "           └ <bound method Runner.run of <tornado.gen.Runner object at 0x7fe75c1f9518>>\n",
      "\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 775, in run\n",
      "    yielded = self.gen.send(value)\n",
      "              │    │   │    └ (10, 103, <bound method Kernel.dispatch_shell of <ipykernel.ipkernel.IPythonKernel object at 0x7fe8902d59e8>>, (<zmq.eventloo...\n",
      "              │    │   └ <method 'send' of 'generator' objects>\n",
      "              │    └ <generator object process_one at 0x7fe7575e58e0>\n",
      "              └ <tornado.gen.Runner object at 0x7fe75c1f9518>\n",
      "\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "          │   │            │         └ (<zmq.eventloop.zmqstream.ZMQStream object at 0x7fe8902d5198>, [<zmq.sugar.frame.Frame object at 0x7fe890365830>, <zmq.sugar....\n",
      "          │   │            └ <bound method Kernel.dispatch_shell of <ipykernel.ipkernel.IPythonKernel object at 0x7fe8902d59e8>>\n",
      "          │   └ <function maybe_future at 0x7fe890b05488>\n",
      "          └ <module 'tornado.gen' from '/usr/local/lib/python3.6/dist-packages/tornado/gen.py'>\n",
      "\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "              │             └ <generator object dispatch_shell at 0x7fe757838620>\n",
      "              └ <function _fake_ctx_run at 0x7fe890b6fae8>\n",
      "\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 162, in _fake_ctx_run\n",
      "    return f(*args, **kw)\n",
      "           │  │       └ {}\n",
      "           │  └ (<generator object dispatch_shell at 0x7fe757838620>,)\n",
      "           └ <built-in function next>\n",
      "\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "          │   │            │       │       │       └ {'header': {'msg_id': 'f1c268c18c3e403189b4b20b978a9a1f', 'username': 'username', 'session': '81804c5b317944988bef63e9a723773...\n",
      "          │   │            │       │       └ [b'81804c5b317944988bef63e9a7237736']\n",
      "          │   │            │       └ <zmq.eventloop.zmqstream.ZMQStream object at 0x7fe8902d5198>\n",
      "          │   │            └ <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object at 0x7fe8902d59e8>>\n",
      "          │   └ <function maybe_future at 0x7fe890b05488>\n",
      "          └ <module 'tornado.gen' from '/usr/local/lib/python3.6/dist-packages/tornado/gen.py'>\n",
      "\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "              │             └ <generator object execute_request at 0x7fe757838c50>\n",
      "              └ <function _fake_ctx_run at 0x7fe890b6fae8>\n",
      "\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 162, in _fake_ctx_run\n",
      "    return f(*args, **kw)\n",
      "           │  │       └ {}\n",
      "           │  └ (<generator object execute_request at 0x7fe757838c50>,)\n",
      "           └ <built-in function next>\n",
      "\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 541, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "    │                 └ True\n",
      "    └ {}\n",
      "\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "              │             └ <generator object do_execute at 0x7fe756349eb8>\n",
      "              └ <function _fake_ctx_run at 0x7fe890b6fae8>\n",
      "\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 162, in _fake_ctx_run\n",
      "    return f(*args, **kw)\n",
      "           │  │       └ {}\n",
      "           │  └ (<generator object do_execute at 0x7fe756349eb8>,)\n",
      "           └ <built-in function next>\n",
      "\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "          │     │        │                   │                     └ False\n",
      "          │     │        │                   └ True\n",
      "          │     │        └ \"def fetch_scheduler(optimizer):\\n    if CONFIG.scheduler == 'CosineAnnealingLR':\\n        scheduler = lr_scheduler.CosineAnn...\n",
      "          │     └ <function ZMQInteractiveShell.run_cell at 0x7fe890307f28>\n",
      "          └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7fe8902d5550>\n",
      "\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "                 │                    │               │       └ {'store_history': True, 'silent': False}\n",
      "                 │                    │               └ (\"def fetch_scheduler(optimizer):\\n    if CONFIG.scheduler == 'CosineAnnealingLR':\\n        scheduler = lr_scheduler.CosineAn...\n",
      "                 │                    └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7fe8902d5550>\n",
      "                 └ <class 'ipykernel.zmqshell.ZMQInteractiveShell'>\n",
      "\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2867, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "    │         │              │       └ True\n",
      "    │         │              └ False\n",
      "    │         └ True\n",
      "    └ \"def fetch_scheduler(optimizer):\\n    if CONFIG.scheduler == 'CosineAnnealingLR':\\n        scheduler = lr_scheduler.CosineAnn...\n",
      "\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2895, in _run_cell\n",
      "    return runner(coro)\n",
      "           │      └ <coroutine object InteractiveShell.run_cell_async at 0x7fe756349fc0>\n",
      "           └ <function _pseudo_sync_runner at 0x7fe89521d400>\n",
      "\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "    │    └ <method 'send' of 'coroutine' objects>\n",
      "    └ <coroutine object InteractiveShell.run_cell_async at 0x7fe756349fc0>\n",
      "\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3072, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "                  │                       │                └ <ExecutionResult object at 7fe75c2521d0, execution_count=98 error_before_exec=None error_in_exec=None info=<ExecutionInfo obj...\n",
      "                  │                       └ <IPython.core.compilerop.CachingCompiler object at 0x7fe8902d5b38>\n",
      "                  └ 'last_expr'\n",
      "\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3263, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "              │    │        │     │               └ False\n",
      "              │    │        │     └ <ExecutionResult object at 7fe75c2521d0, execution_count=98 error_before_exec=None error_in_exec=None info=<ExecutionInfo obj...\n",
      "              │    │        └ <code object <module> at 0x7fe75c1b0a50, file \"<ipython-input-98-3fbb5ff72dad>\", line 16>\n",
      "              │    └ <function InteractiveShell.run_code at 0x7fe895231ea0>\n",
      "              └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7fe8902d5550>\n",
      "\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "         │         │    │               │    └ {'__name__': '__main__', '__doc__': 'Automatically created module for IPython interactive environment', '__package__': None, ...\n",
      "         │         │    │               └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7fe8902d5550>\n",
      "         │         │    └ <property object at 0x7fe89521bd68>\n",
      "         │         └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7fe8902d5550>\n",
      "         └ <code object <module> at 0x7fe75c1b0a50, file \"<ipython-input-98-3fbb5ff72dad>\", line 16>\n",
      "\n",
      "> File \"<ipython-input-98-3fbb5ff72dad>\", line 16, in <module>\n",
      "    model, history = run(model, optimizer, scheduler=scheduler, device=CONFIG.device, num_epochs=CONFIG.epochs)\n",
      "    │                │   │      │                    │                 │      │                  │      └ 5\n",
      "    │                │   │      │                    │                 │      │                  └ <class '__main__.CONFIG'>\n",
      "    │                │   │      │                    │                 │      └ device(type='cuda', index=0)\n",
      "    │                │   │      │                    │                 └ <class '__main__.CONFIG'>\n",
      "    │                │   │      │                    └ <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7fe75c204d30>\n",
      "    │                │   │      └ Adam (\n",
      "    │                │   │        Parameter Group 0\n",
      "    │                │   │            amsgrad: False\n",
      "    │                │   │            betas: (0.9, 0.999)\n",
      "    │                │   │            eps: 1e-08\n",
      "    │                │   │            initial_lr: 0.0001\n",
      "    │                │   │            lr: 0.0001\n",
      "    │                │   │            ...\n",
      "    │                │   └ codModel(\n",
      "    │                │       (model): EfficientNet(\n",
      "    │                │         (conv_stem): Conv2dSame(3, 24, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "    │                │         (bn1...\n",
      "    │                └ <function run at 0x7fe7576b8f28>\n",
      "    └ codModel(\n",
      "        (model): EfficientNet(\n",
      "          (conv_stem): Conv2dSame(3, 24, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "          (bn1...\n",
      "  File \"<ipython-input-72-b3d177e72560>\", line 12, in run\n",
      "    device=CONFIG.device, epoch=epoch)\n",
      "           │      │             └ 1\n",
      "           │      └ device(type='cuda', index=0)\n",
      "           └ <class '__main__.CONFIG'>\n",
      "  File \"<ipython-input-75-749c755faf5d>\", line 9, in train_one_epoch\n",
      "    for step, (images, labels) in bar:\n",
      "                                  └ <tqdm.std.tqdm object at 0x7fe834ef4cc0>\n",
      "\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tqdm/std.py\", line 1180, in __iter__\n",
      "    for obj in iterable:\n",
      "               └ <enumerate object at 0x7fe757626438>\n",
      "\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
      "    data = self._next_data()\n",
      "           │    └ <function _MultiProcessingDataLoaderIter._next_data at 0x7fe821998400>\n",
      "           └ <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7fe75c23ff60>\n",
      "\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 1203, in _next_data\n",
      "    return self._process_data(data)\n",
      "           │    │             └ <torch._utils.ExceptionWrapper object at 0x7fe75c201908>\n",
      "           │    └ <function _MultiProcessingDataLoaderIter._process_data at 0x7fe821998510>\n",
      "           └ <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7fe75c23ff60>\n",
      "\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 1229, in _process_data\n",
      "    data.reraise()\n",
      "    │    └ <function ExceptionWrapper.reraise at 0x7fe8678e9a60>\n",
      "    └ <torch._utils.ExceptionWrapper object at 0x7fe75c201908>\n",
      "\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/_utils.py\", line 434, in reraise\n",
      "    raise exception\n",
      "          └ ValueError('Caught ValueError in DataLoader worker process 0.\\nOriginal Traceback (most recent call last):\\n  File \"/usr/loca...\n",
      "\n",
      "ValueError: Caught ValueError in DataLoader worker process 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
      "    data = fetcher.fetch(index)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"<ipython-input-32-4ff3caf47a7b>\", line 12, in __getitem__\n",
      "    image = np.load(self.file_names[index]).astype(np.float32)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\", line 444, in load\n",
      "    raise ValueError(\"Cannot load file containing pickled data \"\n",
      "ValueError: Cannot load file containing pickled data when allow_pickle=False\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-3fbb5ff72dad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONFIG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONFIG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCONFIG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCONFIG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "def fetch_scheduler(optimizer):\n",
    "    if CONFIG.scheduler == 'CosineAnnealingLR':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=CONFIG.T_max, eta_min=CONFIG.min_lr)\n",
    "    elif CONFIG.scheduler == 'CosineAnnealingWarmRestarts':\n",
    "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=CONFIG.T_0, T_mult=1, eta_min=CONFIG.min_lr)\n",
    "    elif CONFIG.scheduler == None:\n",
    "        return None\n",
    "        \n",
    "    return scheduler\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=CONFIG.learning_rate, weight_decay=CONFIG.weight_decay)\n",
    "scheduler = fetch_scheduler(optimizer)\n",
    "\n",
    "print(CONFIG.device)\n",
    "print(CONFIG.epochs)\n",
    "model, history = run(model, optimizer, scheduler=scheduler, device=CONFIG.device, num_epochs=CONFIG.epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
