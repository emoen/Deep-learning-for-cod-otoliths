{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8ec969d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image, ExifTags\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import compute_class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "import scipy\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img, ImageDataGenerator\n",
    "from tensorflow.keras.layers import Activation, Dense, GlobalAveragePooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "\n",
    "#salmon-scales\n",
    "#from train_util import read_images, load_xy, get_checkpoint_tensorboard, create_model_grayscale, get_fresh_weights, base_output, dense1_linear_output, train_validate_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaf8bc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-1.10.1-cp36-cp36m-manylinux1_x86_64.whl (881.9 MB)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.7.4.3)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch) (0.8)\n",
      "Installing collected packages: torch\n",
      "\u001b[33m  WARNING: The scripts convert-caffe2-to-onnx, convert-onnx-to-caffe2 and torchrun are installed in '/home/endrem/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed torch-1.10.1\n"
     ]
    }
   ],
   "source": [
    "#!pip uninstall plotly -y\n",
    "#!pip install plotly --user\n",
    "#!pip uninstall torch -y\n",
    "#!pip install torch --user\n",
    "#!pip install loguru --user\n",
    "#!pip install timm --user #PyTorch Image Models\n",
    "#!pip install albumentations  --user #augmentation\n",
    "#!pip install colorama --user #color terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3ec8a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import amp\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import timm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from colorama import Fore\n",
    "b_ = Fore.BLUE\n",
    "\n",
    "from train_val_test_split import train_validate_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559189a4",
   "metadata": {},
   "source": [
    "### Train Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be13b22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/efficientnet.py\n",
    "# tf_efficientnetv2_s_in21k - input_size=(3, 300, 300), test_input_size=(3, 384, 384)\n",
    "# tf_efficientnetv2_m_in21k - input_size=(3, 384, 384), test_input_size=(3, 480, 480)\n",
    "# tf_efficientnetv2_l_in21k - input_size=(3, 384, 384), test_input_size=(3, 480, 480)\n",
    "# tf_efficientnetv2_xl_in21k -input_size=(3, 384, 384), test_input_size=(3, 512, 512)\n",
    "\n",
    "class CONFIG:\n",
    "    seed = 42\n",
    "    model_name = 'tf_efficientnetv2_m_in21k' \n",
    "    train_batch_size = 8\n",
    "    valid_batch_size = 8\n",
    "    img_size = 384\n",
    "    val_img_size = 480\n",
    "    learning_rate = 1e-5\n",
    "    min_lr = 1e-6\n",
    "    weight_decay = 1e-6\n",
    "    T_max = 10\n",
    "    scheduler = 'CosineAnnealingLR'\n",
    "    n_accumulate = 1\n",
    "    n_fold = 10 #5\n",
    "    target_size = 1\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    debugging = False\n",
    "    which_exposure = \"min\"\n",
    "    CHANNELS = \"channels_first\"\n",
    "    KERAS_TRAIN_TEST_SEED = 2021\n",
    "    ROOTDIR = \"./EFFNetV2_m/\"\n",
    "    CUDA_VISIBLE_DEVICE = \"0\"\n",
    "    #tensorboard_path = 'tensorboard_test2'\n",
    "    #checkpoint_path = 'checkpoints_test2/cod_oto_efficientnetBBB.{epoch:03d}-{val_loss:.2f}.hdf5'\n",
    "    input_shape = (3, img_size, img_size)\n",
    "    test_size = 0.1 #0.15\n",
    "    test_split_seed = 8\n",
    "    steps_per_epoch = 160 #0\n",
    "    epochs = 150\n",
    "    early_stopping_patience = 14\n",
    "    reduceLROnPlateau_factor = 0.2\n",
    "    reduceLROnPlateau_patience = 7\n",
    "    early_stopping = 25\n",
    "    base_dir = '/gpfs/gpfs0/deep/data/Savannah_Professional_Practice2021_08_12_2021/CodOtholiths-MachineLearning/Savannah_Professional_Practice'\n",
    "    \n",
    "    \n",
    "def set_seed(seed = 42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "set_seed(CONFIG.seed)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0c779b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "config_dict = CONFIG.__dict__\n",
    "config_dict = dict(config_dict)\n",
    "config_dict.pop('device', None)\n",
    "config_dict.pop('__dict__', None)\n",
    "config_dict.pop('__weakref__', None)\n",
    "config_dict.pop('__doc__', None)\n",
    "\n",
    "with open(CONFIG.ROOTDIR+'config.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(config_dict, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ef2dc5",
   "metadata": {},
   "source": [
    "### Read files to Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "083e5863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error_count:226\n",
      "add_count:5150\n"
     ]
    }
   ],
   "source": [
    "from utils.read_jpg_cods import read_jpg_cods\n",
    "from utils.train_val_test_split import *\n",
    "from utils.train_test_split import *\n",
    "\n",
    "CONFIG.debugging = False\n",
    "df = read_jpg_cods( CONFIG ) #5316 #5110 #5150\n",
    "#5110 images, after updating folder 2015: len age:5153 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "041f135f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error_count:226\n",
      "add_count:5150\n"
     ]
    }
   ],
   "source": [
    "CONFIG.img_size = CONFIG.val_img_size\n",
    "df_test = read_jpg_cods( CONFIG ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4ddd26",
   "metadata": {},
   "source": [
    "### Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3deb968b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len age:5150\n",
      "True\n",
      "True\n",
      "(515, 3, 480, 480)\n",
      "(4635, 3, 384, 384)\n",
      "4635\n",
      "(515, 3, 480, 480)\n",
      "515\n",
      "5150\n",
      "5150\n"
     ]
    }
   ],
   "source": [
    "print(\"len age:\"+str( len(df.age) ) ) #len age:5090, error_count:205\n",
    "train_imgs, train_age, test_imgs, test_age, test_path = train_test_split(df, CONFIG, test_size=CONFIG.test_size, a_seed=CONFIG.test_split_seed)\n",
    "test_path.to_csv( CONFIG.ROOTDIR+\"test_set_files.csv\", index=False)\n",
    "train_imgs2, train_age2, test_imgs2, test_age2, test_path2 = train_test_split(df_test, CONFIG, test_size=CONFIG.test_size, a_seed=CONFIG.test_split_seed)\n",
    "\n",
    "print(np.any(test_path2==test_path))\n",
    "print(np.any(test_age==test_age2))\n",
    "test_imgs = test_imgs2\n",
    "\n",
    "del train_imgs2\n",
    "del test_imgs2\n",
    "del train_age2\n",
    "del test_age2\n",
    "print(test_imgs.shape)\n",
    "\n",
    "#df1 = pd.DataFrame(list(zip(train_imgs, train_age)), columns=['image', 'age'])\n",
    "\n",
    "print(train_imgs.shape)\n",
    "print(len(train_age))\n",
    "print(test_imgs.shape)\n",
    "print(len(test_age))\n",
    "print(len(train_age)+len(test_age))\n",
    "print(len(df))\n",
    "#print(len(df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2cd2a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4378, 3, 384, 384)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(3502, 3, 384, 384)\n",
      "(3502,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(876, 3, 384, 384)\n",
      "(876,)\n",
      "#########################\n",
      "(3502, 3, 384, 384)\n",
      "(3502,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(876, 3, 384, 384)\n",
      "(876,)\n",
      "#########################\n",
      "(3502, 3, 384, 384)\n",
      "(3502,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(876, 3, 384, 384)\n",
      "(876,)\n",
      "#########################\n",
      "(3503, 3, 384, 384)\n",
      "(3503,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(875, 3, 384, 384)\n",
      "(875,)\n",
      "#########################\n",
      "(3503, 3, 384, 384)\n",
      "(3503,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(875, 3, 384, 384)\n",
      "(875,)\n",
      "#########################\n"
     ]
    }
   ],
   "source": [
    "print( train_imgs.shape )\n",
    "print( type(train_imgs ))\n",
    "print( type(train_age ))\n",
    "\n",
    "a_seed = CONFIG.KERAS_TRAIN_TEST_SEED #2021\n",
    "numberOfFolds = CONFIG.n_fold #5\n",
    "kfold = StratifiedKFold(n_splits=numberOfFolds, random_state=a_seed, shuffle=True)\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(train_imgs, train_age.tolist())):\n",
    "    train_imgs_new = train_imgs[train_idx]\n",
    "    train_age_new = train_age[train_idx]\n",
    "    val_imgs_new = train_imgs[val_idx]\n",
    "    val_age_new = train_age[val_idx]\n",
    "    \n",
    "    print( train_imgs_new.shape )\n",
    "    print( train_age_new.shape )\n",
    "    print( type( train_imgs_new ))\n",
    "    print( type( train_age_new ))\n",
    "    print( val_imgs_new.shape )\n",
    "    print( val_age_new.shape )\n",
    "    \n",
    "    #print(train_imgs_new[0:5])\n",
    "    print(\"#########################\")\n",
    "    #print(val_imgs_new[0:5])\n",
    "    \n",
    "    train_dataset = codDataset(train_imgs_new, train_age_new)\n",
    "    valid_dataset = codDataset(val_imgs_new, val_age_new)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CONFIG.train_batch_size, \n",
    "                              num_workers=0, shuffle=True, pin_memory=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG.valid_batch_size, \n",
    "                              num_workers=0, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e792b0",
   "metadata": {},
   "source": [
    "### Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ceb841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class codDataset(Dataset):\n",
    "    def __init__(self, imgs, age): \n",
    "        self.labels = age \n",
    "        self.image = imgs #np.stack( df['image'].values , axis=0) # make 4D-array (num_imgs, channels, width, height)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = self.image[index]\n",
    "        label = torch.tensor(self.labels[index]).float()\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96789f86",
   "metadata": {},
   "source": [
    "### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a6bbfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    \"train\": A.Compose([\n",
    "        A.Resize(CONFIG.img_size, CONFIG.img_size),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.ShiftScaleRotate(shift_limit=0.01, #0.1, \n",
    "                           scale_limit=0.0,  #0.15, \n",
    "                           rotate_limit=360, \n",
    "                           p=0.5),\n",
    "        #A.CoarseDropout(p=0.5),\n",
    "        #A.Cutout(p=0.5),\n",
    "        ToTensorV2()], p=1.),\n",
    "    \n",
    "    \"valid\": A.Compose([\n",
    "        A.Resize(CONFIG.img_size, CONFIG.img_size),\n",
    "        ToTensorV2()], p=1.)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e876af74",
   "metadata": {},
   "source": [
    "### Cod Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c561efd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class codModel(nn.Module):\n",
    "\n",
    "    def __init__(self, model_name, pretrained=True):\n",
    "        super(codModel, self).__init__()\n",
    "        self.model = timm.create_model(CONFIG.model_name, pretrained=pretrained, in_chans=3, num_classes=1) #model_name\n",
    "        self.n_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Linear(self.n_features, CONFIG.target_size)\n",
    "        #lastLayer = nn.Sequential(nn.Linear(self.n_features, 256),\n",
    "        #      nn.LeakyReLU(),\n",
    "        #      nn.Linear(256, 32),\n",
    "        #      nn.LeakyReLU(),\n",
    "        #      nn.Linear(32, CONFIG.target_size))\n",
    "        #self.model.classifier = lastLayer\n",
    "        #print(\"model self:\"+str(self.model.classifier))\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.model(x)\n",
    "        return output\n",
    "    \n",
    "model = codModel(CONFIG.model_name)\n",
    "model.to(CONFIG.device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca673f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torchsummary\n",
    "#from torchsummary import summary\n",
    "\n",
    "#summary(model, (3, 384,384))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08a7c973",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4432b7c",
   "metadata": {},
   "source": [
    "### Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a08ea61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n",
    "    model.train()\n",
    "    scaler = amp.GradScaler()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss_fn = nn.MSELoss()\n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for step, (images, labels) in bar:  \n",
    "        #optimizer.zero_grad()\n",
    "        \n",
    "        images = images.to(device, dtype=torch.float)\n",
    "        labels = labels.to(device, dtype=torch.float)\n",
    "        labels = torch.unsqueeze(labels, 1)\n",
    "        \n",
    "        batch_size = images.size(0)\n",
    "        \n",
    "        with amp.autocast(enabled=True):\n",
    "            outputs = model(images)\n",
    "            #print(\"outputs:+\"+str(outputs))\n",
    "            #print(\"labels:\"+str(labels))\n",
    "            #print(\"mse:\"+str(mean_squared_error(labels.cpu().data.numpy(), outputs.cpu().data.numpy())))\n",
    "            loss = loss_fn(outputs, labels)\n",
    "         \n",
    "        \n",
    "        scaler.scale(loss).backward() # Scales loss.  Calls backward() on scaled loss to create scaled gradients\n",
    "        #model.print_debug() #model.classifier.weight[0:10,0]\n",
    "        \n",
    "        # scaler.step() first unscales the gradients of the optimizer's assigned params.\n",
    "        # If these gradients do not contain infs or NaNs, optimizer.step() is then called,\n",
    "        # otherwise, optimizer.step() is skipped.        \n",
    "        scaler.step(optimizer)\n",
    "        scaler.update() # Updates the scale for next iteration.\n",
    "            \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad() # set_to_none=True here can modestly improve performance\n",
    "                \n",
    "        running_loss += loss.item() #(loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss/dataset_size\n",
    "        \n",
    "        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss, LR=optimizer.param_groups[0]['lr'])\n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c631f02",
   "metadata": {},
   "source": [
    "### Test train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59bbcbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 22/612 [00:09<04:15,  2.31it/s, Epoch=0, LR=1e-6, Train_Loss=5.67]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-56802743e162>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m train_epoch_loss = train_one_epoch(model, optimizer, scheduler, \n\u001b[1;32m     26\u001b[0m                                    \u001b[0mdataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                                    device=CONFIG.device, epoch=epoch)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-d0be6a4f172d>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, optimizer, scheduler, dataloader, device, epoch)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# otherwise, optimizer.step() is skipped.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Updates the scale for next iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No inf checks were recorded for this optimizer.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    142\u001b[0m                    \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                    \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                    eps=group['eps'])\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def fetch_scheduler(optimizer):\n",
    "    if CONFIG.scheduler == 'CosineAnnealingLR':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=CONFIG.T_max, eta_min=CONFIG.min_lr)\n",
    "    elif CONFIG.scheduler == 'CosineAnnealingWarmRestarts':\n",
    "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=CONFIG.T_0, T_mult=1, eta_min=CONFIG.min_lr)\n",
    "    elif CONFIG.scheduler == None:\n",
    "        return None\n",
    "        \n",
    "    return scheduler\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=CONFIG.learning_rate, weight_decay=CONFIG.weight_decay)\n",
    "scheduler = fetch_scheduler(optimizer)\n",
    "epoch = 0\n",
    "print(CONFIG.device)\n",
    "print(CONFIG.epochs)\n",
    "\n",
    "#for name, param in model.named_parameters():\n",
    "#for param in model.parameters():\n",
    "#    print(str( name ) +\" \"+ str(param.requires_grad))\n",
    "train_dataset = codDataset(train_imgs, train_age)\n",
    "train_loader = DataLoader(train_dataset, batch_size=CONFIG.train_batch_size, \n",
    "                              num_workers=0, shuffle=True, pin_memory=True)\n",
    "\n",
    "gc.collect()\n",
    "train_epoch_loss = train_one_epoch(model, optimizer, scheduler, \n",
    "                                   dataloader=train_loader, \n",
    "                                   device=CONFIG.device, epoch=epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cb63a5",
   "metadata": {},
   "source": [
    "### Validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31712a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "@torch.no_grad()\n",
    "def valid_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n",
    "    model.eval()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    TARGETS = []\n",
    "    PREDS = []\n",
    "    \n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for step, (images, labels) in bar: \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        labels = torch.unsqueeze(labels, 1)\n",
    "        outputs = model(images)\n",
    "        loss = nn.MSELoss()(outputs, labels)\n",
    "        \n",
    "        batch_size = images.size(0)\n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss/dataset_size\n",
    "        \n",
    "        PREDS.append(outputs.cpu().detach().numpy())\n",
    "        TARGETS.append(labels.view(-1).cpu().detach().numpy())\n",
    "        \n",
    "        bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss,\n",
    "                        LR=optimizer.param_groups[0]['lr'])   \n",
    "    \n",
    "    TARGETS = np.concatenate(TARGETS)\n",
    "    PREDS = np.concatenate(PREDS)\n",
    "    PREDS = np.squeeze(PREDS)\n",
    "    \n",
    "    print(\"max:\"+str(np.max( PREDS )))\n",
    "    print(\"mean:\"+str(np.mean( PREDS )))\n",
    "    print(\"min:\"+str(np.min( PREDS )))\n",
    "    \n",
    "    PREDS = PREDS.round()\n",
    "    val_auc = accuracy_score(TARGETS, PREDS) #roc_auc_score(TARGETS, PREDS)\n",
    "    mse_score = mean_squared_error(TARGETS, PREDS)\n",
    "    print(\"acc:\"+str( val_auc ) )\n",
    "    print(\"mse:\"+str( mse_score ) )\n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss , val_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1eff9f1",
   "metadata": {},
   "source": [
    "### Test validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6735bd8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 24/612 [00:02<01:07,  8.77it/s, Epoch=0, LR=1e-6, Valid_Loss=42.7]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-7cea9f13b67d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m train_epoch_loss, acc_score = valid_one_epoch(model, optimizer, scheduler, \n\u001b[1;32m     12\u001b[0m                                    \u001b[0mdataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                                    device=CONFIG.device, epoch=epoch)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-4636016e600b>\u001b[0m in \u001b[0;36mvalid_one_epoch\u001b[0;34m(model, optimizer, scheduler, dataloader, device, epoch)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;31m#print(\"outputs:+\"+str(outputs))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m#print(\"labels:\"+str(labels))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-48588f961f9f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/timm/models/efficientnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_rate\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/timm/models/efficientnet.py\u001b[0m in \u001b[0;36mforward_features\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/timm/models/efficientnet_blocks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;31m# Squeeze-and-excitation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# Point-wise linear projection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/timm/models/efficientnet_blocks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mx_se\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mx_se\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_se\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mx_se\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_se\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mx_se\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_se\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_se\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1097\u001b[0;31m         \u001b[0mforward_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1098\u001b[0m         \u001b[0;31m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m         \u001b[0;31m# this function, and just call forward.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=CONFIG.learning_rate, weight_decay=CONFIG.weight_decay)\n",
    "scheduler = fetch_scheduler(optimizer)\n",
    "epoch = 0\n",
    "print(CONFIG.device)\n",
    "print(CONFIG.epochs)\n",
    "\n",
    "valid_dataset = codDataset(train_imgs[0:10], train_age[0:10]) \n",
    "valid_loader = DataLoader(valid_dataset, batch_size=CONFIG.valid_batch_size, \n",
    "                          num_workers=0, shuffle=False, pin_memory=True)\n",
    "gc.collect()\n",
    "train_epoch_loss, acc_score = valid_one_epoch(model, optimizer, scheduler, \n",
    "                                   dataloader=train_loader, \n",
    "                                   device=CONFIG.device, epoch=epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63afb20b",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "278c1dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@logger.catch\n",
    "def run(model, optimizer, scheduler, train_loader, valid_loader, fold_i):   \n",
    "    device=CONFIG.device\n",
    "    num_epochs=CONFIG.epochs\n",
    "    patience = CONFIG.early_stopping\n",
    "    \n",
    "    start = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_epoch_auc = 0\n",
    "    best_epoch = 0\n",
    "    history = defaultdict(list)\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1): \n",
    "        gc.collect()\n",
    "        train_epoch_loss = train_one_epoch(model, optimizer, scheduler, \n",
    "                                           dataloader=train_loader, \n",
    "                                           device=CONFIG.device, epoch=epoch)\n",
    "        \n",
    "        valid_epoch_loss, acc_score = valid_one_epoch(model, optimizer, scheduler,\n",
    "                                                            dataloader=valid_loader, \n",
    "                                                            device=CONFIG.device, epoch=epoch)\n",
    "    \n",
    "        history['Train Loss'].append(train_epoch_loss)\n",
    "        history['Valid Loss'].append(valid_epoch_loss)\n",
    "        history['Valid AUC'].append(acc_score) #valid_epoch_auc)\n",
    "        \n",
    "        #print(f'Valid AUC: {valid_epoch_auc}')\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        \n",
    "        # deep copy the model\n",
    "        if acc_score >= best_epoch_auc:\n",
    "            print(f\"{b_}Validation AUC Improved ({best_epoch_auc} ---> {acc_score})\")\n",
    "            best_epoch_auc = acc_score\n",
    "            best_epoch = epoch\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            PATH = CONFIG.ROOTDIR +\"AUC{:.4f}_epoch{:.0f}_fold_{:.0f}.bin\".format(best_epoch_auc, epoch, fold_i)\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "            print(\"Model Saved\")\n",
    "            \n",
    "        print()\n",
    "        if best_epoch < epoch - patience:\n",
    "            break\n",
    "    \n",
    "    end = time.time()\n",
    "    time_elapsed = end - start\n",
    "    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "    print(\"Best AUC: {:.4f}\".format(best_epoch_auc))\n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    #print(model.classifier.weight[0:10,0])\n",
    "    \n",
    "    return model, history, best_model_wts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b6db47",
   "metadata": {},
   "source": [
    "### Train fold 0 to 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "2d84af52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CONFIG.n_fold\n",
    "CONFIG.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353082af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "150\n",
      "<class 'numpy.ndarray'>\n",
      "(515, 3, 480, 480)\n",
      "<class 'numpy.ndarray'>\n",
      "#########\n",
      "<class 'numpy.ndarray'>\n",
      "(4635, 3, 384, 384)\n",
      "test_img shape:(515, 3, 480, 480)\n",
      "test_img[0].shape:(3, 480, 480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:41<00:00,  2.35it/s, Epoch=1, LR=1e-5, Train_Loss=1.06]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.24it/s, Epoch=1, LR=1e-5, Valid_Loss=0.884]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.483282\n",
      "mean:5.18172\n",
      "min:0.951399\n",
      "acc:0.5280172413793104\n",
      "mse:0.98491377\n",
      "\u001b[34mValidation AUC Improved (0 ---> 0.5280172413793104)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:42<00:00,  2.35it/s, Epoch=2, LR=9.78e-6, Train_Loss=0.129]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.26it/s, Epoch=2, LR=9.78e-6, Valid_Loss=0.836]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.248125\n",
      "mean:5.054015\n",
      "min:0.2890271\n",
      "acc:0.5366379310344828\n",
      "mse:0.8814655\n",
      "\u001b[34mValidation AUC Improved (0.5280172413793104 ---> 0.5366379310344828)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:42<00:00,  2.35it/s, Epoch=3, LR=9.14e-6, Train_Loss=0.0799]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.28it/s, Epoch=3, LR=9.14e-6, Valid_Loss=0.883]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.467041\n",
      "mean:4.984438\n",
      "min:0.22082293\n",
      "acc:0.49137931034482757\n",
      "mse:0.9741379\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:41<00:00,  2.36it/s, Epoch=4, LR=8.15e-6, Train_Loss=0.0472]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.30it/s, Epoch=4, LR=8.15e-6, Valid_Loss=0.903]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:10.489645\n",
      "mean:5.091308\n",
      "min:0.26955166\n",
      "acc:0.5280172413793104\n",
      "mse:0.9784483\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:41<00:00,  2.36it/s, Epoch=5, LR=6.89e-6, Train_Loss=0.0343]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.27it/s, Epoch=5, LR=6.89e-6, Valid_Loss=0.792]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.040092\n",
      "mean:5.178221\n",
      "min:0.39364594\n",
      "acc:0.5603448275862069\n",
      "mse:0.88793105\n",
      "\u001b[34mValidation AUC Improved (0.5366379310344828 ---> 0.5603448275862069)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:41<00:00,  2.36it/s, Epoch=6, LR=5.5e-6, Train_Loss=0.0263]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.25it/s, Epoch=6, LR=5.5e-6, Valid_Loss=0.774]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.230487\n",
      "mean:5.1770926\n",
      "min:0.41586357\n",
      "acc:0.5581896551724138\n",
      "mse:0.8362069\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:41<00:00,  2.36it/s, Epoch=7, LR=4.11e-6, Train_Loss=0.0246]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.30it/s, Epoch=7, LR=4.11e-6, Valid_Loss=0.714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.517181\n",
      "mean:5.3584847\n",
      "min:0.38888693\n",
      "acc:0.6163793103448276\n",
      "mse:0.7844828\n",
      "\u001b[34mValidation AUC Improved (0.5603448275862069 ---> 0.6163793103448276)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:41<00:00,  2.35it/s, Epoch=8, LR=2.85e-6, Train_Loss=0.0205]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.28it/s, Epoch=8, LR=2.85e-6, Valid_Loss=0.656]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.280216\n",
      "mean:5.2742934\n",
      "min:0.40091673\n",
      "acc:0.6206896551724138\n",
      "mse:0.7155172\n",
      "\u001b[34mValidation AUC Improved (0.6163793103448276 ---> 0.6206896551724138)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:40<00:00,  2.36it/s, Epoch=9, LR=1.86e-6, Train_Loss=0.0191]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.27it/s, Epoch=9, LR=1.86e-6, Valid_Loss=0.64] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.393481\n",
      "mean:5.406223\n",
      "min:0.440729\n",
      "acc:0.6120689655172413\n",
      "mse:0.7176724\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:41<00:00,  2.36it/s, Epoch=10, LR=1.22e-6, Train_Loss=0.0164]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.26it/s, Epoch=10, LR=1.22e-6, Valid_Loss=0.667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.172728\n",
      "mean:5.2624598\n",
      "min:0.52587175\n",
      "acc:0.5948275862068966\n",
      "mse:0.7413793\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:41<00:00,  2.36it/s, Epoch=11, LR=1e-6, Train_Loss=0.0159]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.25it/s, Epoch=11, LR=1e-6, Valid_Loss=0.662]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.14266\n",
      "mean:5.270428\n",
      "min:0.42952842\n",
      "acc:0.5948275862068966\n",
      "mse:0.75\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:41<00:00,  2.36it/s, Epoch=12, LR=1.22e-6, Train_Loss=0.0156]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.28it/s, Epoch=12, LR=1.22e-6, Valid_Loss=0.644]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.299308\n",
      "mean:5.3094487\n",
      "min:0.5134781\n",
      "acc:0.6120689655172413\n",
      "mse:0.7112069\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:41<00:00,  2.35it/s, Epoch=13, LR=1.86e-6, Train_Loss=0.0149]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.36it/s, Epoch=13, LR=1.86e-6, Valid_Loss=0.672]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.498219\n",
      "mean:5.2694817\n",
      "min:0.44995508\n",
      "acc:0.5926724137931034\n",
      "mse:0.7909483\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:41<00:00,  2.36it/s, Epoch=14, LR=2.85e-6, Train_Loss=0.0145]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.29it/s, Epoch=14, LR=2.85e-6, Valid_Loss=0.639]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.226158\n",
      "mean:5.3342505\n",
      "min:0.47000837\n",
      "acc:0.5991379310344828\n",
      "mse:0.7241379\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:41<00:00,  2.35it/s, Epoch=15, LR=4.11e-6, Train_Loss=0.0153]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.28it/s, Epoch=15, LR=4.11e-6, Valid_Loss=0.66] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.297422\n",
      "mean:5.2568526\n",
      "min:0.6704608\n",
      "acc:0.5862068965517241\n",
      "mse:0.7435345\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:42<00:00,  2.35it/s, Epoch=16, LR=5.5e-6, Train_Loss=0.0139]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.27it/s, Epoch=16, LR=5.5e-6, Valid_Loss=0.625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.198516\n",
      "mean:5.288972\n",
      "min:0.6135254\n",
      "acc:0.6056034482758621\n",
      "mse:0.7176724\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:41<00:00,  2.36it/s, Epoch=17, LR=6.89e-6, Train_Loss=0.0147]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.28it/s, Epoch=17, LR=6.89e-6, Valid_Loss=0.631]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:10.897514\n",
      "mean:5.227192\n",
      "min:0.45130402\n",
      "acc:0.5991379310344828\n",
      "mse:0.7241379\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:40<00:00,  2.36it/s, Epoch=18, LR=8.15e-6, Train_Loss=0.0136]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.29it/s, Epoch=18, LR=8.15e-6, Valid_Loss=0.675]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:10.819568\n",
      "mean:5.3069277\n",
      "min:0.5775037\n",
      "acc:0.6120689655172413\n",
      "mse:0.73275864\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:42<00:00,  2.35it/s, Epoch=19, LR=9.14e-6, Train_Loss=0.0136]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.16it/s, Epoch=19, LR=9.14e-6, Valid_Loss=0.639]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.030287\n",
      "mean:5.3294725\n",
      "min:0.6287752\n",
      "acc:0.6379310344827587\n",
      "mse:0.6961207\n",
      "\u001b[34mValidation AUC Improved (0.6206896551724138 ---> 0.6379310344827587)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:42<00:00,  2.35it/s, Epoch=20, LR=9.78e-6, Train_Loss=0.0137] \n",
      "100%|██████████| 58/58 [00:06<00:00,  9.31it/s, Epoch=20, LR=9.78e-6, Valid_Loss=0.627]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.339275\n",
      "mean:5.404193\n",
      "min:0.72349375\n",
      "acc:0.6163793103448276\n",
      "mse:0.7112069\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:41<00:00,  2.35it/s, Epoch=21, LR=1e-5, Train_Loss=0.0132]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.27it/s, Epoch=21, LR=1e-5, Valid_Loss=0.634]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.256055\n",
      "mean:5.312683\n",
      "min:0.5987131\n",
      "acc:0.6314655172413793\n",
      "mse:0.7155172\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:42<00:00,  2.35it/s, Epoch=22, LR=9.78e-6, Train_Loss=0.0104] \n",
      "100%|██████████| 58/58 [00:06<00:00,  9.33it/s, Epoch=22, LR=9.78e-6, Valid_Loss=0.635]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.170828\n",
      "mean:5.229789\n",
      "min:0.56638545\n",
      "acc:0.625\n",
      "mse:0.6810345\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:42<00:00,  2.35it/s, Epoch=23, LR=9.14e-6, Train_Loss=0.00929]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.28it/s, Epoch=23, LR=9.14e-6, Valid_Loss=0.661]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.688606\n",
      "mean:5.491389\n",
      "min:0.5989111\n",
      "acc:0.6314655172413793\n",
      "mse:0.7262931\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:41<00:00,  2.36it/s, Epoch=24, LR=8.15e-6, Train_Loss=0.00862]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.29it/s, Epoch=24, LR=8.15e-6, Valid_Loss=0.576]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.448698\n",
      "mean:5.413528\n",
      "min:0.60791653\n",
      "acc:0.6487068965517241\n",
      "mse:0.6551724\n",
      "\u001b[34mValidation AUC Improved (0.6379310344827587 ---> 0.6487068965517241)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:41<00:00,  2.36it/s, Epoch=25, LR=6.89e-6, Train_Loss=0.00755]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.29it/s, Epoch=25, LR=6.89e-6, Valid_Loss=0.565]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.261351\n",
      "mean:5.3642383\n",
      "min:0.65073925\n",
      "acc:0.6637931034482759\n",
      "mse:0.6163793\n",
      "\u001b[34mValidation AUC Improved (0.6487068965517241 ---> 0.6637931034482759)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:42<00:00,  2.35it/s, Epoch=26, LR=5.5e-6, Train_Loss=0.00651]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.28it/s, Epoch=26, LR=5.5e-6, Valid_Loss=0.565]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.376284\n",
      "mean:5.362238\n",
      "min:0.72916424\n",
      "acc:0.6745689655172413\n",
      "mse:0.6228448\n",
      "\u001b[34mValidation AUC Improved (0.6637931034482759 ---> 0.6745689655172413)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:41<00:00,  2.35it/s, Epoch=27, LR=4.11e-6, Train_Loss=0.00553]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.30it/s, Epoch=27, LR=4.11e-6, Valid_Loss=0.546]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.30832\n",
      "mean:5.405247\n",
      "min:0.75896\n",
      "acc:0.6681034482758621\n",
      "mse:0.6185345\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:41<00:00,  2.36it/s, Epoch=28, LR=2.85e-6, Train_Loss=0.00487]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.28it/s, Epoch=28, LR=2.85e-6, Valid_Loss=0.578]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.307215\n",
      "mean:5.2977047\n",
      "min:0.6000782\n",
      "acc:0.6594827586206896\n",
      "mse:0.6508621\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:41<00:00,  2.35it/s, Epoch=29, LR=1.86e-6, Train_Loss=0.0045] \n",
      "100%|██████████| 58/58 [00:06<00:00,  9.28it/s, Epoch=29, LR=1.86e-6, Valid_Loss=0.557]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.357828\n",
      "mean:5.386117\n",
      "min:0.7122966\n",
      "acc:0.6637931034482759\n",
      "mse:0.64008623\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:42<00:00,  2.34it/s, Epoch=30, LR=1.22e-6, Train_Loss=0.00443]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.26it/s, Epoch=30, LR=1.22e-6, Valid_Loss=0.564]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.265213\n",
      "mean:5.383287\n",
      "min:0.77850085\n",
      "acc:0.6745689655172413\n",
      "mse:0.6314655\n",
      "\u001b[34mValidation AUC Improved (0.6745689655172413 ---> 0.6745689655172413)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:43<00:00,  2.34it/s, Epoch=31, LR=1e-6, Train_Loss=0.00377]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.28it/s, Epoch=31, LR=1e-6, Valid_Loss=0.539]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.50366\n",
      "mean:5.4013762\n",
      "min:0.6401614\n",
      "acc:0.6875\n",
      "mse:0.5883621\n",
      "\u001b[34mValidation AUC Improved (0.6745689655172413 ---> 0.6875)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:42<00:00,  2.34it/s, Epoch=32, LR=1.22e-6, Train_Loss=0.00393]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.28it/s, Epoch=32, LR=1.22e-6, Valid_Loss=0.565]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.272779\n",
      "mean:5.3844013\n",
      "min:0.745155\n",
      "acc:0.6745689655172413\n",
      "mse:0.62931037\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:42<00:00,  2.34it/s, Epoch=33, LR=1.86e-6, Train_Loss=0.00391]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.25it/s, Epoch=33, LR=1.86e-6, Valid_Loss=0.589]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.362813\n",
      "mean:5.37609\n",
      "min:0.7288255\n",
      "acc:0.6681034482758621\n",
      "mse:0.6573276\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:41<00:00,  2.35it/s, Epoch=34, LR=2.85e-6, Train_Loss=0.00413]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.24it/s, Epoch=34, LR=2.85e-6, Valid_Loss=0.579]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.303829\n",
      "mean:5.3917646\n",
      "min:0.7975678\n",
      "acc:0.6637931034482759\n",
      "mse:0.64008623\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:42<00:00,  2.35it/s, Epoch=35, LR=4.11e-6, Train_Loss=0.00455]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.28it/s, Epoch=35, LR=4.11e-6, Valid_Loss=0.569]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.330758\n",
      "mean:5.365728\n",
      "min:0.8724356\n",
      "acc:0.6681034482758621\n",
      "mse:0.63577586\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:41<00:00,  2.36it/s, Epoch=36, LR=5.5e-6, Train_Loss=0.00447]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.29it/s, Epoch=36, LR=5.5e-6, Valid_Loss=0.54] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.496544\n",
      "mean:5.409707\n",
      "min:0.80433077\n",
      "acc:0.6681034482758621\n",
      "mse:0.6012931\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:41<00:00,  2.35it/s, Epoch=37, LR=6.89e-6, Train_Loss=0.00498]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.27it/s, Epoch=37, LR=6.89e-6, Valid_Loss=0.532]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.293536\n",
      "mean:5.383331\n",
      "min:0.7263235\n",
      "acc:0.6831896551724138\n",
      "mse:0.57327586\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:42<00:00,  2.35it/s, Epoch=38, LR=8.15e-6, Train_Loss=0.0061] \n",
      "100%|██████████| 58/58 [00:06<00:00,  9.27it/s, Epoch=38, LR=8.15e-6, Valid_Loss=0.597]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.247747\n",
      "mean:5.2636538\n",
      "min:0.55213416\n",
      "acc:0.6336206896551724\n",
      "mse:0.67241377\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:41<00:00,  2.36it/s, Epoch=39, LR=9.14e-6, Train_Loss=0.00591]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.27it/s, Epoch=39, LR=9.14e-6, Valid_Loss=0.549]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.634234\n",
      "mean:5.426662\n",
      "min:0.8540595\n",
      "acc:0.6681034482758621\n",
      "mse:0.63577586\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:41<00:00,  2.36it/s, Epoch=40, LR=9.78e-6, Train_Loss=0.00582]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.29it/s, Epoch=40, LR=9.78e-6, Valid_Loss=0.553]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.445763\n",
      "mean:5.3773737\n",
      "min:0.90187335\n",
      "acc:0.6702586206896551\n",
      "mse:0.62068963\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:41<00:00,  2.36it/s, Epoch=41, LR=1e-5, Train_Loss=0.00578]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.30it/s, Epoch=41, LR=1e-5, Valid_Loss=0.536]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.632301\n",
      "mean:5.372061\n",
      "min:0.8864919\n",
      "acc:0.6831896551724138\n",
      "mse:0.6034483\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:42<00:00,  2.35it/s, Epoch=42, LR=9.78e-6, Train_Loss=0.00551]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.28it/s, Epoch=42, LR=9.78e-6, Valid_Loss=0.566]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.645141\n",
      "mean:5.2889304\n",
      "min:0.8436494\n",
      "acc:0.6939655172413793\n",
      "mse:0.60560346\n",
      "\u001b[34mValidation AUC Improved (0.6875 ---> 0.6939655172413793)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:42<00:00,  2.35it/s, Epoch=43, LR=9.14e-6, Train_Loss=0.0051] \n",
      "100%|██████████| 58/58 [00:06<00:00,  9.27it/s, Epoch=43, LR=9.14e-6, Valid_Loss=0.533]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.878257\n",
      "mean:5.411159\n",
      "min:0.78189105\n",
      "acc:0.6810344827586207\n",
      "mse:0.60560346\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:42<00:00,  2.34it/s, Epoch=44, LR=8.15e-6, Train_Loss=0.00408]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.28it/s, Epoch=44, LR=8.15e-6, Valid_Loss=0.511]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.725077\n",
      "mean:5.40426\n",
      "min:0.6761482\n",
      "acc:0.6853448275862069\n",
      "mse:0.5711207\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:41<00:00,  2.36it/s, Epoch=45, LR=6.89e-6, Train_Loss=0.00377]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.28it/s, Epoch=45, LR=6.89e-6, Valid_Loss=0.506]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.651087\n",
      "mean:5.39356\n",
      "min:0.72989976\n",
      "acc:0.6982758620689655\n",
      "mse:0.58189654\n",
      "\u001b[34mValidation AUC Improved (0.6939655172413793 ---> 0.6982758620689655)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:41<00:00,  2.36it/s, Epoch=46, LR=5.5e-6, Train_Loss=0.00311]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.28it/s, Epoch=46, LR=5.5e-6, Valid_Loss=0.507]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.364519\n",
      "mean:5.375622\n",
      "min:0.8050852\n",
      "acc:0.6724137931034483\n",
      "mse:0.57758623\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:42<00:00,  2.35it/s, Epoch=47, LR=4.11e-6, Train_Loss=0.00272]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.26it/s, Epoch=47, LR=4.11e-6, Valid_Loss=0.505]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.426583\n",
      "mean:5.4182706\n",
      "min:0.8347771\n",
      "acc:0.6853448275862069\n",
      "mse:0.5840517\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:42<00:00,  2.34it/s, Epoch=48, LR=2.85e-6, Train_Loss=0.00238]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.26it/s, Epoch=48, LR=2.85e-6, Valid_Loss=0.504]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.508766\n",
      "mean:5.382793\n",
      "min:0.7352738\n",
      "acc:0.6788793103448276\n",
      "mse:0.5905172\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:42<00:00,  2.35it/s, Epoch=49, LR=1.86e-6, Train_Loss=0.00185]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.26it/s, Epoch=49, LR=1.86e-6, Valid_Loss=0.509]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.549832\n",
      "mean:5.40454\n",
      "min:0.73800915\n",
      "acc:0.6853448275862069\n",
      "mse:0.5840517\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:41<00:00,  2.36it/s, Epoch=50, LR=1.22e-6, Train_Loss=0.00187]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.29it/s, Epoch=50, LR=1.22e-6, Valid_Loss=0.509]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.59402\n",
      "mean:5.405826\n",
      "min:0.73553145\n",
      "acc:0.6853448275862069\n",
      "mse:0.5840517\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:41<00:00,  2.36it/s, Epoch=51, LR=1e-6, Train_Loss=0.00183]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.27it/s, Epoch=51, LR=1e-6, Valid_Loss=0.52] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.601886\n",
      "mean:5.3910384\n",
      "min:0.8035034\n",
      "acc:0.6875\n",
      "mse:0.58189654\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:42<00:00,  2.35it/s, Epoch=52, LR=1.22e-6, Train_Loss=0.00176]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.30it/s, Epoch=52, LR=1.22e-6, Valid_Loss=0.505]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.566528\n",
      "mean:5.4000907\n",
      "min:0.8183138\n",
      "acc:0.7004310344827587\n",
      "mse:0.5689655\n",
      "\u001b[34mValidation AUC Improved (0.6982758620689655 ---> 0.7004310344827587)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:41<00:00,  2.36it/s, Epoch=53, LR=1.86e-6, Train_Loss=0.00168]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.26it/s, Epoch=53, LR=1.86e-6, Valid_Loss=0.518]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.491789\n",
      "mean:5.4058323\n",
      "min:0.7803038\n",
      "acc:0.6831896551724138\n",
      "mse:0.5862069\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:41<00:00,  2.36it/s, Epoch=54, LR=2.85e-6, Train_Loss=0.00201]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.27it/s, Epoch=54, LR=2.85e-6, Valid_Loss=0.506]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.559272\n",
      "mean:5.3994036\n",
      "min:0.68903536\n",
      "acc:0.6918103448275862\n",
      "mse:0.57758623\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:41<00:00,  2.36it/s, Epoch=55, LR=4.11e-6, Train_Loss=0.00251]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.28it/s, Epoch=55, LR=4.11e-6, Valid_Loss=0.517]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.639782\n",
      "mean:5.3279934\n",
      "min:0.75026274\n",
      "acc:0.6810344827586207\n",
      "mse:0.57543105\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:48<00:00,  2.29it/s, Epoch=56, LR=5.5e-6, Train_Loss=0.00232]\n",
      "100%|██████████| 58/58 [00:06<00:00,  8.40it/s, Epoch=56, LR=5.5e-6, Valid_Loss=0.511]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.400195\n",
      "mean:5.4277487\n",
      "min:0.84430045\n",
      "acc:0.6745689655172413\n",
      "mse:0.5883621\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:41<00:00,  2.35it/s, Epoch=57, LR=6.89e-6, Train_Loss=0.00288]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.31it/s, Epoch=57, LR=6.89e-6, Valid_Loss=0.489]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.913636\n",
      "mean:5.453442\n",
      "min:0.711563\n",
      "acc:0.6961206896551724\n",
      "mse:0.55818963\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:41<00:00,  2.36it/s, Epoch=58, LR=8.15e-6, Train_Loss=0.00364]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.29it/s, Epoch=58, LR=8.15e-6, Valid_Loss=0.523]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.771317\n",
      "mean:5.428589\n",
      "min:0.77636397\n",
      "acc:0.6788793103448276\n",
      "mse:0.5905172\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:41<00:00,  2.36it/s, Epoch=59, LR=9.14e-6, Train_Loss=0.00364]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.31it/s, Epoch=59, LR=9.14e-6, Valid_Loss=0.523]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.7318125\n",
      "mean:5.500324\n",
      "min:0.833748\n",
      "acc:0.6767241379310345\n",
      "mse:0.5862069\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:42<00:00,  2.34it/s, Epoch=60, LR=9.78e-6, Train_Loss=0.00375]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.26it/s, Epoch=60, LR=9.78e-6, Valid_Loss=0.525]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.231847\n",
      "mean:5.3859386\n",
      "min:0.66239655\n",
      "acc:0.6875\n",
      "mse:0.5689655\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:41<00:00,  2.35it/s, Epoch=61, LR=1e-5, Train_Loss=0.00382]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.28it/s, Epoch=61, LR=1e-5, Valid_Loss=0.513]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.39965\n",
      "mean:5.4776773\n",
      "min:0.6964062\n",
      "acc:0.6810344827586207\n",
      "mse:0.5926724\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:42<00:00,  2.35it/s, Epoch=62, LR=9.78e-6, Train_Loss=0.00357]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.29it/s, Epoch=62, LR=9.78e-6, Valid_Loss=0.494]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.653167\n",
      "mean:5.366593\n",
      "min:0.77124596\n",
      "acc:0.6896551724137931\n",
      "mse:0.56681037\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:42<00:00,  2.35it/s, Epoch=63, LR=9.14e-6, Train_Loss=0.00325]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.28it/s, Epoch=63, LR=9.14e-6, Valid_Loss=0.503]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.635283\n",
      "mean:5.400283\n",
      "min:0.6951025\n",
      "acc:0.6982758620689655\n",
      "mse:0.5646552\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:41<00:00,  2.36it/s, Epoch=64, LR=8.15e-6, Train_Loss=0.0025] \n",
      "100%|██████████| 58/58 [00:06<00:00,  9.30it/s, Epoch=64, LR=8.15e-6, Valid_Loss=0.502]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.726285\n",
      "mean:5.376256\n",
      "min:0.76317513\n",
      "acc:0.7047413793103449\n",
      "mse:0.55172414\n",
      "\u001b[34mValidation AUC Improved (0.7004310344827587 ---> 0.7047413793103449)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:42<00:00,  2.35it/s, Epoch=65, LR=6.89e-6, Train_Loss=0.0023] \n",
      "100%|██████████| 58/58 [00:06<00:00,  9.28it/s, Epoch=65, LR=6.89e-6, Valid_Loss=0.494]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.667879\n",
      "mean:5.466436\n",
      "min:0.7646001\n",
      "acc:0.709051724137931\n",
      "mse:0.54741377\n",
      "\u001b[34mValidation AUC Improved (0.7047413793103449 ---> 0.709051724137931)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:42<00:00,  2.35it/s, Epoch=66, LR=5.5e-6, Train_Loss=0.00241]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.29it/s, Epoch=66, LR=5.5e-6, Valid_Loss=0.486]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.629258\n",
      "mean:5.461315\n",
      "min:0.730606\n",
      "acc:0.7025862068965517\n",
      "mse:0.55818963\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:42<00:00,  2.35it/s, Epoch=67, LR=4.11e-6, Train_Loss=0.00154]\n",
      "100%|██████████| 58/58 [00:06<00:00,  9.13it/s, Epoch=67, LR=4.11e-6, Valid_Loss=0.486]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.685568\n",
      "mean:5.425\n",
      "min:0.7635008\n",
      "acc:0.709051724137931\n",
      "mse:0.5538793\n",
      "\u001b[34mValidation AUC Improved (0.709051724137931 ---> 0.709051724137931)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:41<00:00,  2.36it/s, Epoch=68, LR=2.85e-6, Train_Loss=0.0014] \n",
      "100%|██████████| 58/58 [00:06<00:00,  9.29it/s, Epoch=68, LR=2.85e-6, Valid_Loss=0.486]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:11.654541\n",
      "mean:5.441823\n",
      "min:0.76965016\n",
      "acc:0.7047413793103449\n",
      "mse:0.54525864\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 130/522 [00:55<02:47,  2.34it/s, Epoch=69, LR=1.86e-6, Train_Loss=0.0019] "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "\n",
    "def fetch_scheduler(optimizer):\n",
    "    if CONFIG.scheduler == 'CosineAnnealingLR':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=CONFIG.T_max, eta_min=CONFIG.min_lr)\n",
    "    elif CONFIG.scheduler == 'CosineAnnealingWarmRestarts':\n",
    "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=CONFIG.T_0, T_mult=1, eta_min=CONFIG.min_lr)\n",
    "    elif CONFIG.scheduler == None:\n",
    "        return None\n",
    "        \n",
    "    return scheduler\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=CONFIG.learning_rate, weight_decay=CONFIG.weight_decay)\n",
    "scheduler = fetch_scheduler(optimizer)\n",
    "\n",
    "print(CONFIG.device)\n",
    "print(CONFIG.epochs)\n",
    "#test_img = np.stack(df_test['image'].values  , axis=0)\n",
    "#test_img = test_img * 1.0/255.0\n",
    "print(type(test_imgs))\n",
    "print(test_imgs.shape)\n",
    "print(type(test_age))\n",
    "print(\"#########\")\n",
    "print(type(train_imgs))\n",
    "print(train_imgs.shape)\n",
    "\n",
    "test_img = torch.from_numpy(test_imgs)\n",
    "print(\"test_img shape:\"+str( test_imgs.shape) )\n",
    "print(\"test_img[0].shape:\"+str( test_imgs[0].shape))\n",
    "#test_img.to(CONFIG.device)\n",
    "\n",
    "a_seed = CONFIG.KERAS_TRAIN_TEST_SEED #2021\n",
    "numberOfFolds = CONFIG.n_fold #5\n",
    "kfold = StratifiedKFold(n_splits=numberOfFolds, random_state=a_seed, shuffle=True)\n",
    "#for i in range(0,5):\n",
    "#CONFIG.epochs=5\n",
    "test_15 = pd.DataFrame()\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(train_imgs, train_age.tolist())):\n",
    "    #train_loader, valid_loader = prepare_data(fold=i)\n",
    "    ######## K-FOLD Start #################\n",
    "    train_imgs_new = train_imgs[train_idx]\n",
    "    train_age_new = train_age[train_idx]\n",
    "    val_imgs_new = train_imgs[val_idx]\n",
    "    val_age_new = train_age[val_idx]\n",
    "    \n",
    "    train_dataset = codDataset(train_imgs_new, train_age_new)\n",
    "    valid_dataset = codDataset(val_imgs_new, val_age_new)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CONFIG.train_batch_size, \n",
    "                              num_workers=0, shuffle=True, pin_memory=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG.valid_batch_size, \n",
    "                              num_workers=0, shuffle=False, pin_memory=True)\n",
    "    ######################### K-FOLD End #########################\n",
    "    model, history, best_model_wts = run(model, optimizer, scheduler, train_loader, valid_loader, fold)\n",
    "\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    with torch.no_grad():\n",
    "        PREDS_TEST  = []\n",
    "        \n",
    "        ceil_step = int(test_imgs.shape[0] / 25) + int(test_imgs.shape[0] % 25 > 0)\n",
    "        for i in range(0, ceil_step):\n",
    "            start_step = i * 25\n",
    "            preds = model( torch.Tensor(test_imgs[start_step:start_step+25]).to(CONFIG.device) )\n",
    "            preds = preds.cpu().detach().numpy()\n",
    "            preds = preds.flatten()\n",
    "            PREDS_TEST.extend(preds.tolist())\n",
    "            \n",
    "            if i == 0:\n",
    "                fig = plt.figure(figsize=(5, 5))\n",
    "                plt.subplots_adjust(hspace = 2.0)\n",
    "                #test_imgs.shape[0]\n",
    "                for j in range(0, 25):\n",
    "                    fig.add_subplot(5, 5, j+1)\n",
    "                    plt.imshow( test_imgs[j].transpose(1,2,0) )\n",
    "                    plt.title(f'{preds[j]:.2f} ,{test_age[j]}')\n",
    "                    plt.xticks([])\n",
    "                    plt.yticks([])\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "        print(\"max:\"+str(np.max( PREDS_TEST )))\n",
    "        print(\"mean:\"+str(np.mean( PREDS_TEST )))\n",
    "        print(\"min:\"+str(np.min( PREDS_TEST )))\n",
    "\n",
    "        ROUNDED_PREDS_TEST = np.asarray(PREDS_TEST).round().astype('int')\n",
    "        #print(ROUNDED_PREDS_TEST ) \n",
    "        #print(type(ROUNDED_PREDS_TEST))\n",
    "        #print(ROUNDED_PREDS_TEST.shape)\n",
    "\n",
    "        print(\"test mse:\"+str( mean_squared_error(PREDS_TEST, test_age) )) \n",
    "        print(\"test acc:\"+str( accuracy_score(ROUNDED_PREDS_TEST.tolist(), test_age.tolist() ) )) \n",
    "        print(\"PREDS TYPE:\"+str(type(PREDS_TEST)))\n",
    "        #print(PREDS_TEST.shape) ##list\n",
    "        #print(\"PREDS:\"+str(ROUNDED_PREDS_TEST))\n",
    "        #print(\"TRUE:\"+str(test_age))\n",
    "\n",
    "        del model\n",
    "        model = codModel(CONFIG.model_name)\n",
    "        model.to(CONFIG.device);\n",
    "        \n",
    "        optimizer = optim.Adam(model.parameters(), lr=CONFIG.learning_rate, weight_decay=CONFIG.weight_decay)\n",
    "        scheduler = fetch_scheduler(optimizer)\n",
    "        test_15[str(fold)] = PREDS_TEST\n",
    "        \n",
    "test_15.to_csv(CONFIG.ROOTDIR+'preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21f5d883",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
