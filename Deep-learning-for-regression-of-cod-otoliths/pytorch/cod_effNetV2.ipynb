{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8ec969d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image, ExifTags\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import compute_class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "import scipy\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img, ImageDataGenerator\n",
    "from tensorflow.keras.layers import Activation, Dense, GlobalAveragePooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "\n",
    "#salmon-scales\n",
    "#from train_util import read_images, load_xy, get_checkpoint_tensorboard, create_model_grayscale, get_fresh_weights, base_output, dense1_linear_output, train_validate_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaf8bc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (5.4.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.6/dist-packages (from plotly) (8.0.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from plotly) (1.15.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.10.0)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch) (0.8)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.7.4.3)\n",
      "Requirement already satisfied: loguru in /usr/local/lib/python3.6/dist-packages (0.5.3)\n",
      "Requirement already satisfied: aiocontextvars>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from loguru) (0.2.2)\n",
      "Requirement already satisfied: contextvars==2.4 in /usr/local/lib/python3.6/dist-packages (from aiocontextvars>=0.2.0->loguru) (2.4)\n",
      "Requirement already satisfied: immutables>=0.9 in /usr/local/lib/python3.6/dist-packages (from contextvars==2.4->aiocontextvars>=0.2.0->loguru) (0.16)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.6/dist-packages (from immutables>=0.9->contextvars==2.4->aiocontextvars>=0.2.0->loguru) (3.7.4.3)\n",
      "Requirement already satisfied: timm in /usr/local/lib/python3.6/dist-packages (0.4.12)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from timm) (0.11.1)\n",
      "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.6/dist-packages (from timm) (1.10.0)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->timm) (0.8)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->timm) (3.7.4.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision->timm) (1.19.5)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.6/dist-packages (from torchvision->timm) (8.4.0)\n",
      "Requirement already satisfied: albumentations in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from albumentations) (1.5.4)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from albumentations) (6.0)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.6/dist-packages (from albumentations) (0.17.2)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from albumentations) (4.5.4.60)\n",
      "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.6/dist-packages (from albumentations) (0.0.4)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from albumentations) (1.19.5)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from qudida>=0.0.4->albumentations) (0.24.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from qudida>=0.0.4->albumentations) (3.7.4.3)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16.1->albumentations) (2020.9.3)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16.1->albumentations) (8.4.0)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16.1->albumentations) (2.12.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16.1->albumentations) (1.1.1)\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16.1->albumentations) (2.5.1)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16.1->albumentations) (3.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (0.11.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (3.0.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.3.1)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.16.1->albumentations) (4.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.15.0)\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install plotly --user\n",
    "!pip install torch --user\n",
    "!pip install loguru --user\n",
    "!pip install timm --user #PyTorch Image Models\n",
    "!pip install albumentations  --user #augmentation\n",
    "!pip install colorama --user #color terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3ec8a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import amp\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import timm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from colorama import Fore\n",
    "b_ = Fore.BLUE\n",
    "\n",
    "from train_val_test_split import train_validate_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559189a4",
   "metadata": {},
   "source": [
    "### Train Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be13b22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/efficientnet.py\n",
    "# tf_efficientnetv2_s_in21k - input_size=(3, 300, 300), test_input_size=(3, 384, 384)\n",
    "# tf_efficientnetv2_m_in21k - input_size=(3, 384, 384), test_input_size=(3, 480, 480)\n",
    "# tf_efficientnetv2_l_in21k - input_size=(3, 384, 384), test_input_size=(3, 480, 480)\n",
    "# tf_efficientnetv2_xl_in21k -input_size=(3, 384, 384), test_input_size=(3, 512, 512)\n",
    "\n",
    "class CONFIG:\n",
    "    seed = 42\n",
    "    model_name = 'tf_efficientnetv2_xl_in21k' \n",
    "    train_batch_size = 8\n",
    "    valid_batch_size = 8\n",
    "    img_size = 384\n",
    "    val_img_size = 480\n",
    "    epochs = 25\n",
    "    learning_rate = 1e-5\n",
    "    min_lr = 1e-6\n",
    "    weight_decay = 1e-6\n",
    "    T_max = 10\n",
    "    scheduler = 'CosineAnnealingLR'\n",
    "    n_accumulate = 1\n",
    "    n_fold = 5\n",
    "    target_size = 1\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    debugging = False\n",
    "    which_exposure = \"min\"\n",
    "    CHANNELS = \"channels_first\"\n",
    "    \n",
    "def set_seed(seed = 42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "set_seed(CONFIG.seed)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ef2dc5",
   "metadata": {},
   "source": [
    "### Read files to Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69e05a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jpg_cods(config):\n",
    "    \"\"\"\n",
    "    reads a .jpg file in each folder in structure of folders\n",
    "    depending on light exposure in {min, middle, max}\n",
    "    returns tensor with images, and 1-1 correspondence with age\n",
    "    \"\"\"\n",
    "    df_cod = pd.DataFrame(columns=['age', 'image', 'path', 'light', 'ExposureTime'])\n",
    "\n",
    "    base_dir = '/gpfs/gpfs0/deep/data/Savannah_Professional_Practice2021_06_10_21/CodOtholiths-MachineLearning/Savannah_Professional_Practice'\n",
    "    base_dirs_posix = Path(base_dir)\n",
    "\n",
    "    error_count = 0\n",
    "    add_count = 0\n",
    "    for some_year_dir in base_dirs_posix.iterdir():\n",
    "        if config.debugging: # terminate quickly for testing\n",
    "            if add_count > 0:\n",
    "                break\n",
    "\n",
    "        if not os.path.isdir(some_year_dir) or \"Extra\" in str(some_year_dir): #dont read files in root dir, or folder \"Extra\"\n",
    "            continue\n",
    "\n",
    "        # dir structure: /year/station_number/cod_img_by_age/6 jpeg images of one fish\n",
    "        stat_nos = [name for name in os.listdir(some_year_dir) if os.path.isdir(os.path.join(some_year_dir, name))]\n",
    "        for i in range(0, len(stat_nos)):\n",
    "            cod_path = os.path.join(some_year_dir, stat_nos[i])\n",
    "            yr_station_codage_path = [os.path.join(cod_path, n) for n in os.listdir(cod_path)\n",
    "                                      if os.path.isdir(os.path.join(cod_path, n))]\n",
    "            cod_age = [n for n in os.listdir(cod_path)\n",
    "                       if os.path.isdir(os.path.join(cod_path, n))]\n",
    "\n",
    "            assert len(yr_station_codage_path) == len(cod_age)\n",
    "            for j in range(0, len(yr_station_codage_path)):\n",
    "                # print(onlyfiles)\n",
    "                onlyfiles = [f for f in os.listdir(yr_station_codage_path[j])\n",
    "                             if os.path.isfile(os.path.join(yr_station_codage_path[j], f))]\n",
    "\n",
    "                if len(onlyfiles) != 6:\n",
    "                    # print(str(len(onlyfiles)) + '\\t' + str( yr_station_codage_path[j] ) + \"\\t\" +'\\t'.join(map(str,onlyfiles)))\n",
    "                    error_count += 1\n",
    "                else:\n",
    "                    full_path = [os.path.join(yr_station_codage_path[j], f)\n",
    "                                 for f in os.listdir(yr_station_codage_path[j])\n",
    "                                 if os.path.isfile(os.path.join(yr_station_codage_path[j], f))]\n",
    "\n",
    "                    begin_age = cod_age[j].lower().find('age')\n",
    "                    age = cod_age[j][begin_age + 3:begin_age + 5]\n",
    "                    try:\n",
    "                        age = int(age)\n",
    "                    except ValueError:\n",
    "                        age = 0\n",
    "                        continue\n",
    "\n",
    "                    full_path.sort()\n",
    "                    exposures_set = set()\n",
    "                    exposures_list = []\n",
    "                    for k in range(0, len(full_path)):\n",
    "                        img = Image.open(full_path[k])\n",
    "                        exif = {ExifTags.TAGS[k]: v for k, v in img._getexif().items() if k in ExifTags.TAGS}\n",
    "                        exposures_set.add(exif['ExposureTime'])  # requires: 3 unique exposures,\n",
    "                        exposures_list.append(exif['ExposureTime'])  # requires: 6 exposures total - rotated 180 deg\n",
    "\n",
    "                    if len(exposures_list) == 6 and len(exposures_set) == 3 and age not in [0, 14, 15, 16, 17]:\n",
    "                        expo_args = np.argsort(exposures_list).tolist()\n",
    "\n",
    "                        # print( \"exposures_list\"+str(exposures_list) )\n",
    "                        # print(\" argsort: \"+str(expo_args) )\n",
    "                        # if expo_args != [1, 4, 0, 3, 2, 5]:\n",
    "                        # print( \"exposures_list\"+str(exposures_list) )\n",
    "                        # print(\" argsort: \"+str(expo_args) )\n",
    "\n",
    "                        index_to_exposed_jpg = -1\n",
    "                        light_value = -1\n",
    "                        if config.which_exposure == 'min':\n",
    "                            index_to_exposed_jpg = 0\n",
    "                            light_value = 1\n",
    "                        if config.which_exposure == 'middle':\n",
    "                            index_to_exposed_jpg = 2\n",
    "                            light_value = 2\n",
    "\n",
    "                        if config.which_exposure == 'max':\n",
    "                            index_to_exposed_jpg = 4\n",
    "                            light_value = 3\n",
    "\n",
    "                        pil_img = load_img(full_path[expo_args[ index_to_exposed_jpg ]], target_size=(config.img_size, config.img_size))\n",
    "                        array_img = img_to_array(pil_img, data_format=config.CHANNELS)\n",
    "                        add_count += 1\n",
    "                        #print(\"fp:\"+str(full_path[expo_args[ index_to_exposed_jpg ]]) )\n",
    "                        df_cod = df_cod.append({\n",
    "                            'age': age,\n",
    "                            'image': array_img,\n",
    "                            'path': full_path[expo_args[ index_to_exposed_jpg ]],\n",
    "                            'light': light_value,\n",
    "                            'ExposureTime': exposures_list[expo_args[ index_to_exposed_jpg ]]}, ignore_index=True)\n",
    "\n",
    "    print(\"error_count:\" + str(error_count))\n",
    "    print(\"add_count:\" + str(add_count))\n",
    "    return df_cod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e5c01d",
   "metadata": {},
   "source": [
    "### Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "083e5863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error_count:222\n",
      "add_count:5153\n",
      "len age:5153\n"
     ]
    }
   ],
   "source": [
    "B4_input_shape = (3, CONFIG.img_size, CONFIG.img_size)  \n",
    "\n",
    "df = read_jpg_cods( CONFIG ) #5316 #5110\n",
    "# 5110 images, after updating folder 2015: len age:5153\n",
    "\n",
    "print(\"len age:\"+str( len(df.age) ) ) #len age:5090, error_count:205"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1aec12",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71b13f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5090, 3, 300, 300)\n",
      "len age:5090\n"
     ]
    }
   ],
   "source": [
    "#df.age[5089]\n",
    "\n",
    "tmp = np.asarray( df.image )\n",
    "a = np.stack(tmp, axis=0).shape #(5090, 3, 300, 300)\n",
    "print(a)\n",
    "\n",
    "print(\"len age:\"+str( len(df.age) ) ) #len age:5090"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68187c02",
   "metadata": {},
   "source": [
    "### Test Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6af06b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 384, 384)\n",
      "(3, 300, 300)\n",
      "(3, 300, 300)\n",
      "(3, 300, 300)\n",
      "(3, 300, 300)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "pil_img = load_img(df.path[0], target_size=(300,300), grayscale=False)\n",
    "array_img = img_to_array(pil_img, data_format='channels_first')\n",
    "image = array_img\n",
    "\n",
    "print(B4_input_shape)\n",
    "#image = np.load(df.path[0],allow_pickle=True).astype(np.float32)\n",
    "print(image.shape)\n",
    "image = (image - image.mean(axis=(1,2), keepdims=True)) / image.std(axis=(1,2), keepdims=True)\n",
    "print(image.shape)\n",
    "#image = np.vstack(image).transpose((1, 0))\n",
    "print(image.shape)\n",
    "label = torch.tensor(df.age[0]).float()\n",
    "print(image.shape) #(3, 144400)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e792b0",
   "metadata": {},
   "source": [
    "### Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a503ff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ceb841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class codDataset(Dataset):\n",
    "    def __init__(self, df, transforms=None):\n",
    "        self.df = df\n",
    "        self.file_names = df['path'].values\n",
    "        self.labels = df['age'].values\n",
    "        self.image = np.stack( df['image'].values , axis=0) # make 4D-array (num_imgs, channels, width,height)\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        #print(\"loading filename:\"+str(self.file_names[index]))\n",
    "        #image = np.load(self.file_names[index]).astype(np.float32)\n",
    "        #B4_input_shape = (380, 380, 3)\n",
    "        #pil_img = load_img(df.path[0], target_size=B4_input_shape, grayscale=False)\n",
    "        #image = img_to_array(pil_img, data_format='channels_last')\n",
    "        \n",
    "        image = self.df.image[index] * 1.0/255.0\n",
    "        #image = (image - image.mean( axis=(1,2), keepdims=True )) / image.std(axis=(1,2), keepdims=True)\n",
    "        label = torch.tensor(self.labels[index]).float()\n",
    "        \n",
    "        #if self.transforms:\n",
    "        #image = self.transforms(image=image)[\"image\"]\n",
    "            \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607e9500",
   "metadata": {},
   "source": [
    "### Test standardscalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97c1793b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 4, 2: 4, 3: 4, 4: 4, 5: 4, 6: 4}\n",
      "(30,)\n",
      "[-1.46385011 -0.87831007 -0.29277002  0.29277002  0.87831007  1.46385011\n",
      " -1.46385011 -0.87831007 -0.29277002  0.29277002  0.87831007  1.46385011\n",
      " -1.46385011 -0.87831007 -0.29277002  0.29277002  0.87831007  1.46385011\n",
      " -1.46385011 -0.87831007 -0.29277002  0.29277002  0.87831007  1.46385011\n",
      " -1.46385011 -0.87831007 -0.29277002  0.29277002  0.87831007  1.46385011]\n",
      "{-1.4638501094227998: 4, -0.8783100656536799: 4, -0.29277002188455997: 4, 0.29277002188455997: 4, 0.8783100656536799: 4, 1.4638501094227998: 4}\n",
      "(30,)\n",
      "[-1.46385011 -0.87831007 -0.29277002  0.29277002  0.87831007  1.46385011\n",
      " -1.46385011 -0.87831007 -0.29277002  0.29277002  0.87831007  1.46385011\n",
      " -1.46385011 -0.87831007 -0.29277002  0.29277002  0.87831007  1.46385011\n",
      " -1.46385011 -0.87831007 -0.29277002  0.29277002  0.87831007  1.46385011\n",
      " -1.46385011 -0.87831007 -0.29277002  0.29277002  0.87831007  1.46385011]\n",
      "{-1.4638501094227998: 4, -0.8783100656536799: 4, -0.29277002188455997: 4, 0.29277002188455997: 4, 0.8783100656536799: 4, 1.4638501094227998: 4}\n",
      "(30,)\n",
      "[-1.46385011 -0.87831007 -0.29277002  0.29277002  0.87831007  1.46385011\n",
      " -1.46385011 -0.87831007 -0.29277002  0.29277002  0.87831007  1.46385011\n",
      " -1.46385011 -0.87831007 -0.29277002  0.29277002  0.87831007  1.46385011\n",
      " -1.46385011 -0.87831007 -0.29277002  0.29277002  0.87831007  1.46385011\n",
      " -1.46385011 -0.87831007 -0.29277002  0.29277002  0.87831007  1.46385011]\n",
      "{-1.4638501094227998: 4, -0.8783100656536799: 4, -0.29277002188455997: 4, 0.29277002188455997: 4, 0.8783100656536799: 4, 1.4638501094227998: 4}\n",
      "(30,)\n",
      "[-1.46385011 -0.87831007 -0.29277002  0.29277002  0.87831007  1.46385011\n",
      " -1.46385011 -0.87831007 -0.29277002  0.29277002  0.87831007  1.46385011\n",
      " -1.46385011 -0.87831007 -0.29277002  0.29277002  0.87831007  1.46385011\n",
      " -1.46385011 -0.87831007 -0.29277002  0.29277002  0.87831007  1.46385011\n",
      " -1.46385011 -0.87831007 -0.29277002  0.29277002  0.87831007  1.46385011]\n",
      "{-1.4638501094227998: 4, -0.8783100656536799: 4, -0.29277002188455997: 4, 0.29277002188455997: 4, 0.8783100656536799: 4, 1.4638501094227998: 4}\n",
      "(30,)\n",
      "[-1.46385011 -0.87831007 -0.29277002  0.29277002  0.87831007  1.46385011\n",
      " -1.46385011 -0.87831007 -0.29277002  0.29277002  0.87831007  1.46385011\n",
      " -1.46385011 -0.87831007 -0.29277002  0.29277002  0.87831007  1.46385011\n",
      " -1.46385011 -0.87831007 -0.29277002  0.29277002  0.87831007  1.46385011\n",
      " -1.46385011 -0.87831007 -0.29277002  0.29277002  0.87831007  1.46385011]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n    print(\"min/max train_age:\"+str(np.min(np.asarray(train_age)))+ \", \"+ str(np.max(np.asarray(train_age))) )\\n    print(\"min/max test_age:\"+str(np.min(np.asarray(test_age)))+ \", \"+ str(np.max(np.asarray(test_age))) )\\n    print(\"train_age shape:\"+str(train_age.shape))\\n    print(\"test_age shape:\"+str(test_age.shape))\\n    print(\"age.shape:\"+str(age.shape))\\n\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "age = np.asarray([1,2,3,4,5,6,1,2,3,4,5,6,1,2,3,4,5,6,1,2,3,4,5,6,1,2,3,4,5,6])\n",
    "\n",
    "train_age = []\n",
    "test_age = [] #<class 'list'>\n",
    "for i in range(0, len(age)):\n",
    "    train_age.append(age[i])\n",
    "    test_age.append(age[i])\n",
    "\n",
    "train_age = np.asarray(train_age)\n",
    "\n",
    "#kfold = KFold(n_splits = 5, random_state = 2021, shuffle = True)\n",
    "#for fold, (trn_ind, val_ind) in enumerate(kfold.split(train_age)):\n",
    "\n",
    "kfold = StratifiedKFold(n_splits = 5)\n",
    "for fold, (trn_ind, val_ind) in enumerate(kfold.split(train_age, train_age)):\n",
    "    train_idx = trn_ind\n",
    "    val_idx = val_ind\n",
    "\n",
    "    unique, counts = np.unique( train_age[train_idx], return_counts=True)\n",
    "    print( dict(zip(unique, counts)) )\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    #train_age = np.asarray( train_age ).reshape(-1,1)  #(30,1) without reshape (30,)\n",
    "    scaler.fit( train_age.reshape(-1,1) )\n",
    "    train_age = scaler.transform( train_age.reshape(-1,1) ).squeeze()\n",
    "    print(train_age.shape)\n",
    "\n",
    "    test_age = np.asarray( test_age ).reshape(-1,1) \n",
    "    test_age = scaler.transform( test_age )\n",
    "    print(test_age.squeeze())\n",
    "\n",
    "    test_age = np.vstack(test_age)\n",
    "    age = np.vstack(age)\n",
    "\n",
    "\"\"\"\n",
    "    print(\"min/max train_age:\"+str(np.min(np.asarray(train_age)))+ \", \"+ str(np.max(np.asarray(train_age))) )\n",
    "    print(\"min/max test_age:\"+str(np.min(np.asarray(test_age)))+ \", \"+ str(np.max(np.asarray(test_age))) )\n",
    "    print(\"train_age shape:\"+str(train_age.shape))\n",
    "    print(\"test_age shape:\"+str(test_age.shape))\n",
    "    print(\"age.shape:\"+str(age.shape))\n",
    "\n",
    "\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96789f86",
   "metadata": {},
   "source": [
    "### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a6bbfa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/albumentations/augmentations/transforms.py:691: FutureWarning:\n",
      "\n",
      "This class has been deprecated. Please use CoarseDropout\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_transforms = {\n",
    "    \"train\": A.Compose([\n",
    "        A.Resize(CONFIG.img_size, CONFIG.img_size),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.ShiftScaleRotate(shift_limit=0.1, \n",
    "                           scale_limit=0.15, \n",
    "                           rotate_limit=360, \n",
    "                           p=0.5),\n",
    "        A.CoarseDropout(p=0.5),\n",
    "        A.Cutout(p=0.5),\n",
    "        ToTensorV2()], p=1.),\n",
    "    \n",
    "    \"valid\": A.Compose([\n",
    "        A.Resize(CONFIG.img_size, CONFIG.img_size),\n",
    "        ToTensorV2()], p=1.)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e876af74",
   "metadata": {},
   "source": [
    "### Cod Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c561efd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class codModel(nn.Module):\n",
    "\n",
    "    def __init__(self, model_name, pretrained=True):\n",
    "        super(codModel, self).__init__()\n",
    "        self.model = timm.create_model('tf_efficientnetv2_l_in21k', pretrained=pretrained, in_chans=3, num_classes=1) #model_name\n",
    "        self.n_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Linear(self.n_features, CONFIG.target_size)\n",
    "        #lastLayer = nn.Sequential(nn.Linear(self.n_features, 256),\n",
    "        #      nn.LeakyReLU(),\n",
    "        #      nn.Linear(256, 32),\n",
    "        #      nn.LeakyReLU(),\n",
    "        #      nn.Linear(32, CONFIG.target_size))\n",
    "        #self.model.classifier = lastLayer\n",
    "        #print(\"model self:\"+str(self.model.classifier))\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.model(x)\n",
    "        return output\n",
    "    \n",
    "model = codModel(CONFIG.model_name)\n",
    "model.to(CONFIG.device);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf070fd",
   "metadata": {},
   "source": [
    "### debug output - linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "016d28aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1280, out_features=21843, bias=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = timm.create_model(CONFIG.model_name, pretrained=True, in_chans=3)\n",
    "#n_features = model.classifier.in_features\n",
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "b92a242e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2254]], grad_fn=<AddmmBackward0>)\n",
      "tensor(113.8671, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 0, loss 113.86708068847656\n",
      "tensor(9.3376, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 1, loss 9.337577819824219\n",
      "tensor(0.8109, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 2, loss 0.8108803629875183\n",
      "tensor(0.1148, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 3, loss 0.1148345097899437\n",
      "tensor(0.0575, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 4, loss 0.05751663073897362\n",
      "tensor(0.0523, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 5, loss 0.052303723990917206\n",
      "tensor(0.0513, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 6, loss 0.05134684965014458\n",
      "tensor(0.0507, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 7, loss 0.05074301362037659\n",
      "tensor(0.0502, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 8, loss 0.05017391964793205\n",
      "tensor(0.0496, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 9, loss 0.04961342364549637\n",
      "tensor(0.0491, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 10, loss 0.04905945807695389\n",
      "tensor(0.0485, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 11, loss 0.04851153492927551\n",
      "tensor(0.0480, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 12, loss 0.04796981438994408\n",
      "tensor(0.0474, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 13, loss 0.04743416979908943\n",
      "tensor(0.0469, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 14, loss 0.0469045490026474\n",
      "tensor(0.0464, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 15, loss 0.0463806577026844\n",
      "tensor(0.0459, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 16, loss 0.045862745493650436\n",
      "tensor(0.0454, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 17, loss 0.04535068944096565\n",
      "tensor(0.0448, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 18, loss 0.04484418034553528\n",
      "tensor(0.0443, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 19, loss 0.04434340074658394\n",
      "tensor(0.0438, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 20, loss 0.043848250061273575\n",
      "tensor(0.0434, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 21, loss 0.043358590453863144\n",
      "tensor(0.0429, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 22, loss 0.04287440702319145\n",
      "tensor(0.0424, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 23, loss 0.042395614087581635\n",
      "tensor(0.0419, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 24, loss 0.0419221930205822\n",
      "tensor(0.0415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 25, loss 0.04145412519574165\n",
      "tensor(0.0410, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 26, loss 0.040991198271512985\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 27, loss 0.04053341597318649\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 28, loss 0.04008081182837486\n",
      "tensor(0.0396, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 29, loss 0.03963322564959526\n",
      "tensor(0.0392, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 30, loss 0.0391906201839447\n",
      "tensor(0.0388, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 31, loss 0.038753025233745575\n",
      "tensor(0.0383, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 32, loss 0.03832024708390236\n",
      "tensor(0.0379, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 33, loss 0.03789238631725311\n",
      "tensor(0.0375, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 34, loss 0.03746924549341202\n",
      "tensor(0.0371, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 35, loss 0.03705083206295967\n",
      "tensor(0.0366, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 36, loss 0.0366370864212513\n",
      "tensor(0.0362, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 37, loss 0.03622789680957794\n",
      "tensor(0.0358, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 38, loss 0.035823408514261246\n",
      "tensor(0.0354, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 39, loss 0.03542335703969002\n",
      "tensor(0.0350, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 40, loss 0.03502778336405754\n",
      "tensor(0.0346, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 41, loss 0.03463662788271904\n",
      "tensor(0.0342, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 42, loss 0.03424987941980362\n",
      "tensor(0.0339, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 43, loss 0.03386741131544113\n",
      "tensor(0.0335, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 44, loss 0.033489204943180084\n",
      "tensor(0.0331, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 45, loss 0.03311522677540779\n",
      "tensor(0.0327, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 46, loss 0.032745473086833954\n",
      "tensor(0.0324, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 47, loss 0.03237975761294365\n",
      "tensor(0.0320, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 48, loss 0.03201821446418762\n",
      "tensor(0.0317, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 49, loss 0.03166068345308304\n",
      "tensor(0.0313, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 50, loss 0.03130710870027542\n",
      "tensor(0.0310, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 51, loss 0.030957475304603577\n",
      "tensor(0.0306, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 52, loss 0.030611783266067505\n",
      "tensor(0.0303, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 53, loss 0.030269959941506386\n",
      "tensor(0.0299, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 54, loss 0.02993195503950119\n",
      "tensor(0.0296, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 55, loss 0.029597703367471695\n",
      "tensor(0.0293, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 56, loss 0.0292672012001276\n",
      "tensor(0.0289, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 57, loss 0.028940364718437195\n",
      "tensor(0.0286, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 58, loss 0.028617190197110176\n",
      "tensor(0.0283, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 59, loss 0.028297649696469307\n",
      "tensor(0.0280, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 60, loss 0.027981655672192574\n",
      "tensor(0.0277, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 61, loss 0.027669208124279976\n",
      "tensor(0.0274, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 62, loss 0.027360187843441963\n",
      "tensor(0.0271, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 63, loss 0.02705467864871025\n",
      "tensor(0.0268, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 64, loss 0.026752565056085587\n",
      "tensor(0.0265, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 65, loss 0.026453809812664986\n",
      "tensor(0.0262, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 66, loss 0.026158422231674194\n",
      "tensor(0.0259, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 67, loss 0.02586628682911396\n",
      "tensor(0.0256, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 68, loss 0.02557741105556488\n",
      "tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 69, loss 0.02529189921915531\n",
      "tensor(0.0250, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 70, loss 0.02500937320291996\n",
      "tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 71, loss 0.024730144068598747\n",
      "tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 72, loss 0.02445400319993496\n",
      "tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 73, loss 0.024180924519896507\n",
      "tensor(0.0239, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 74, loss 0.023910915479063988\n",
      "tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 75, loss 0.023643920198082924\n",
      "tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 76, loss 0.023379841819405556\n",
      "tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 77, loss 0.023118779063224792\n",
      "tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 78, loss 0.022860584780573845\n",
      "tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 79, loss 0.02260533906519413\n",
      "tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 80, loss 0.02235288918018341\n",
      "tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 81, loss 0.02210327982902527\n",
      "tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 82, loss 0.02185644954442978\n",
      "tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 83, loss 0.021612390875816345\n",
      "tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 84, loss 0.02137102745473385\n",
      "tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 85, loss 0.02113235741853714\n",
      "tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 86, loss 0.020896432921290398\n",
      "tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 87, loss 0.020663073286414146\n",
      "tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 88, loss 0.02043233811855316\n",
      "tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 89, loss 0.02020418457686901\n",
      "tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 90, loss 0.019978519529104233\n",
      "tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 91, loss 0.019755426794290543\n",
      "tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 92, loss 0.019534841179847717\n",
      "tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 93, loss 0.019316690042614937\n",
      "tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 94, loss 0.01910095103085041\n",
      "tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 95, loss 0.018887674435973167\n",
      "tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 96, loss 0.01867678575217724\n",
      "tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 97, loss 0.018468230962753296\n",
      "tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 98, loss 0.018261980265378952\n",
      "tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 99, loss 0.01805802993476391\n",
      "[[ 0.7500255]\n",
      " [ 2.786024 ]\n",
      " [ 4.8220224]\n",
      " [ 6.8580213]\n",
      " [ 8.89402  ]\n",
      " [10.930018 ]\n",
      " [12.966017 ]\n",
      " [15.002016 ]\n",
      " [17.038013 ]\n",
      " [19.074013 ]\n",
      " [21.110012 ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "m = nn.Linear(128, 1) \n",
    "input = torch.randn(1, 128 ) \n",
    "output = m(input)\n",
    "print(output)\n",
    "################\n",
    "# create dummy data for training\n",
    "x_values = [i for i in range(11)]\n",
    "x_train = np.array(x_values, dtype=np.float32)\n",
    "x_train = x_train.reshape(-1, 1)\n",
    "\n",
    "y_values = [2*i + 1 for i in x_values]\n",
    "y_train = np.array(y_values, dtype=np.float32)\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "class linearRegression(torch.nn.Module):\n",
    "    def __init__(self, inputSize, outputSize):\n",
    "        super(linearRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(inputSize, outputSize)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "    \n",
    "inputDim = 1        # takes variable 'x' \n",
    "outputDim = 1       # takes variable 'y'\n",
    "learningRate = 0.01 \n",
    "epochs = 100\n",
    "\n",
    "model = linearRegression(inputDim, outputDim)\n",
    "##### For GPU #######\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "    \n",
    "criterion = torch.nn.MSELoss() \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Converting inputs and labels to Variable\n",
    "    if torch.cuda.is_available():\n",
    "        inputs = Variable(torch.from_numpy(x_train).cuda())\n",
    "        labels = Variable(torch.from_numpy(y_train).cuda())\n",
    "    else:\n",
    "        inputs = Variable(torch.from_numpy(x_train))\n",
    "        labels = Variable(torch.from_numpy(y_train))\n",
    "\n",
    "    # Clear gradient buffers because we don't want any gradient from previous epoch to carry forward, dont want to cummulate gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # get output from the model, given the inputs\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # get loss for the predicted output\n",
    "    loss = criterion(outputs, labels)\n",
    "    print(loss)\n",
    "    # get gradients w.r.t to parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    print('epoch {}, loss {}'.format(epoch, loss.item()))\n",
    "    \n",
    "with torch.no_grad(): # we don't need gradients in the testing phase\n",
    "    if torch.cuda.is_available():\n",
    "        predicted = model(Variable(torch.from_numpy(x_train).cuda())).cpu().data.numpy()\n",
    "    else:\n",
    "        predicted = model(Variable(torch.from_numpy(x_train))).data.numpy()\n",
    "    print(predicted)\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(x_train, y_train, 'go', label='True data', alpha=0.5)\n",
    "plt.plot(x_train, predicted, '--', label='Predictions', alpha=0.5)\n",
    "plt.legend(loc='best')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca673f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "        Conv2dSame-1         [-1, 32, 192, 192]             864\n",
      "       BatchNorm2d-2         [-1, 32, 192, 192]              64\n",
      "              SiLU-3         [-1, 32, 192, 192]               0\n",
      "            Conv2d-4         [-1, 32, 192, 192]           9,216\n",
      "       BatchNorm2d-5         [-1, 32, 192, 192]              64\n",
      "              SiLU-6         [-1, 32, 192, 192]               0\n",
      "         ConvBnAct-7         [-1, 32, 192, 192]               0\n",
      "            Conv2d-8         [-1, 32, 192, 192]           9,216\n",
      "       BatchNorm2d-9         [-1, 32, 192, 192]              64\n",
      "             SiLU-10         [-1, 32, 192, 192]               0\n",
      "        ConvBnAct-11         [-1, 32, 192, 192]               0\n",
      "           Conv2d-12         [-1, 32, 192, 192]           9,216\n",
      "      BatchNorm2d-13         [-1, 32, 192, 192]              64\n",
      "             SiLU-14         [-1, 32, 192, 192]               0\n",
      "        ConvBnAct-15         [-1, 32, 192, 192]               0\n",
      "           Conv2d-16         [-1, 32, 192, 192]           9,216\n",
      "      BatchNorm2d-17         [-1, 32, 192, 192]              64\n",
      "             SiLU-18         [-1, 32, 192, 192]               0\n",
      "        ConvBnAct-19         [-1, 32, 192, 192]               0\n",
      "       Conv2dSame-20          [-1, 128, 96, 96]          36,864\n",
      "      BatchNorm2d-21          [-1, 128, 96, 96]             256\n",
      "             SiLU-22          [-1, 128, 96, 96]               0\n",
      "         Identity-23          [-1, 128, 96, 96]               0\n",
      "           Conv2d-24           [-1, 64, 96, 96]           8,192\n",
      "      BatchNorm2d-25           [-1, 64, 96, 96]             128\n",
      "     EdgeResidual-26           [-1, 64, 96, 96]               0\n",
      "           Conv2d-27          [-1, 256, 96, 96]         147,456\n",
      "      BatchNorm2d-28          [-1, 256, 96, 96]             512\n",
      "             SiLU-29          [-1, 256, 96, 96]               0\n",
      "         Identity-30          [-1, 256, 96, 96]               0\n",
      "           Conv2d-31           [-1, 64, 96, 96]          16,384\n",
      "      BatchNorm2d-32           [-1, 64, 96, 96]             128\n",
      "     EdgeResidual-33           [-1, 64, 96, 96]               0\n",
      "           Conv2d-34          [-1, 256, 96, 96]         147,456\n",
      "      BatchNorm2d-35          [-1, 256, 96, 96]             512\n",
      "             SiLU-36          [-1, 256, 96, 96]               0\n",
      "         Identity-37          [-1, 256, 96, 96]               0\n",
      "           Conv2d-38           [-1, 64, 96, 96]          16,384\n",
      "      BatchNorm2d-39           [-1, 64, 96, 96]             128\n",
      "     EdgeResidual-40           [-1, 64, 96, 96]               0\n",
      "           Conv2d-41          [-1, 256, 96, 96]         147,456\n",
      "      BatchNorm2d-42          [-1, 256, 96, 96]             512\n",
      "             SiLU-43          [-1, 256, 96, 96]               0\n",
      "         Identity-44          [-1, 256, 96, 96]               0\n",
      "           Conv2d-45           [-1, 64, 96, 96]          16,384\n",
      "      BatchNorm2d-46           [-1, 64, 96, 96]             128\n",
      "     EdgeResidual-47           [-1, 64, 96, 96]               0\n",
      "           Conv2d-48          [-1, 256, 96, 96]         147,456\n",
      "      BatchNorm2d-49          [-1, 256, 96, 96]             512\n",
      "             SiLU-50          [-1, 256, 96, 96]               0\n",
      "         Identity-51          [-1, 256, 96, 96]               0\n",
      "           Conv2d-52           [-1, 64, 96, 96]          16,384\n",
      "      BatchNorm2d-53           [-1, 64, 96, 96]             128\n",
      "     EdgeResidual-54           [-1, 64, 96, 96]               0\n",
      "           Conv2d-55          [-1, 256, 96, 96]         147,456\n",
      "      BatchNorm2d-56          [-1, 256, 96, 96]             512\n",
      "             SiLU-57          [-1, 256, 96, 96]               0\n",
      "         Identity-58          [-1, 256, 96, 96]               0\n",
      "           Conv2d-59           [-1, 64, 96, 96]          16,384\n",
      "      BatchNorm2d-60           [-1, 64, 96, 96]             128\n",
      "     EdgeResidual-61           [-1, 64, 96, 96]               0\n",
      "           Conv2d-62          [-1, 256, 96, 96]         147,456\n",
      "      BatchNorm2d-63          [-1, 256, 96, 96]             512\n",
      "             SiLU-64          [-1, 256, 96, 96]               0\n",
      "         Identity-65          [-1, 256, 96, 96]               0\n",
      "           Conv2d-66           [-1, 64, 96, 96]          16,384\n",
      "      BatchNorm2d-67           [-1, 64, 96, 96]             128\n",
      "     EdgeResidual-68           [-1, 64, 96, 96]               0\n",
      "       Conv2dSame-69          [-1, 256, 48, 48]         147,456\n",
      "      BatchNorm2d-70          [-1, 256, 48, 48]             512\n",
      "             SiLU-71          [-1, 256, 48, 48]               0\n",
      "         Identity-72          [-1, 256, 48, 48]               0\n",
      "           Conv2d-73           [-1, 96, 48, 48]          24,576\n",
      "      BatchNorm2d-74           [-1, 96, 48, 48]             192\n",
      "     EdgeResidual-75           [-1, 96, 48, 48]               0\n",
      "           Conv2d-76          [-1, 384, 48, 48]         331,776\n",
      "      BatchNorm2d-77          [-1, 384, 48, 48]             768\n",
      "             SiLU-78          [-1, 384, 48, 48]               0\n",
      "         Identity-79          [-1, 384, 48, 48]               0\n",
      "           Conv2d-80           [-1, 96, 48, 48]          36,864\n",
      "      BatchNorm2d-81           [-1, 96, 48, 48]             192\n",
      "     EdgeResidual-82           [-1, 96, 48, 48]               0\n",
      "           Conv2d-83          [-1, 384, 48, 48]         331,776\n",
      "      BatchNorm2d-84          [-1, 384, 48, 48]             768\n",
      "             SiLU-85          [-1, 384, 48, 48]               0\n",
      "         Identity-86          [-1, 384, 48, 48]               0\n",
      "           Conv2d-87           [-1, 96, 48, 48]          36,864\n",
      "      BatchNorm2d-88           [-1, 96, 48, 48]             192\n",
      "     EdgeResidual-89           [-1, 96, 48, 48]               0\n",
      "           Conv2d-90          [-1, 384, 48, 48]         331,776\n",
      "      BatchNorm2d-91          [-1, 384, 48, 48]             768\n",
      "             SiLU-92          [-1, 384, 48, 48]               0\n",
      "         Identity-93          [-1, 384, 48, 48]               0\n",
      "           Conv2d-94           [-1, 96, 48, 48]          36,864\n",
      "      BatchNorm2d-95           [-1, 96, 48, 48]             192\n",
      "     EdgeResidual-96           [-1, 96, 48, 48]               0\n",
      "           Conv2d-97          [-1, 384, 48, 48]         331,776\n",
      "      BatchNorm2d-98          [-1, 384, 48, 48]             768\n",
      "             SiLU-99          [-1, 384, 48, 48]               0\n",
      "        Identity-100          [-1, 384, 48, 48]               0\n",
      "          Conv2d-101           [-1, 96, 48, 48]          36,864\n",
      "     BatchNorm2d-102           [-1, 96, 48, 48]             192\n",
      "    EdgeResidual-103           [-1, 96, 48, 48]               0\n",
      "          Conv2d-104          [-1, 384, 48, 48]         331,776\n",
      "     BatchNorm2d-105          [-1, 384, 48, 48]             768\n",
      "            SiLU-106          [-1, 384, 48, 48]               0\n",
      "        Identity-107          [-1, 384, 48, 48]               0\n",
      "          Conv2d-108           [-1, 96, 48, 48]          36,864\n",
      "     BatchNorm2d-109           [-1, 96, 48, 48]             192\n",
      "    EdgeResidual-110           [-1, 96, 48, 48]               0\n",
      "          Conv2d-111          [-1, 384, 48, 48]         331,776\n",
      "     BatchNorm2d-112          [-1, 384, 48, 48]             768\n",
      "            SiLU-113          [-1, 384, 48, 48]               0\n",
      "        Identity-114          [-1, 384, 48, 48]               0\n",
      "          Conv2d-115           [-1, 96, 48, 48]          36,864\n",
      "     BatchNorm2d-116           [-1, 96, 48, 48]             192\n",
      "    EdgeResidual-117           [-1, 96, 48, 48]               0\n",
      "          Conv2d-118          [-1, 384, 48, 48]          36,864\n",
      "     BatchNorm2d-119          [-1, 384, 48, 48]             768\n",
      "            SiLU-120          [-1, 384, 48, 48]               0\n",
      "      Conv2dSame-121          [-1, 384, 24, 24]           3,456\n",
      "     BatchNorm2d-122          [-1, 384, 24, 24]             768\n",
      "            SiLU-123          [-1, 384, 24, 24]               0\n",
      "          Conv2d-124             [-1, 24, 1, 1]           9,240\n",
      "            SiLU-125             [-1, 24, 1, 1]               0\n",
      "          Conv2d-126            [-1, 384, 1, 1]           9,600\n",
      "         Sigmoid-127            [-1, 384, 1, 1]               0\n",
      "   SqueezeExcite-128          [-1, 384, 24, 24]               0\n",
      "          Conv2d-129          [-1, 192, 24, 24]          73,728\n",
      "     BatchNorm2d-130          [-1, 192, 24, 24]             384\n",
      "InvertedResidual-131          [-1, 192, 24, 24]               0\n",
      "          Conv2d-132          [-1, 768, 24, 24]         147,456\n",
      "     BatchNorm2d-133          [-1, 768, 24, 24]           1,536\n",
      "            SiLU-134          [-1, 768, 24, 24]               0\n",
      "          Conv2d-135          [-1, 768, 24, 24]           6,912\n",
      "     BatchNorm2d-136          [-1, 768, 24, 24]           1,536\n",
      "            SiLU-137          [-1, 768, 24, 24]               0\n",
      "          Conv2d-138             [-1, 48, 1, 1]          36,912\n",
      "            SiLU-139             [-1, 48, 1, 1]               0\n",
      "          Conv2d-140            [-1, 768, 1, 1]          37,632\n",
      "         Sigmoid-141            [-1, 768, 1, 1]               0\n",
      "   SqueezeExcite-142          [-1, 768, 24, 24]               0\n",
      "          Conv2d-143          [-1, 192, 24, 24]         147,456\n",
      "     BatchNorm2d-144          [-1, 192, 24, 24]             384\n",
      "InvertedResidual-145          [-1, 192, 24, 24]               0\n",
      "          Conv2d-146          [-1, 768, 24, 24]         147,456\n",
      "     BatchNorm2d-147          [-1, 768, 24, 24]           1,536\n",
      "            SiLU-148          [-1, 768, 24, 24]               0\n",
      "          Conv2d-149          [-1, 768, 24, 24]           6,912\n",
      "     BatchNorm2d-150          [-1, 768, 24, 24]           1,536\n",
      "            SiLU-151          [-1, 768, 24, 24]               0\n",
      "          Conv2d-152             [-1, 48, 1, 1]          36,912\n",
      "            SiLU-153             [-1, 48, 1, 1]               0\n",
      "          Conv2d-154            [-1, 768, 1, 1]          37,632\n",
      "         Sigmoid-155            [-1, 768, 1, 1]               0\n",
      "   SqueezeExcite-156          [-1, 768, 24, 24]               0\n",
      "          Conv2d-157          [-1, 192, 24, 24]         147,456\n",
      "     BatchNorm2d-158          [-1, 192, 24, 24]             384\n",
      "InvertedResidual-159          [-1, 192, 24, 24]               0\n",
      "          Conv2d-160          [-1, 768, 24, 24]         147,456\n",
      "     BatchNorm2d-161          [-1, 768, 24, 24]           1,536\n",
      "            SiLU-162          [-1, 768, 24, 24]               0\n",
      "          Conv2d-163          [-1, 768, 24, 24]           6,912\n",
      "     BatchNorm2d-164          [-1, 768, 24, 24]           1,536\n",
      "            SiLU-165          [-1, 768, 24, 24]               0\n",
      "          Conv2d-166             [-1, 48, 1, 1]          36,912\n",
      "            SiLU-167             [-1, 48, 1, 1]               0\n",
      "          Conv2d-168            [-1, 768, 1, 1]          37,632\n",
      "         Sigmoid-169            [-1, 768, 1, 1]               0\n",
      "   SqueezeExcite-170          [-1, 768, 24, 24]               0\n",
      "          Conv2d-171          [-1, 192, 24, 24]         147,456\n",
      "     BatchNorm2d-172          [-1, 192, 24, 24]             384\n",
      "InvertedResidual-173          [-1, 192, 24, 24]               0\n",
      "          Conv2d-174          [-1, 768, 24, 24]         147,456\n",
      "     BatchNorm2d-175          [-1, 768, 24, 24]           1,536\n",
      "            SiLU-176          [-1, 768, 24, 24]               0\n",
      "          Conv2d-177          [-1, 768, 24, 24]           6,912\n",
      "     BatchNorm2d-178          [-1, 768, 24, 24]           1,536\n",
      "            SiLU-179          [-1, 768, 24, 24]               0\n",
      "          Conv2d-180             [-1, 48, 1, 1]          36,912\n",
      "            SiLU-181             [-1, 48, 1, 1]               0\n",
      "          Conv2d-182            [-1, 768, 1, 1]          37,632\n",
      "         Sigmoid-183            [-1, 768, 1, 1]               0\n",
      "   SqueezeExcite-184          [-1, 768, 24, 24]               0\n",
      "          Conv2d-185          [-1, 192, 24, 24]         147,456\n",
      "     BatchNorm2d-186          [-1, 192, 24, 24]             384\n",
      "InvertedResidual-187          [-1, 192, 24, 24]               0\n",
      "          Conv2d-188          [-1, 768, 24, 24]         147,456\n",
      "     BatchNorm2d-189          [-1, 768, 24, 24]           1,536\n",
      "            SiLU-190          [-1, 768, 24, 24]               0\n",
      "          Conv2d-191          [-1, 768, 24, 24]           6,912\n",
      "     BatchNorm2d-192          [-1, 768, 24, 24]           1,536\n",
      "            SiLU-193          [-1, 768, 24, 24]               0\n",
      "          Conv2d-194             [-1, 48, 1, 1]          36,912\n",
      "            SiLU-195             [-1, 48, 1, 1]               0\n",
      "          Conv2d-196            [-1, 768, 1, 1]          37,632\n",
      "         Sigmoid-197            [-1, 768, 1, 1]               0\n",
      "   SqueezeExcite-198          [-1, 768, 24, 24]               0\n",
      "          Conv2d-199          [-1, 192, 24, 24]         147,456\n",
      "     BatchNorm2d-200          [-1, 192, 24, 24]             384\n",
      "InvertedResidual-201          [-1, 192, 24, 24]               0\n",
      "          Conv2d-202          [-1, 768, 24, 24]         147,456\n",
      "     BatchNorm2d-203          [-1, 768, 24, 24]           1,536\n",
      "            SiLU-204          [-1, 768, 24, 24]               0\n",
      "          Conv2d-205          [-1, 768, 24, 24]           6,912\n",
      "     BatchNorm2d-206          [-1, 768, 24, 24]           1,536\n",
      "            SiLU-207          [-1, 768, 24, 24]               0\n",
      "          Conv2d-208             [-1, 48, 1, 1]          36,912\n",
      "            SiLU-209             [-1, 48, 1, 1]               0\n",
      "          Conv2d-210            [-1, 768, 1, 1]          37,632\n",
      "         Sigmoid-211            [-1, 768, 1, 1]               0\n",
      "   SqueezeExcite-212          [-1, 768, 24, 24]               0\n",
      "          Conv2d-213          [-1, 192, 24, 24]         147,456\n",
      "     BatchNorm2d-214          [-1, 192, 24, 24]             384\n",
      "InvertedResidual-215          [-1, 192, 24, 24]               0\n",
      "          Conv2d-216          [-1, 768, 24, 24]         147,456\n",
      "     BatchNorm2d-217          [-1, 768, 24, 24]           1,536\n",
      "            SiLU-218          [-1, 768, 24, 24]               0\n",
      "          Conv2d-219          [-1, 768, 24, 24]           6,912\n",
      "     BatchNorm2d-220          [-1, 768, 24, 24]           1,536\n",
      "            SiLU-221          [-1, 768, 24, 24]               0\n",
      "          Conv2d-222             [-1, 48, 1, 1]          36,912\n",
      "            SiLU-223             [-1, 48, 1, 1]               0\n",
      "          Conv2d-224            [-1, 768, 1, 1]          37,632\n",
      "         Sigmoid-225            [-1, 768, 1, 1]               0\n",
      "   SqueezeExcite-226          [-1, 768, 24, 24]               0\n",
      "          Conv2d-227          [-1, 192, 24, 24]         147,456\n",
      "     BatchNorm2d-228          [-1, 192, 24, 24]             384\n",
      "InvertedResidual-229          [-1, 192, 24, 24]               0\n",
      "          Conv2d-230          [-1, 768, 24, 24]         147,456\n",
      "     BatchNorm2d-231          [-1, 768, 24, 24]           1,536\n",
      "            SiLU-232          [-1, 768, 24, 24]               0\n",
      "          Conv2d-233          [-1, 768, 24, 24]           6,912\n",
      "     BatchNorm2d-234          [-1, 768, 24, 24]           1,536\n",
      "            SiLU-235          [-1, 768, 24, 24]               0\n",
      "          Conv2d-236             [-1, 48, 1, 1]          36,912\n",
      "            SiLU-237             [-1, 48, 1, 1]               0\n",
      "          Conv2d-238            [-1, 768, 1, 1]          37,632\n",
      "         Sigmoid-239            [-1, 768, 1, 1]               0\n",
      "   SqueezeExcite-240          [-1, 768, 24, 24]               0\n",
      "          Conv2d-241          [-1, 192, 24, 24]         147,456\n",
      "     BatchNorm2d-242          [-1, 192, 24, 24]             384\n",
      "InvertedResidual-243          [-1, 192, 24, 24]               0\n",
      "          Conv2d-244          [-1, 768, 24, 24]         147,456\n",
      "     BatchNorm2d-245          [-1, 768, 24, 24]           1,536\n",
      "            SiLU-246          [-1, 768, 24, 24]               0\n",
      "          Conv2d-247          [-1, 768, 24, 24]           6,912\n",
      "     BatchNorm2d-248          [-1, 768, 24, 24]           1,536\n",
      "            SiLU-249          [-1, 768, 24, 24]               0\n",
      "          Conv2d-250             [-1, 48, 1, 1]          36,912\n",
      "            SiLU-251             [-1, 48, 1, 1]               0\n",
      "          Conv2d-252            [-1, 768, 1, 1]          37,632\n",
      "         Sigmoid-253            [-1, 768, 1, 1]               0\n",
      "   SqueezeExcite-254          [-1, 768, 24, 24]               0\n",
      "          Conv2d-255          [-1, 192, 24, 24]         147,456\n",
      "     BatchNorm2d-256          [-1, 192, 24, 24]             384\n",
      "InvertedResidual-257          [-1, 192, 24, 24]               0\n",
      "          Conv2d-258         [-1, 1152, 24, 24]         221,184\n",
      "     BatchNorm2d-259         [-1, 1152, 24, 24]           2,304\n",
      "            SiLU-260         [-1, 1152, 24, 24]               0\n",
      "          Conv2d-261         [-1, 1152, 24, 24]          10,368\n",
      "     BatchNorm2d-262         [-1, 1152, 24, 24]           2,304\n",
      "            SiLU-263         [-1, 1152, 24, 24]               0\n",
      "          Conv2d-264             [-1, 48, 1, 1]          55,344\n",
      "            SiLU-265             [-1, 48, 1, 1]               0\n",
      "          Conv2d-266           [-1, 1152, 1, 1]          56,448\n",
      "         Sigmoid-267           [-1, 1152, 1, 1]               0\n",
      "   SqueezeExcite-268         [-1, 1152, 24, 24]               0\n",
      "          Conv2d-269          [-1, 224, 24, 24]         258,048\n",
      "     BatchNorm2d-270          [-1, 224, 24, 24]             448\n",
      "InvertedResidual-271          [-1, 224, 24, 24]               0\n",
      "          Conv2d-272         [-1, 1344, 24, 24]         301,056\n",
      "     BatchNorm2d-273         [-1, 1344, 24, 24]           2,688\n",
      "            SiLU-274         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-275         [-1, 1344, 24, 24]          12,096\n",
      "     BatchNorm2d-276         [-1, 1344, 24, 24]           2,688\n",
      "            SiLU-277         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-278             [-1, 56, 1, 1]          75,320\n",
      "            SiLU-279             [-1, 56, 1, 1]               0\n",
      "          Conv2d-280           [-1, 1344, 1, 1]          76,608\n",
      "         Sigmoid-281           [-1, 1344, 1, 1]               0\n",
      "   SqueezeExcite-282         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-283          [-1, 224, 24, 24]         301,056\n",
      "     BatchNorm2d-284          [-1, 224, 24, 24]             448\n",
      "InvertedResidual-285          [-1, 224, 24, 24]               0\n",
      "          Conv2d-286         [-1, 1344, 24, 24]         301,056\n",
      "     BatchNorm2d-287         [-1, 1344, 24, 24]           2,688\n",
      "            SiLU-288         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-289         [-1, 1344, 24, 24]          12,096\n",
      "     BatchNorm2d-290         [-1, 1344, 24, 24]           2,688\n",
      "            SiLU-291         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-292             [-1, 56, 1, 1]          75,320\n",
      "            SiLU-293             [-1, 56, 1, 1]               0\n",
      "          Conv2d-294           [-1, 1344, 1, 1]          76,608\n",
      "         Sigmoid-295           [-1, 1344, 1, 1]               0\n",
      "   SqueezeExcite-296         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-297          [-1, 224, 24, 24]         301,056\n",
      "     BatchNorm2d-298          [-1, 224, 24, 24]             448\n",
      "InvertedResidual-299          [-1, 224, 24, 24]               0\n",
      "          Conv2d-300         [-1, 1344, 24, 24]         301,056\n",
      "     BatchNorm2d-301         [-1, 1344, 24, 24]           2,688\n",
      "            SiLU-302         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-303         [-1, 1344, 24, 24]          12,096\n",
      "     BatchNorm2d-304         [-1, 1344, 24, 24]           2,688\n",
      "            SiLU-305         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-306             [-1, 56, 1, 1]          75,320\n",
      "            SiLU-307             [-1, 56, 1, 1]               0\n",
      "          Conv2d-308           [-1, 1344, 1, 1]          76,608\n",
      "         Sigmoid-309           [-1, 1344, 1, 1]               0\n",
      "   SqueezeExcite-310         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-311          [-1, 224, 24, 24]         301,056\n",
      "     BatchNorm2d-312          [-1, 224, 24, 24]             448\n",
      "InvertedResidual-313          [-1, 224, 24, 24]               0\n",
      "          Conv2d-314         [-1, 1344, 24, 24]         301,056\n",
      "     BatchNorm2d-315         [-1, 1344, 24, 24]           2,688\n",
      "            SiLU-316         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-317         [-1, 1344, 24, 24]          12,096\n",
      "     BatchNorm2d-318         [-1, 1344, 24, 24]           2,688\n",
      "            SiLU-319         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-320             [-1, 56, 1, 1]          75,320\n",
      "            SiLU-321             [-1, 56, 1, 1]               0\n",
      "          Conv2d-322           [-1, 1344, 1, 1]          76,608\n",
      "         Sigmoid-323           [-1, 1344, 1, 1]               0\n",
      "   SqueezeExcite-324         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-325          [-1, 224, 24, 24]         301,056\n",
      "     BatchNorm2d-326          [-1, 224, 24, 24]             448\n",
      "InvertedResidual-327          [-1, 224, 24, 24]               0\n",
      "          Conv2d-328         [-1, 1344, 24, 24]         301,056\n",
      "     BatchNorm2d-329         [-1, 1344, 24, 24]           2,688\n",
      "            SiLU-330         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-331         [-1, 1344, 24, 24]          12,096\n",
      "     BatchNorm2d-332         [-1, 1344, 24, 24]           2,688\n",
      "            SiLU-333         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-334             [-1, 56, 1, 1]          75,320\n",
      "            SiLU-335             [-1, 56, 1, 1]               0\n",
      "          Conv2d-336           [-1, 1344, 1, 1]          76,608\n",
      "         Sigmoid-337           [-1, 1344, 1, 1]               0\n",
      "   SqueezeExcite-338         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-339          [-1, 224, 24, 24]         301,056\n",
      "     BatchNorm2d-340          [-1, 224, 24, 24]             448\n",
      "InvertedResidual-341          [-1, 224, 24, 24]               0\n",
      "          Conv2d-342         [-1, 1344, 24, 24]         301,056\n",
      "     BatchNorm2d-343         [-1, 1344, 24, 24]           2,688\n",
      "            SiLU-344         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-345         [-1, 1344, 24, 24]          12,096\n",
      "     BatchNorm2d-346         [-1, 1344, 24, 24]           2,688\n",
      "            SiLU-347         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-348             [-1, 56, 1, 1]          75,320\n",
      "            SiLU-349             [-1, 56, 1, 1]               0\n",
      "          Conv2d-350           [-1, 1344, 1, 1]          76,608\n",
      "         Sigmoid-351           [-1, 1344, 1, 1]               0\n",
      "   SqueezeExcite-352         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-353          [-1, 224, 24, 24]         301,056\n",
      "     BatchNorm2d-354          [-1, 224, 24, 24]             448\n",
      "InvertedResidual-355          [-1, 224, 24, 24]               0\n",
      "          Conv2d-356         [-1, 1344, 24, 24]         301,056\n",
      "     BatchNorm2d-357         [-1, 1344, 24, 24]           2,688\n",
      "            SiLU-358         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-359         [-1, 1344, 24, 24]          12,096\n",
      "     BatchNorm2d-360         [-1, 1344, 24, 24]           2,688\n",
      "            SiLU-361         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-362             [-1, 56, 1, 1]          75,320\n",
      "            SiLU-363             [-1, 56, 1, 1]               0\n",
      "          Conv2d-364           [-1, 1344, 1, 1]          76,608\n",
      "         Sigmoid-365           [-1, 1344, 1, 1]               0\n",
      "   SqueezeExcite-366         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-367          [-1, 224, 24, 24]         301,056\n",
      "     BatchNorm2d-368          [-1, 224, 24, 24]             448\n",
      "InvertedResidual-369          [-1, 224, 24, 24]               0\n",
      "          Conv2d-370         [-1, 1344, 24, 24]         301,056\n",
      "     BatchNorm2d-371         [-1, 1344, 24, 24]           2,688\n",
      "            SiLU-372         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-373         [-1, 1344, 24, 24]          12,096\n",
      "     BatchNorm2d-374         [-1, 1344, 24, 24]           2,688\n",
      "            SiLU-375         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-376             [-1, 56, 1, 1]          75,320\n",
      "            SiLU-377             [-1, 56, 1, 1]               0\n",
      "          Conv2d-378           [-1, 1344, 1, 1]          76,608\n",
      "         Sigmoid-379           [-1, 1344, 1, 1]               0\n",
      "   SqueezeExcite-380         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-381          [-1, 224, 24, 24]         301,056\n",
      "     BatchNorm2d-382          [-1, 224, 24, 24]             448\n",
      "InvertedResidual-383          [-1, 224, 24, 24]               0\n",
      "          Conv2d-384         [-1, 1344, 24, 24]         301,056\n",
      "     BatchNorm2d-385         [-1, 1344, 24, 24]           2,688\n",
      "            SiLU-386         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-387         [-1, 1344, 24, 24]          12,096\n",
      "     BatchNorm2d-388         [-1, 1344, 24, 24]           2,688\n",
      "            SiLU-389         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-390             [-1, 56, 1, 1]          75,320\n",
      "            SiLU-391             [-1, 56, 1, 1]               0\n",
      "          Conv2d-392           [-1, 1344, 1, 1]          76,608\n",
      "         Sigmoid-393           [-1, 1344, 1, 1]               0\n",
      "   SqueezeExcite-394         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-395          [-1, 224, 24, 24]         301,056\n",
      "     BatchNorm2d-396          [-1, 224, 24, 24]             448\n",
      "InvertedResidual-397          [-1, 224, 24, 24]               0\n",
      "          Conv2d-398         [-1, 1344, 24, 24]         301,056\n",
      "     BatchNorm2d-399         [-1, 1344, 24, 24]           2,688\n",
      "            SiLU-400         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-401         [-1, 1344, 24, 24]          12,096\n",
      "     BatchNorm2d-402         [-1, 1344, 24, 24]           2,688\n",
      "            SiLU-403         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-404             [-1, 56, 1, 1]          75,320\n",
      "            SiLU-405             [-1, 56, 1, 1]               0\n",
      "          Conv2d-406           [-1, 1344, 1, 1]          76,608\n",
      "         Sigmoid-407           [-1, 1344, 1, 1]               0\n",
      "   SqueezeExcite-408         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-409          [-1, 224, 24, 24]         301,056\n",
      "     BatchNorm2d-410          [-1, 224, 24, 24]             448\n",
      "InvertedResidual-411          [-1, 224, 24, 24]               0\n",
      "          Conv2d-412         [-1, 1344, 24, 24]         301,056\n",
      "     BatchNorm2d-413         [-1, 1344, 24, 24]           2,688\n",
      "            SiLU-414         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-415         [-1, 1344, 24, 24]          12,096\n",
      "     BatchNorm2d-416         [-1, 1344, 24, 24]           2,688\n",
      "            SiLU-417         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-418             [-1, 56, 1, 1]          75,320\n",
      "            SiLU-419             [-1, 56, 1, 1]               0\n",
      "          Conv2d-420           [-1, 1344, 1, 1]          76,608\n",
      "         Sigmoid-421           [-1, 1344, 1, 1]               0\n",
      "   SqueezeExcite-422         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-423          [-1, 224, 24, 24]         301,056\n",
      "     BatchNorm2d-424          [-1, 224, 24, 24]             448\n",
      "InvertedResidual-425          [-1, 224, 24, 24]               0\n",
      "          Conv2d-426         [-1, 1344, 24, 24]         301,056\n",
      "     BatchNorm2d-427         [-1, 1344, 24, 24]           2,688\n",
      "            SiLU-428         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-429         [-1, 1344, 24, 24]          12,096\n",
      "     BatchNorm2d-430         [-1, 1344, 24, 24]           2,688\n",
      "            SiLU-431         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-432             [-1, 56, 1, 1]          75,320\n",
      "            SiLU-433             [-1, 56, 1, 1]               0\n",
      "          Conv2d-434           [-1, 1344, 1, 1]          76,608\n",
      "         Sigmoid-435           [-1, 1344, 1, 1]               0\n",
      "   SqueezeExcite-436         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-437          [-1, 224, 24, 24]         301,056\n",
      "     BatchNorm2d-438          [-1, 224, 24, 24]             448\n",
      "InvertedResidual-439          [-1, 224, 24, 24]               0\n",
      "          Conv2d-440         [-1, 1344, 24, 24]         301,056\n",
      "     BatchNorm2d-441         [-1, 1344, 24, 24]           2,688\n",
      "            SiLU-442         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-443         [-1, 1344, 24, 24]          12,096\n",
      "     BatchNorm2d-444         [-1, 1344, 24, 24]           2,688\n",
      "            SiLU-445         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-446             [-1, 56, 1, 1]          75,320\n",
      "            SiLU-447             [-1, 56, 1, 1]               0\n",
      "          Conv2d-448           [-1, 1344, 1, 1]          76,608\n",
      "         Sigmoid-449           [-1, 1344, 1, 1]               0\n",
      "   SqueezeExcite-450         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-451          [-1, 224, 24, 24]         301,056\n",
      "     BatchNorm2d-452          [-1, 224, 24, 24]             448\n",
      "InvertedResidual-453          [-1, 224, 24, 24]               0\n",
      "          Conv2d-454         [-1, 1344, 24, 24]         301,056\n",
      "     BatchNorm2d-455         [-1, 1344, 24, 24]           2,688\n",
      "            SiLU-456         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-457         [-1, 1344, 24, 24]          12,096\n",
      "     BatchNorm2d-458         [-1, 1344, 24, 24]           2,688\n",
      "            SiLU-459         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-460             [-1, 56, 1, 1]          75,320\n",
      "            SiLU-461             [-1, 56, 1, 1]               0\n",
      "          Conv2d-462           [-1, 1344, 1, 1]          76,608\n",
      "         Sigmoid-463           [-1, 1344, 1, 1]               0\n",
      "   SqueezeExcite-464         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-465          [-1, 224, 24, 24]         301,056\n",
      "     BatchNorm2d-466          [-1, 224, 24, 24]             448\n",
      "InvertedResidual-467          [-1, 224, 24, 24]               0\n",
      "          Conv2d-468         [-1, 1344, 24, 24]         301,056\n",
      "     BatchNorm2d-469         [-1, 1344, 24, 24]           2,688\n",
      "            SiLU-470         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-471         [-1, 1344, 24, 24]          12,096\n",
      "     BatchNorm2d-472         [-1, 1344, 24, 24]           2,688\n",
      "            SiLU-473         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-474             [-1, 56, 1, 1]          75,320\n",
      "            SiLU-475             [-1, 56, 1, 1]               0\n",
      "          Conv2d-476           [-1, 1344, 1, 1]          76,608\n",
      "         Sigmoid-477           [-1, 1344, 1, 1]               0\n",
      "   SqueezeExcite-478         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-479          [-1, 224, 24, 24]         301,056\n",
      "     BatchNorm2d-480          [-1, 224, 24, 24]             448\n",
      "InvertedResidual-481          [-1, 224, 24, 24]               0\n",
      "          Conv2d-482         [-1, 1344, 24, 24]         301,056\n",
      "     BatchNorm2d-483         [-1, 1344, 24, 24]           2,688\n",
      "            SiLU-484         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-485         [-1, 1344, 24, 24]          12,096\n",
      "     BatchNorm2d-486         [-1, 1344, 24, 24]           2,688\n",
      "            SiLU-487         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-488             [-1, 56, 1, 1]          75,320\n",
      "            SiLU-489             [-1, 56, 1, 1]               0\n",
      "          Conv2d-490           [-1, 1344, 1, 1]          76,608\n",
      "         Sigmoid-491           [-1, 1344, 1, 1]               0\n",
      "   SqueezeExcite-492         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-493          [-1, 224, 24, 24]         301,056\n",
      "     BatchNorm2d-494          [-1, 224, 24, 24]             448\n",
      "InvertedResidual-495          [-1, 224, 24, 24]               0\n",
      "          Conv2d-496         [-1, 1344, 24, 24]         301,056\n",
      "     BatchNorm2d-497         [-1, 1344, 24, 24]           2,688\n",
      "            SiLU-498         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-499         [-1, 1344, 24, 24]          12,096\n",
      "     BatchNorm2d-500         [-1, 1344, 24, 24]           2,688\n",
      "            SiLU-501         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-502             [-1, 56, 1, 1]          75,320\n",
      "            SiLU-503             [-1, 56, 1, 1]               0\n",
      "          Conv2d-504           [-1, 1344, 1, 1]          76,608\n",
      "         Sigmoid-505           [-1, 1344, 1, 1]               0\n",
      "   SqueezeExcite-506         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-507          [-1, 224, 24, 24]         301,056\n",
      "     BatchNorm2d-508          [-1, 224, 24, 24]             448\n",
      "InvertedResidual-509          [-1, 224, 24, 24]               0\n",
      "          Conv2d-510         [-1, 1344, 24, 24]         301,056\n",
      "     BatchNorm2d-511         [-1, 1344, 24, 24]           2,688\n",
      "            SiLU-512         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-513         [-1, 1344, 24, 24]          12,096\n",
      "     BatchNorm2d-514         [-1, 1344, 24, 24]           2,688\n",
      "            SiLU-515         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-516             [-1, 56, 1, 1]          75,320\n",
      "            SiLU-517             [-1, 56, 1, 1]               0\n",
      "          Conv2d-518           [-1, 1344, 1, 1]          76,608\n",
      "         Sigmoid-519           [-1, 1344, 1, 1]               0\n",
      "   SqueezeExcite-520         [-1, 1344, 24, 24]               0\n",
      "          Conv2d-521          [-1, 224, 24, 24]         301,056\n",
      "     BatchNorm2d-522          [-1, 224, 24, 24]             448\n",
      "InvertedResidual-523          [-1, 224, 24, 24]               0\n",
      "          Conv2d-524         [-1, 1344, 24, 24]         301,056\n",
      "     BatchNorm2d-525         [-1, 1344, 24, 24]           2,688\n",
      "            SiLU-526         [-1, 1344, 24, 24]               0\n",
      "      Conv2dSame-527         [-1, 1344, 12, 12]          12,096\n",
      "     BatchNorm2d-528         [-1, 1344, 12, 12]           2,688\n",
      "            SiLU-529         [-1, 1344, 12, 12]               0\n",
      "          Conv2d-530             [-1, 56, 1, 1]          75,320\n",
      "            SiLU-531             [-1, 56, 1, 1]               0\n",
      "          Conv2d-532           [-1, 1344, 1, 1]          76,608\n",
      "         Sigmoid-533           [-1, 1344, 1, 1]               0\n",
      "   SqueezeExcite-534         [-1, 1344, 12, 12]               0\n",
      "          Conv2d-535          [-1, 384, 12, 12]         516,096\n",
      "     BatchNorm2d-536          [-1, 384, 12, 12]             768\n",
      "InvertedResidual-537          [-1, 384, 12, 12]               0\n",
      "          Conv2d-538         [-1, 2304, 12, 12]         884,736\n",
      "     BatchNorm2d-539         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-540         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-541         [-1, 2304, 12, 12]          20,736\n",
      "     BatchNorm2d-542         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-543         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-544             [-1, 96, 1, 1]         221,280\n",
      "            SiLU-545             [-1, 96, 1, 1]               0\n",
      "          Conv2d-546           [-1, 2304, 1, 1]         223,488\n",
      "         Sigmoid-547           [-1, 2304, 1, 1]               0\n",
      "   SqueezeExcite-548         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-549          [-1, 384, 12, 12]         884,736\n",
      "     BatchNorm2d-550          [-1, 384, 12, 12]             768\n",
      "InvertedResidual-551          [-1, 384, 12, 12]               0\n",
      "          Conv2d-552         [-1, 2304, 12, 12]         884,736\n",
      "     BatchNorm2d-553         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-554         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-555         [-1, 2304, 12, 12]          20,736\n",
      "     BatchNorm2d-556         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-557         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-558             [-1, 96, 1, 1]         221,280\n",
      "            SiLU-559             [-1, 96, 1, 1]               0\n",
      "          Conv2d-560           [-1, 2304, 1, 1]         223,488\n",
      "         Sigmoid-561           [-1, 2304, 1, 1]               0\n",
      "   SqueezeExcite-562         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-563          [-1, 384, 12, 12]         884,736\n",
      "     BatchNorm2d-564          [-1, 384, 12, 12]             768\n",
      "InvertedResidual-565          [-1, 384, 12, 12]               0\n",
      "          Conv2d-566         [-1, 2304, 12, 12]         884,736\n",
      "     BatchNorm2d-567         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-568         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-569         [-1, 2304, 12, 12]          20,736\n",
      "     BatchNorm2d-570         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-571         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-572             [-1, 96, 1, 1]         221,280\n",
      "            SiLU-573             [-1, 96, 1, 1]               0\n",
      "          Conv2d-574           [-1, 2304, 1, 1]         223,488\n",
      "         Sigmoid-575           [-1, 2304, 1, 1]               0\n",
      "   SqueezeExcite-576         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-577          [-1, 384, 12, 12]         884,736\n",
      "     BatchNorm2d-578          [-1, 384, 12, 12]             768\n",
      "InvertedResidual-579          [-1, 384, 12, 12]               0\n",
      "          Conv2d-580         [-1, 2304, 12, 12]         884,736\n",
      "     BatchNorm2d-581         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-582         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-583         [-1, 2304, 12, 12]          20,736\n",
      "     BatchNorm2d-584         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-585         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-586             [-1, 96, 1, 1]         221,280\n",
      "            SiLU-587             [-1, 96, 1, 1]               0\n",
      "          Conv2d-588           [-1, 2304, 1, 1]         223,488\n",
      "         Sigmoid-589           [-1, 2304, 1, 1]               0\n",
      "   SqueezeExcite-590         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-591          [-1, 384, 12, 12]         884,736\n",
      "     BatchNorm2d-592          [-1, 384, 12, 12]             768\n",
      "InvertedResidual-593          [-1, 384, 12, 12]               0\n",
      "          Conv2d-594         [-1, 2304, 12, 12]         884,736\n",
      "     BatchNorm2d-595         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-596         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-597         [-1, 2304, 12, 12]          20,736\n",
      "     BatchNorm2d-598         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-599         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-600             [-1, 96, 1, 1]         221,280\n",
      "            SiLU-601             [-1, 96, 1, 1]               0\n",
      "          Conv2d-602           [-1, 2304, 1, 1]         223,488\n",
      "         Sigmoid-603           [-1, 2304, 1, 1]               0\n",
      "   SqueezeExcite-604         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-605          [-1, 384, 12, 12]         884,736\n",
      "     BatchNorm2d-606          [-1, 384, 12, 12]             768\n",
      "InvertedResidual-607          [-1, 384, 12, 12]               0\n",
      "          Conv2d-608         [-1, 2304, 12, 12]         884,736\n",
      "     BatchNorm2d-609         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-610         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-611         [-1, 2304, 12, 12]          20,736\n",
      "     BatchNorm2d-612         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-613         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-614             [-1, 96, 1, 1]         221,280\n",
      "            SiLU-615             [-1, 96, 1, 1]               0\n",
      "          Conv2d-616           [-1, 2304, 1, 1]         223,488\n",
      "         Sigmoid-617           [-1, 2304, 1, 1]               0\n",
      "   SqueezeExcite-618         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-619          [-1, 384, 12, 12]         884,736\n",
      "     BatchNorm2d-620          [-1, 384, 12, 12]             768\n",
      "InvertedResidual-621          [-1, 384, 12, 12]               0\n",
      "          Conv2d-622         [-1, 2304, 12, 12]         884,736\n",
      "     BatchNorm2d-623         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-624         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-625         [-1, 2304, 12, 12]          20,736\n",
      "     BatchNorm2d-626         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-627         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-628             [-1, 96, 1, 1]         221,280\n",
      "            SiLU-629             [-1, 96, 1, 1]               0\n",
      "          Conv2d-630           [-1, 2304, 1, 1]         223,488\n",
      "         Sigmoid-631           [-1, 2304, 1, 1]               0\n",
      "   SqueezeExcite-632         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-633          [-1, 384, 12, 12]         884,736\n",
      "     BatchNorm2d-634          [-1, 384, 12, 12]             768\n",
      "InvertedResidual-635          [-1, 384, 12, 12]               0\n",
      "          Conv2d-636         [-1, 2304, 12, 12]         884,736\n",
      "     BatchNorm2d-637         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-638         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-639         [-1, 2304, 12, 12]          20,736\n",
      "     BatchNorm2d-640         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-641         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-642             [-1, 96, 1, 1]         221,280\n",
      "            SiLU-643             [-1, 96, 1, 1]               0\n",
      "          Conv2d-644           [-1, 2304, 1, 1]         223,488\n",
      "         Sigmoid-645           [-1, 2304, 1, 1]               0\n",
      "   SqueezeExcite-646         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-647          [-1, 384, 12, 12]         884,736\n",
      "     BatchNorm2d-648          [-1, 384, 12, 12]             768\n",
      "InvertedResidual-649          [-1, 384, 12, 12]               0\n",
      "          Conv2d-650         [-1, 2304, 12, 12]         884,736\n",
      "     BatchNorm2d-651         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-652         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-653         [-1, 2304, 12, 12]          20,736\n",
      "     BatchNorm2d-654         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-655         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-656             [-1, 96, 1, 1]         221,280\n",
      "            SiLU-657             [-1, 96, 1, 1]               0\n",
      "          Conv2d-658           [-1, 2304, 1, 1]         223,488\n",
      "         Sigmoid-659           [-1, 2304, 1, 1]               0\n",
      "   SqueezeExcite-660         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-661          [-1, 384, 12, 12]         884,736\n",
      "     BatchNorm2d-662          [-1, 384, 12, 12]             768\n",
      "InvertedResidual-663          [-1, 384, 12, 12]               0\n",
      "          Conv2d-664         [-1, 2304, 12, 12]         884,736\n",
      "     BatchNorm2d-665         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-666         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-667         [-1, 2304, 12, 12]          20,736\n",
      "     BatchNorm2d-668         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-669         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-670             [-1, 96, 1, 1]         221,280\n",
      "            SiLU-671             [-1, 96, 1, 1]               0\n",
      "          Conv2d-672           [-1, 2304, 1, 1]         223,488\n",
      "         Sigmoid-673           [-1, 2304, 1, 1]               0\n",
      "   SqueezeExcite-674         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-675          [-1, 384, 12, 12]         884,736\n",
      "     BatchNorm2d-676          [-1, 384, 12, 12]             768\n",
      "InvertedResidual-677          [-1, 384, 12, 12]               0\n",
      "          Conv2d-678         [-1, 2304, 12, 12]         884,736\n",
      "     BatchNorm2d-679         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-680         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-681         [-1, 2304, 12, 12]          20,736\n",
      "     BatchNorm2d-682         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-683         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-684             [-1, 96, 1, 1]         221,280\n",
      "            SiLU-685             [-1, 96, 1, 1]               0\n",
      "          Conv2d-686           [-1, 2304, 1, 1]         223,488\n",
      "         Sigmoid-687           [-1, 2304, 1, 1]               0\n",
      "   SqueezeExcite-688         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-689          [-1, 384, 12, 12]         884,736\n",
      "     BatchNorm2d-690          [-1, 384, 12, 12]             768\n",
      "InvertedResidual-691          [-1, 384, 12, 12]               0\n",
      "          Conv2d-692         [-1, 2304, 12, 12]         884,736\n",
      "     BatchNorm2d-693         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-694         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-695         [-1, 2304, 12, 12]          20,736\n",
      "     BatchNorm2d-696         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-697         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-698             [-1, 96, 1, 1]         221,280\n",
      "            SiLU-699             [-1, 96, 1, 1]               0\n",
      "          Conv2d-700           [-1, 2304, 1, 1]         223,488\n",
      "         Sigmoid-701           [-1, 2304, 1, 1]               0\n",
      "   SqueezeExcite-702         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-703          [-1, 384, 12, 12]         884,736\n",
      "     BatchNorm2d-704          [-1, 384, 12, 12]             768\n",
      "InvertedResidual-705          [-1, 384, 12, 12]               0\n",
      "          Conv2d-706         [-1, 2304, 12, 12]         884,736\n",
      "     BatchNorm2d-707         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-708         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-709         [-1, 2304, 12, 12]          20,736\n",
      "     BatchNorm2d-710         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-711         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-712             [-1, 96, 1, 1]         221,280\n",
      "            SiLU-713             [-1, 96, 1, 1]               0\n",
      "          Conv2d-714           [-1, 2304, 1, 1]         223,488\n",
      "         Sigmoid-715           [-1, 2304, 1, 1]               0\n",
      "   SqueezeExcite-716         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-717          [-1, 384, 12, 12]         884,736\n",
      "     BatchNorm2d-718          [-1, 384, 12, 12]             768\n",
      "InvertedResidual-719          [-1, 384, 12, 12]               0\n",
      "          Conv2d-720         [-1, 2304, 12, 12]         884,736\n",
      "     BatchNorm2d-721         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-722         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-723         [-1, 2304, 12, 12]          20,736\n",
      "     BatchNorm2d-724         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-725         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-726             [-1, 96, 1, 1]         221,280\n",
      "            SiLU-727             [-1, 96, 1, 1]               0\n",
      "          Conv2d-728           [-1, 2304, 1, 1]         223,488\n",
      "         Sigmoid-729           [-1, 2304, 1, 1]               0\n",
      "   SqueezeExcite-730         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-731          [-1, 384, 12, 12]         884,736\n",
      "     BatchNorm2d-732          [-1, 384, 12, 12]             768\n",
      "InvertedResidual-733          [-1, 384, 12, 12]               0\n",
      "          Conv2d-734         [-1, 2304, 12, 12]         884,736\n",
      "     BatchNorm2d-735         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-736         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-737         [-1, 2304, 12, 12]          20,736\n",
      "     BatchNorm2d-738         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-739         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-740             [-1, 96, 1, 1]         221,280\n",
      "            SiLU-741             [-1, 96, 1, 1]               0\n",
      "          Conv2d-742           [-1, 2304, 1, 1]         223,488\n",
      "         Sigmoid-743           [-1, 2304, 1, 1]               0\n",
      "   SqueezeExcite-744         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-745          [-1, 384, 12, 12]         884,736\n",
      "     BatchNorm2d-746          [-1, 384, 12, 12]             768\n",
      "InvertedResidual-747          [-1, 384, 12, 12]               0\n",
      "          Conv2d-748         [-1, 2304, 12, 12]         884,736\n",
      "     BatchNorm2d-749         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-750         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-751         [-1, 2304, 12, 12]          20,736\n",
      "     BatchNorm2d-752         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-753         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-754             [-1, 96, 1, 1]         221,280\n",
      "            SiLU-755             [-1, 96, 1, 1]               0\n",
      "          Conv2d-756           [-1, 2304, 1, 1]         223,488\n",
      "         Sigmoid-757           [-1, 2304, 1, 1]               0\n",
      "   SqueezeExcite-758         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-759          [-1, 384, 12, 12]         884,736\n",
      "     BatchNorm2d-760          [-1, 384, 12, 12]             768\n",
      "InvertedResidual-761          [-1, 384, 12, 12]               0\n",
      "          Conv2d-762         [-1, 2304, 12, 12]         884,736\n",
      "     BatchNorm2d-763         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-764         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-765         [-1, 2304, 12, 12]          20,736\n",
      "     BatchNorm2d-766         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-767         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-768             [-1, 96, 1, 1]         221,280\n",
      "            SiLU-769             [-1, 96, 1, 1]               0\n",
      "          Conv2d-770           [-1, 2304, 1, 1]         223,488\n",
      "         Sigmoid-771           [-1, 2304, 1, 1]               0\n",
      "   SqueezeExcite-772         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-773          [-1, 384, 12, 12]         884,736\n",
      "     BatchNorm2d-774          [-1, 384, 12, 12]             768\n",
      "InvertedResidual-775          [-1, 384, 12, 12]               0\n",
      "          Conv2d-776         [-1, 2304, 12, 12]         884,736\n",
      "     BatchNorm2d-777         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-778         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-779         [-1, 2304, 12, 12]          20,736\n",
      "     BatchNorm2d-780         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-781         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-782             [-1, 96, 1, 1]         221,280\n",
      "            SiLU-783             [-1, 96, 1, 1]               0\n",
      "          Conv2d-784           [-1, 2304, 1, 1]         223,488\n",
      "         Sigmoid-785           [-1, 2304, 1, 1]               0\n",
      "   SqueezeExcite-786         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-787          [-1, 384, 12, 12]         884,736\n",
      "     BatchNorm2d-788          [-1, 384, 12, 12]             768\n",
      "InvertedResidual-789          [-1, 384, 12, 12]               0\n",
      "          Conv2d-790         [-1, 2304, 12, 12]         884,736\n",
      "     BatchNorm2d-791         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-792         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-793         [-1, 2304, 12, 12]          20,736\n",
      "     BatchNorm2d-794         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-795         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-796             [-1, 96, 1, 1]         221,280\n",
      "            SiLU-797             [-1, 96, 1, 1]               0\n",
      "          Conv2d-798           [-1, 2304, 1, 1]         223,488\n",
      "         Sigmoid-799           [-1, 2304, 1, 1]               0\n",
      "   SqueezeExcite-800         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-801          [-1, 384, 12, 12]         884,736\n",
      "     BatchNorm2d-802          [-1, 384, 12, 12]             768\n",
      "InvertedResidual-803          [-1, 384, 12, 12]               0\n",
      "          Conv2d-804         [-1, 2304, 12, 12]         884,736\n",
      "     BatchNorm2d-805         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-806         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-807         [-1, 2304, 12, 12]          20,736\n",
      "     BatchNorm2d-808         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-809         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-810             [-1, 96, 1, 1]         221,280\n",
      "            SiLU-811             [-1, 96, 1, 1]               0\n",
      "          Conv2d-812           [-1, 2304, 1, 1]         223,488\n",
      "         Sigmoid-813           [-1, 2304, 1, 1]               0\n",
      "   SqueezeExcite-814         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-815          [-1, 384, 12, 12]         884,736\n",
      "     BatchNorm2d-816          [-1, 384, 12, 12]             768\n",
      "InvertedResidual-817          [-1, 384, 12, 12]               0\n",
      "          Conv2d-818         [-1, 2304, 12, 12]         884,736\n",
      "     BatchNorm2d-819         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-820         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-821         [-1, 2304, 12, 12]          20,736\n",
      "     BatchNorm2d-822         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-823         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-824             [-1, 96, 1, 1]         221,280\n",
      "            SiLU-825             [-1, 96, 1, 1]               0\n",
      "          Conv2d-826           [-1, 2304, 1, 1]         223,488\n",
      "         Sigmoid-827           [-1, 2304, 1, 1]               0\n",
      "   SqueezeExcite-828         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-829          [-1, 384, 12, 12]         884,736\n",
      "     BatchNorm2d-830          [-1, 384, 12, 12]             768\n",
      "InvertedResidual-831          [-1, 384, 12, 12]               0\n",
      "          Conv2d-832         [-1, 2304, 12, 12]         884,736\n",
      "     BatchNorm2d-833         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-834         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-835         [-1, 2304, 12, 12]          20,736\n",
      "     BatchNorm2d-836         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-837         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-838             [-1, 96, 1, 1]         221,280\n",
      "            SiLU-839             [-1, 96, 1, 1]               0\n",
      "          Conv2d-840           [-1, 2304, 1, 1]         223,488\n",
      "         Sigmoid-841           [-1, 2304, 1, 1]               0\n",
      "   SqueezeExcite-842         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-843          [-1, 384, 12, 12]         884,736\n",
      "     BatchNorm2d-844          [-1, 384, 12, 12]             768\n",
      "InvertedResidual-845          [-1, 384, 12, 12]               0\n",
      "          Conv2d-846         [-1, 2304, 12, 12]         884,736\n",
      "     BatchNorm2d-847         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-848         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-849         [-1, 2304, 12, 12]          20,736\n",
      "     BatchNorm2d-850         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-851         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-852             [-1, 96, 1, 1]         221,280\n",
      "            SiLU-853             [-1, 96, 1, 1]               0\n",
      "          Conv2d-854           [-1, 2304, 1, 1]         223,488\n",
      "         Sigmoid-855           [-1, 2304, 1, 1]               0\n",
      "   SqueezeExcite-856         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-857          [-1, 384, 12, 12]         884,736\n",
      "     BatchNorm2d-858          [-1, 384, 12, 12]             768\n",
      "InvertedResidual-859          [-1, 384, 12, 12]               0\n",
      "          Conv2d-860         [-1, 2304, 12, 12]         884,736\n",
      "     BatchNorm2d-861         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-862         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-863         [-1, 2304, 12, 12]          20,736\n",
      "     BatchNorm2d-864         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-865         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-866             [-1, 96, 1, 1]         221,280\n",
      "            SiLU-867             [-1, 96, 1, 1]               0\n",
      "          Conv2d-868           [-1, 2304, 1, 1]         223,488\n",
      "         Sigmoid-869           [-1, 2304, 1, 1]               0\n",
      "   SqueezeExcite-870         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-871          [-1, 384, 12, 12]         884,736\n",
      "     BatchNorm2d-872          [-1, 384, 12, 12]             768\n",
      "InvertedResidual-873          [-1, 384, 12, 12]               0\n",
      "          Conv2d-874         [-1, 2304, 12, 12]         884,736\n",
      "     BatchNorm2d-875         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-876         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-877         [-1, 2304, 12, 12]          20,736\n",
      "     BatchNorm2d-878         [-1, 2304, 12, 12]           4,608\n",
      "            SiLU-879         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-880             [-1, 96, 1, 1]         221,280\n",
      "            SiLU-881             [-1, 96, 1, 1]               0\n",
      "          Conv2d-882           [-1, 2304, 1, 1]         223,488\n",
      "         Sigmoid-883           [-1, 2304, 1, 1]               0\n",
      "   SqueezeExcite-884         [-1, 2304, 12, 12]               0\n",
      "          Conv2d-885          [-1, 640, 12, 12]       1,474,560\n",
      "     BatchNorm2d-886          [-1, 640, 12, 12]           1,280\n",
      "InvertedResidual-887          [-1, 640, 12, 12]               0\n",
      "          Conv2d-888         [-1, 3840, 12, 12]       2,457,600\n",
      "     BatchNorm2d-889         [-1, 3840, 12, 12]           7,680\n",
      "            SiLU-890         [-1, 3840, 12, 12]               0\n",
      "          Conv2d-891         [-1, 3840, 12, 12]          34,560\n",
      "     BatchNorm2d-892         [-1, 3840, 12, 12]           7,680\n",
      "            SiLU-893         [-1, 3840, 12, 12]               0\n",
      "          Conv2d-894            [-1, 160, 1, 1]         614,560\n",
      "            SiLU-895            [-1, 160, 1, 1]               0\n",
      "          Conv2d-896           [-1, 3840, 1, 1]         618,240\n",
      "         Sigmoid-897           [-1, 3840, 1, 1]               0\n",
      "   SqueezeExcite-898         [-1, 3840, 12, 12]               0\n",
      "          Conv2d-899          [-1, 640, 12, 12]       2,457,600\n",
      "     BatchNorm2d-900          [-1, 640, 12, 12]           1,280\n",
      "InvertedResidual-901          [-1, 640, 12, 12]               0\n",
      "          Conv2d-902         [-1, 3840, 12, 12]       2,457,600\n",
      "     BatchNorm2d-903         [-1, 3840, 12, 12]           7,680\n",
      "            SiLU-904         [-1, 3840, 12, 12]               0\n",
      "          Conv2d-905         [-1, 3840, 12, 12]          34,560\n",
      "     BatchNorm2d-906         [-1, 3840, 12, 12]           7,680\n",
      "            SiLU-907         [-1, 3840, 12, 12]               0\n",
      "          Conv2d-908            [-1, 160, 1, 1]         614,560\n",
      "            SiLU-909            [-1, 160, 1, 1]               0\n",
      "          Conv2d-910           [-1, 3840, 1, 1]         618,240\n",
      "         Sigmoid-911           [-1, 3840, 1, 1]               0\n",
      "   SqueezeExcite-912         [-1, 3840, 12, 12]               0\n",
      "          Conv2d-913          [-1, 640, 12, 12]       2,457,600\n",
      "     BatchNorm2d-914          [-1, 640, 12, 12]           1,280\n",
      "InvertedResidual-915          [-1, 640, 12, 12]               0\n",
      "          Conv2d-916         [-1, 3840, 12, 12]       2,457,600\n",
      "     BatchNorm2d-917         [-1, 3840, 12, 12]           7,680\n",
      "            SiLU-918         [-1, 3840, 12, 12]               0\n",
      "          Conv2d-919         [-1, 3840, 12, 12]          34,560\n",
      "     BatchNorm2d-920         [-1, 3840, 12, 12]           7,680\n",
      "            SiLU-921         [-1, 3840, 12, 12]               0\n",
      "          Conv2d-922            [-1, 160, 1, 1]         614,560\n",
      "            SiLU-923            [-1, 160, 1, 1]               0\n",
      "          Conv2d-924           [-1, 3840, 1, 1]         618,240\n",
      "         Sigmoid-925           [-1, 3840, 1, 1]               0\n",
      "   SqueezeExcite-926         [-1, 3840, 12, 12]               0\n",
      "          Conv2d-927          [-1, 640, 12, 12]       2,457,600\n",
      "     BatchNorm2d-928          [-1, 640, 12, 12]           1,280\n",
      "InvertedResidual-929          [-1, 640, 12, 12]               0\n",
      "          Conv2d-930         [-1, 3840, 12, 12]       2,457,600\n",
      "     BatchNorm2d-931         [-1, 3840, 12, 12]           7,680\n",
      "            SiLU-932         [-1, 3840, 12, 12]               0\n",
      "          Conv2d-933         [-1, 3840, 12, 12]          34,560\n",
      "     BatchNorm2d-934         [-1, 3840, 12, 12]           7,680\n",
      "            SiLU-935         [-1, 3840, 12, 12]               0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Conv2d-936            [-1, 160, 1, 1]         614,560\n",
      "            SiLU-937            [-1, 160, 1, 1]               0\n",
      "          Conv2d-938           [-1, 3840, 1, 1]         618,240\n",
      "         Sigmoid-939           [-1, 3840, 1, 1]               0\n",
      "   SqueezeExcite-940         [-1, 3840, 12, 12]               0\n",
      "          Conv2d-941          [-1, 640, 12, 12]       2,457,600\n",
      "     BatchNorm2d-942          [-1, 640, 12, 12]           1,280\n",
      "InvertedResidual-943          [-1, 640, 12, 12]               0\n",
      "          Conv2d-944         [-1, 3840, 12, 12]       2,457,600\n",
      "     BatchNorm2d-945         [-1, 3840, 12, 12]           7,680\n",
      "            SiLU-946         [-1, 3840, 12, 12]               0\n",
      "          Conv2d-947         [-1, 3840, 12, 12]          34,560\n",
      "     BatchNorm2d-948         [-1, 3840, 12, 12]           7,680\n",
      "            SiLU-949         [-1, 3840, 12, 12]               0\n",
      "          Conv2d-950            [-1, 160, 1, 1]         614,560\n",
      "            SiLU-951            [-1, 160, 1, 1]               0\n",
      "          Conv2d-952           [-1, 3840, 1, 1]         618,240\n",
      "         Sigmoid-953           [-1, 3840, 1, 1]               0\n",
      "   SqueezeExcite-954         [-1, 3840, 12, 12]               0\n",
      "          Conv2d-955          [-1, 640, 12, 12]       2,457,600\n",
      "     BatchNorm2d-956          [-1, 640, 12, 12]           1,280\n",
      "InvertedResidual-957          [-1, 640, 12, 12]               0\n",
      "          Conv2d-958         [-1, 3840, 12, 12]       2,457,600\n",
      "     BatchNorm2d-959         [-1, 3840, 12, 12]           7,680\n",
      "            SiLU-960         [-1, 3840, 12, 12]               0\n",
      "          Conv2d-961         [-1, 3840, 12, 12]          34,560\n",
      "     BatchNorm2d-962         [-1, 3840, 12, 12]           7,680\n",
      "            SiLU-963         [-1, 3840, 12, 12]               0\n",
      "          Conv2d-964            [-1, 160, 1, 1]         614,560\n",
      "            SiLU-965            [-1, 160, 1, 1]               0\n",
      "          Conv2d-966           [-1, 3840, 1, 1]         618,240\n",
      "         Sigmoid-967           [-1, 3840, 1, 1]               0\n",
      "   SqueezeExcite-968         [-1, 3840, 12, 12]               0\n",
      "          Conv2d-969          [-1, 640, 12, 12]       2,457,600\n",
      "     BatchNorm2d-970          [-1, 640, 12, 12]           1,280\n",
      "InvertedResidual-971          [-1, 640, 12, 12]               0\n",
      "          Conv2d-972         [-1, 1280, 12, 12]         819,200\n",
      "     BatchNorm2d-973         [-1, 1280, 12, 12]           2,560\n",
      "            SiLU-974         [-1, 1280, 12, 12]               0\n",
      "AdaptiveAvgPool2d-975           [-1, 1280, 1, 1]               0\n",
      "         Flatten-976                 [-1, 1280]               0\n",
      "SelectAdaptivePool2d-977                 [-1, 1280]               0\n",
      "          Linear-978                    [-1, 1]           1,281\n",
      "    EfficientNet-979                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 117,235,553\n",
      "Trainable params: 117,235,553\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.69\n",
      "Forward/backward pass size (MB): 2745.87\n",
      "Params size (MB): 447.22\n",
      "Estimated Total Size (MB): 3194.77\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#!pip install torchsummary\n",
    "from torchsummary import summary\n",
    "\n",
    "summary(model, (3, 384,384))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "08a7c973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "codModel(\n",
       "  (model): EfficientNet(\n",
       "    (conv_stem): Conv2dSame(3, 24, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (bn1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act1): SiLU(inplace=True)\n",
       "    (blocks): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): ConvBnAct(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): ConvBnAct(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): EdgeResidual(\n",
       "          (conv_exp): Conv2dSame(24, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "          (bn1): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): EdgeResidual(\n",
       "          (conv_exp): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): EdgeResidual(\n",
       "          (conv_exp): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (3): EdgeResidual(\n",
       "          (conv_exp): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): EdgeResidual(\n",
       "          (conv_exp): Conv2dSame(48, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "          (bn1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): EdgeResidual(\n",
       "          (conv_exp): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): EdgeResidual(\n",
       "          (conv_exp): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (3): EdgeResidual(\n",
       "          (conv_exp): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2dSame(256, 256, kernel_size=(3, 3), stride=(2, 2), groups=256, bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (3): InvertedResidual(\n",
       "          (conv_pw): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (4): InvertedResidual(\n",
       "          (conv_pw): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (5): InvertedResidual(\n",
       "          (conv_pw): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
       "          (bn2): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (bn2): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (bn2): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (3): InvertedResidual(\n",
       "          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (bn2): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (4): InvertedResidual(\n",
       "          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (bn2): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (5): InvertedResidual(\n",
       "          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (bn2): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (6): InvertedResidual(\n",
       "          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (bn2): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (7): InvertedResidual(\n",
       "          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (bn2): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (8): InvertedResidual(\n",
       "          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (bn2): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2dSame(960, 960, kernel_size=(3, 3), stride=(2, 2), groups=960, bias=False)\n",
       "          (bn2): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(960, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "          (bn2): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "          (bn2): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (3): InvertedResidual(\n",
       "          (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "          (bn2): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (4): InvertedResidual(\n",
       "          (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "          (bn2): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (5): InvertedResidual(\n",
       "          (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "          (bn2): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (6): InvertedResidual(\n",
       "          (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "          (bn2): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (7): InvertedResidual(\n",
       "          (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "          (bn2): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (8): InvertedResidual(\n",
       "          (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "          (bn2): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (9): InvertedResidual(\n",
       "          (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "          (bn2): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (10): InvertedResidual(\n",
       "          (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "          (bn2): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (11): InvertedResidual(\n",
       "          (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "          (bn2): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (12): InvertedResidual(\n",
       "          (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "          (bn2): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (13): InvertedResidual(\n",
       "          (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "          (bn2): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (14): InvertedResidual(\n",
       "          (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "          (bn2): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv_head): Conv2d(256, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act2): SiLU(inplace=True)\n",
       "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "    (classifier): Linear(in_features=1280, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ed91c03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "tensor([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "tensor([1, 2, 3, 4, 5, 6, 7, 8], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x     = torch.rand((8, 3, 300, 300))\n",
    "labels = torch.from_numpy( np.asarray([1,2,3,4,5,6,7,8]) )\n",
    "print(torch.cuda.is_available())\n",
    "print(labels)\n",
    "                      \n",
    "inputs, labels = x.to(CONFIG.device), labels.to(CONFIG.device)\n",
    "print(labels)\n",
    "model.to(CONFIG.device);\n",
    "\n",
    "model(inputs).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c0a3af",
   "metadata": {},
   "source": [
    "### Kfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0d717c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 382, 2: 522, 3: 509, 4: 624, 5: 806, 6: 540, 7: 546, 8: 477, 9: 327, 10: 217, 11: 122, 12: 55, 13: 26}\n",
      "{1: 382, 2: 522, 3: 509, 4: 624, 5: 806, 6: 540, 7: 546, 8: 477, 9: 327, 10: 217, 11: 122, 12: 55, 13: 26}\n",
      "{1: 382, 2: 522, 3: 509, 4: 624, 5: 806, 6: 540, 7: 546, 8: 477, 9: 327, 10: 217, 11: 122, 12: 55, 13: 26}\n",
      "{1: 382, 2: 522, 3: 509, 4: 624, 5: 806, 6: 540, 7: 546, 8: 477, 9: 327, 10: 217, 11: 122, 12: 55, 13: 26}\n",
      "{1: 382, 2: 522, 3: 509, 4: 624, 5: 806, 6: 540, 7: 546, 8: 477, 9: 327, 10: 217, 11: 122, 12: 55, 13: 26}\n",
      "{1: 382, 2: 522, 3: 509, 4: 624, 5: 806, 6: 540, 7: 546, 8: 477, 9: 327, 10: 217, 11: 122, 12: 55, 13: 26}\n",
      "0       3\n",
      "1       3\n",
      "2       4\n",
      "3       1\n",
      "4       4\n",
      "       ..\n",
      "5148    0\n",
      "5149    0\n",
      "5150    4\n",
      "5151    3\n",
      "5152    4\n",
      "Name: kfold, Length: 5153, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#df = pd.read_csv(f\"{ROOT_DIR}/train_labels.csv\")\n",
    "skf = StratifiedKFold(n_splits=CONFIG.n_fold, shuffle=True, random_state=CONFIG.seed)\n",
    "y_train = df.age.values\n",
    "\n",
    "for fold, ( train_idx, val_idx) in enumerate( skf.split( X=df, y=df.age.values.tolist() ) ):\n",
    "    df.loc[val_idx , \"kfold\"] = int(fold)\n",
    "    unique, counts = np.unique(df.age.values, return_counts=True)\n",
    "    print( dict(zip(unique, counts)) )\n",
    "\n",
    "unique, counts = np.unique(df.age.values, return_counts=True)\n",
    "print( dict(zip(unique, counts)) )\n",
    "df['kfold'] = df['kfold'].astype(int)\n",
    "print(df.kfold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c26320",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8388220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(fold):\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    \n",
    "    train_dataset = codDataset(df_train, transforms=data_transforms['train'])\n",
    "    valid_dataset = codDataset(df_valid, transforms=data_transforms['valid'])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CONFIG.train_batch_size, \n",
    "                              num_workers=0, shuffle=True, pin_memory=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG.valid_batch_size, \n",
    "                              num_workers=0, shuffle=False, pin_memory=True)\n",
    "    \n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830c6b86",
   "metadata": {},
   "source": [
    "### Prepare dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef0003bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7faff498d4a8>\n",
      "torch.Size([8, 3, 384, 384])\n",
      "df_train.shape(4122, 6)\n",
      "train_dataset_tmp:(3, 384, 384)\n",
      "batch1 :(3, 384, 384)\n",
      "dadf1:torch.Size([1, 3, 384, 384])\n"
     ]
    }
   ],
   "source": [
    "train_loader, valid_loader = prepare_data(fold=0)\n",
    "print(train_loader)\n",
    "inputs, classes = next(iter(train_loader))  \n",
    "print(inputs.shape)\n",
    "\n",
    "fold=0\n",
    "train_dataset=None\n",
    "df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "print(\"df_train.shape\"+str( df_train.shape ))\n",
    "train_dataset_tmp = codDataset(df_train, transforms=data_transforms['train'])\n",
    "\n",
    "print(\"train_dataset_tmp:\"+str(train_dataset_tmp[0][0].shape))\n",
    "tmp_loader = DataLoader(train_dataset_tmp, batch_size=1) #, batch_size=CONFIG.train_batch_size, \n",
    "                          #num_workers=0, shuffle=True, pin_memory=True)\n",
    "    \n",
    "print(\"batch1 :\"+str(train_dataset_tmp[0][0].shape))\n",
    "\n",
    "inputs, classes = next(iter(tmp_loader))  \n",
    "print(\"dadf1:\"+str(inputs.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37ab3eb",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68b74a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def binary_accuracy_for_regression(y_true, y_pred):\n",
    "#    return K.mean(K.equal(y_true, K.round(y_pred)), axis=-1)\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4432b7c",
   "metadata": {},
   "source": [
    "### Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a08ea61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n",
    "    model.train()\n",
    "    scaler = amp.GradScaler()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    \n",
    "    loss_fn = nn.MSELoss()\n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for step, (images, labels) in bar:  \n",
    "        #optimizer.zero_grad()\n",
    "        \n",
    "        images = images.to(device, dtype=torch.float)\n",
    "        labels = labels.to(device, dtype=torch.float)\n",
    "        labels = torch.unsqueeze(labels, 1)\n",
    "        \n",
    "        batch_size = images.size(0)\n",
    "        \n",
    "        \n",
    "        with amp.autocast(enabled=True):\n",
    "            outputs = model(images)\n",
    "            #print(\"outputs:+\"+str(outputs))\n",
    "            #print(\"labels:\"+str(labels))\n",
    "            #print(\"mse:\"+str(mean_squared_error(labels.cpu().data.numpy(), outputs.cpu().data.numpy())))\n",
    "            loss = loss_fn(outputs, labels)\n",
    "         \n",
    "        #loss.backward()\n",
    "        #optimizer.step()\n",
    "        \n",
    "        scaler.scale(loss).backward() # Scales loss.  Calls backward() on scaled loss to create scaled gradients\n",
    "        #model.print_debug() #model.classifier.weight[0:10,0]\n",
    "        \n",
    "        # scaler.step() first unscales the gradients of the optimizer's assigned params.\n",
    "        # If these gradients do not contain infs or NaNs, optimizer.step() is then called,\n",
    "        # otherwise, optimizer.step() is skipped.\n",
    "        \n",
    "        scaler.step(optimizer)\n",
    "        scaler.update() # Updates the scale for next iteration.\n",
    "            \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad() # set_to_none=True here can modestly improve performance\n",
    "                \n",
    "        running_loss += loss.item() #(loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss/dataset_size\n",
    "        \n",
    "        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss, LR=optimizer.param_groups[0]['lr'])\n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c631f02",
   "metadata": {},
   "source": [
    "### Test train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "59bbcbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 509/509 [01:52<00:00,  4.54it/s, Epoch=0, LR=0.001, Train_Loss=0.0219]\n"
     ]
    }
   ],
   "source": [
    "def fetch_scheduler(optimizer):\n",
    "    if CONFIG.scheduler == 'CosineAnnealingLR':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=CONFIG.T_max, eta_min=CONFIG.min_lr)\n",
    "    elif CONFIG.scheduler == 'CosineAnnealingWarmRestarts':\n",
    "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=CONFIG.T_0, T_mult=1, eta_min=CONFIG.min_lr)\n",
    "    elif CONFIG.scheduler == None:\n",
    "        return None\n",
    "        \n",
    "    return scheduler\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=CONFIG.learning_rate, weight_decay=CONFIG.weight_decay)\n",
    "scheduler = fetch_scheduler(optimizer)\n",
    "epoch = 0\n",
    "print(CONFIG.device)\n",
    "print(CONFIG.epochs)\n",
    "\n",
    "#for name, param in model.named_parameters():\n",
    "#for param in model.parameters():\n",
    "#    print(str( name ) +\" \"+ str(param.requires_grad))\n",
    " \n",
    "\n",
    "gc.collect()\n",
    "train_epoch_loss = train_one_epoch(model, optimizer, scheduler, \n",
    "                                   dataloader=train_loader, \n",
    "                                   device=CONFIG.device, epoch=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d461afa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "codModel(\n",
      "  (model): EfficientNet(\n",
      "    (conv_stem): Conv2dSame(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "    (bn1): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act1): SiLU(inplace=True)\n",
      "    (blocks): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): ConvBnAct(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): ConvBnAct(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "        )\n",
      "        (2): ConvBnAct(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "        )\n",
      "        (3): ConvBnAct(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): EdgeResidual(\n",
      "          (conv_exp): Conv2dSame(32, 128, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (se): Identity()\n",
      "          (conv_pwl): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (1): EdgeResidual(\n",
      "          (conv_exp): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (se): Identity()\n",
      "          (conv_pwl): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (2): EdgeResidual(\n",
      "          (conv_exp): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (se): Identity()\n",
      "          (conv_pwl): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (3): EdgeResidual(\n",
      "          (conv_exp): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (se): Identity()\n",
      "          (conv_pwl): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (4): EdgeResidual(\n",
      "          (conv_exp): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (se): Identity()\n",
      "          (conv_pwl): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (5): EdgeResidual(\n",
      "          (conv_exp): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (se): Identity()\n",
      "          (conv_pwl): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (6): EdgeResidual(\n",
      "          (conv_exp): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (se): Identity()\n",
      "          (conv_pwl): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): EdgeResidual(\n",
      "          (conv_exp): Conv2dSame(64, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (se): Identity()\n",
      "          (conv_pwl): Conv2d(256, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (1): EdgeResidual(\n",
      "          (conv_exp): Conv2d(96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (se): Identity()\n",
      "          (conv_pwl): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (2): EdgeResidual(\n",
      "          (conv_exp): Conv2d(96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (se): Identity()\n",
      "          (conv_pwl): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (3): EdgeResidual(\n",
      "          (conv_exp): Conv2d(96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (se): Identity()\n",
      "          (conv_pwl): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (4): EdgeResidual(\n",
      "          (conv_exp): Conv2d(96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (se): Identity()\n",
      "          (conv_pwl): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (5): EdgeResidual(\n",
      "          (conv_exp): Conv2d(96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (se): Identity()\n",
      "          (conv_pwl): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (6): EdgeResidual(\n",
      "          (conv_exp): Conv2d(96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (se): Identity()\n",
      "          (conv_pwl): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (conv_pw): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2dSame(384, 384, kernel_size=(3, 3), stride=(2, 2), groups=384, bias=False)\n",
      "          (bn2): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(384, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(24, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (1): InvertedResidual(\n",
      "          (conv_pw): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "          (bn2): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (2): InvertedResidual(\n",
      "          (conv_pw): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "          (bn2): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (3): InvertedResidual(\n",
      "          (conv_pw): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "          (bn2): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (4): InvertedResidual(\n",
      "          (conv_pw): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "          (bn2): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (5): InvertedResidual(\n",
      "          (conv_pw): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "          (bn2): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (6): InvertedResidual(\n",
      "          (conv_pw): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "          (bn2): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (7): InvertedResidual(\n",
      "          (conv_pw): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "          (bn2): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (8): InvertedResidual(\n",
      "          (conv_pw): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "          (bn2): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (9): InvertedResidual(\n",
      "          (conv_pw): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "          (bn2): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
      "          (bn2): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(1152, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (1): InvertedResidual(\n",
      "          (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)\n",
      "          (bn2): BatchNorm2d(1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (2): InvertedResidual(\n",
      "          (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)\n",
      "          (bn2): BatchNorm2d(1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (3): InvertedResidual(\n",
      "          (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)\n",
      "          (bn2): BatchNorm2d(1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (4): InvertedResidual(\n",
      "          (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)\n",
      "          (bn2): BatchNorm2d(1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (5): InvertedResidual(\n",
      "          (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)\n",
      "          (bn2): BatchNorm2d(1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (6): InvertedResidual(\n",
      "          (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)\n",
      "          (bn2): BatchNorm2d(1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (7): InvertedResidual(\n",
      "          (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)\n",
      "          (bn2): BatchNorm2d(1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (8): InvertedResidual(\n",
      "          (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)\n",
      "          (bn2): BatchNorm2d(1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (9): InvertedResidual(\n",
      "          (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)\n",
      "          (bn2): BatchNorm2d(1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (10): InvertedResidual(\n",
      "          (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)\n",
      "          (bn2): BatchNorm2d(1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (11): InvertedResidual(\n",
      "          (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)\n",
      "          (bn2): BatchNorm2d(1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (12): InvertedResidual(\n",
      "          (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)\n",
      "          (bn2): BatchNorm2d(1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (13): InvertedResidual(\n",
      "          (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)\n",
      "          (bn2): BatchNorm2d(1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (14): InvertedResidual(\n",
      "          (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)\n",
      "          (bn2): BatchNorm2d(1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (15): InvertedResidual(\n",
      "          (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)\n",
      "          (bn2): BatchNorm2d(1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (16): InvertedResidual(\n",
      "          (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)\n",
      "          (bn2): BatchNorm2d(1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (17): InvertedResidual(\n",
      "          (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)\n",
      "          (bn2): BatchNorm2d(1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (18): InvertedResidual(\n",
      "          (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)\n",
      "          (bn2): BatchNorm2d(1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (5): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2dSame(1344, 1344, kernel_size=(3, 3), stride=(2, 2), groups=1344, bias=False)\n",
      "          (bn2): BatchNorm2d(1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(1344, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (1): InvertedResidual(\n",
      "          (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n",
      "          (bn2): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (2): InvertedResidual(\n",
      "          (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n",
      "          (bn2): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (3): InvertedResidual(\n",
      "          (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n",
      "          (bn2): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (4): InvertedResidual(\n",
      "          (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n",
      "          (bn2): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (5): InvertedResidual(\n",
      "          (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n",
      "          (bn2): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (6): InvertedResidual(\n",
      "          (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n",
      "          (bn2): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (7): InvertedResidual(\n",
      "          (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n",
      "          (bn2): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (8): InvertedResidual(\n",
      "          (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n",
      "          (bn2): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (9): InvertedResidual(\n",
      "          (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n",
      "          (bn2): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (10): InvertedResidual(\n",
      "          (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n",
      "          (bn2): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (11): InvertedResidual(\n",
      "          (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n",
      "          (bn2): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (12): InvertedResidual(\n",
      "          (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n",
      "          (bn2): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (13): InvertedResidual(\n",
      "          (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n",
      "          (bn2): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (14): InvertedResidual(\n",
      "          (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n",
      "          (bn2): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (15): InvertedResidual(\n",
      "          (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n",
      "          (bn2): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (16): InvertedResidual(\n",
      "          (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n",
      "          (bn2): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (17): InvertedResidual(\n",
      "          (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n",
      "          (bn2): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (18): InvertedResidual(\n",
      "          (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n",
      "          (bn2): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (19): InvertedResidual(\n",
      "          (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n",
      "          (bn2): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (20): InvertedResidual(\n",
      "          (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n",
      "          (bn2): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (21): InvertedResidual(\n",
      "          (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n",
      "          (bn2): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (22): InvertedResidual(\n",
      "          (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n",
      "          (bn2): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (23): InvertedResidual(\n",
      "          (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n",
      "          (bn2): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (24): InvertedResidual(\n",
      "          (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n",
      "          (bn2): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (6): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n",
      "          (bn2): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(2304, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (1): InvertedResidual(\n",
      "          (conv_pw): Conv2d(640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)\n",
      "          (bn2): BatchNorm2d(3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(3840, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(160, 3840, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (2): InvertedResidual(\n",
      "          (conv_pw): Conv2d(640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)\n",
      "          (bn2): BatchNorm2d(3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(3840, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(160, 3840, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (3): InvertedResidual(\n",
      "          (conv_pw): Conv2d(640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)\n",
      "          (bn2): BatchNorm2d(3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(3840, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(160, 3840, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (4): InvertedResidual(\n",
      "          (conv_pw): Conv2d(640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)\n",
      "          (bn2): BatchNorm2d(3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(3840, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(160, 3840, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (5): InvertedResidual(\n",
      "          (conv_pw): Conv2d(640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)\n",
      "          (bn2): BatchNorm2d(3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(3840, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(160, 3840, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (6): InvertedResidual(\n",
      "          (conv_pw): Conv2d(640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_dw): Conv2d(3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)\n",
      "          (bn2): BatchNorm2d(3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): SiLU(inplace=True)\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(3840, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(160, 3840, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv_head): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act2): SiLU(inplace=True)\n",
      "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
      "    (classifier): Linear(in_features=1280, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.001\n",
      "    weight_decay: 1e-06\n",
      ")\n",
      "<torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f87d0660d30>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f87d0a0d940>\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'epoch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-700bd64bd92b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;31m#model, history = run(model, optimizer, scheduler=scheduler, device=CONFIG.device, num_epochs=CONFIG.epochs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#############\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'epoch' is not defined"
     ]
    }
   ],
   "source": [
    "#model, optimizer, scheduler, device, num_epochs\n",
    "\n",
    "def fetch_scheduler(optimizer):\n",
    "    if CONFIG.scheduler == 'CosineAnnealingLR':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=CONFIG.T_max, eta_min=CONFIG.min_lr)\n",
    "    elif CONFIG.scheduler == 'CosineAnnealingWarmRestarts':\n",
    "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=CONFIG.T_0, T_mult=1, eta_min=CONFIG.min_lr)\n",
    "    elif CONFIG.scheduler == None:\n",
    "        return None\n",
    "        \n",
    "    return scheduler\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=CONFIG.learning_rate, weight_decay=CONFIG.weight_decay)\n",
    "scheduler = fetch_scheduler(optimizer)\n",
    "\n",
    "print( model )\n",
    "print( optimizer )\n",
    "print( scheduler )\n",
    "print( train_loader )\n",
    "print( epoch )\n",
    "#model, history = run(model, optimizer, scheduler=scheduler, device=CONFIG.device, num_epochs=CONFIG.epochs)\n",
    "#############\n",
    "\n",
    "#train_epoch_loss = train_one_epoch(model, optimizer, scheduler, \n",
    "#                       dataloader=train_loader, \n",
    "#                       device=CONFIG.device, epoch=epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cb63a5",
   "metadata": {},
   "source": [
    "### Validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31712a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "@torch.no_grad()\n",
    "def valid_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n",
    "    model.eval()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    TARGETS = []\n",
    "    PREDS = []\n",
    "    \n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for step, (images, labels) in bar: \n",
    "        #print(\"images:\"+str(images.shape))\n",
    "        #print(\"labels:\"+str(labels.shape))\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        labels = torch.unsqueeze(labels, 1)\n",
    "        #print(\"labels.shape:\"+str(labels.shape))\n",
    "        \n",
    "        batch_size = images.size(0)\n",
    "        #print(\"batch_size:\"+str(batch_size))\n",
    "\n",
    "        \n",
    "        outputs = model(images)\n",
    "        #print(\"outputs:+\"+str(outputs))\n",
    "        #print(\"labels:\"+str(labels))\n",
    "        #print(\"mse:\"+str(mean_squared_error(labels.cpu().data.numpy(), outputs.cpu().data.numpy())))\n",
    "            \n",
    "        #print(\"outputs:\"+str(outputs.shape))\n",
    "        #outputs = torch.squeeze(outputs)\n",
    "        loss = nn.MSELoss()(outputs, labels)\n",
    "        #loss = criterion(outputs.view(-1), labels)\n",
    "        \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss/dataset_size\n",
    "        \n",
    "        PREDS.append(outputs.cpu().detach().numpy())\n",
    "        TARGETS.append(labels.view(-1).cpu().detach().numpy())\n",
    "        \n",
    "        bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss,\n",
    "                        LR=optimizer.param_groups[0]['lr'])   \n",
    "    \n",
    "    TARGETS = np.concatenate(TARGETS)\n",
    "    PREDS = np.concatenate(PREDS)\n",
    "    PREDS = np.squeeze(PREDS)\n",
    "    \n",
    "    #print(type(PREDS[0]))\n",
    "    #print(type(TARGETS[0]))\n",
    "    #print(PREDS.shape)\n",
    "    #print(TARGETS.shape)\n",
    "    print(\"preds:\"+str(PREDS[:-10]))\n",
    "    print(\"target:\"+str(TARGETS[:-10]))\n",
    "    print(\"max:\"+str(np.max( PREDS )))\n",
    "    print(\"mean:\"+str(np.mean( PREDS )))\n",
    "    \n",
    "    PREDS = PREDS.round()\n",
    "    val_auc = accuracy_score(TARGETS, PREDS) #roc_auc_score(TARGETS, PREDS)\n",
    "    mse_score = mean_squared_error(TARGETS, PREDS)\n",
    "    print(val_auc)\n",
    "    print(mse_score)\n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss , val_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1eff9f1",
   "metadata": {},
   "source": [
    "### Test validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6735bd8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 509/509 [00:56<00:00,  9.08it/s, Epoch=0, LR=0.001, Valid_Loss=0.235]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[3.5345225 4.952975  5.3617673 ... 5.6906924 4.212286  3.5432181]\n",
      "target:[3. 5. 5. ... 6. 4. 4.]\n",
      "max:13.21456\n",
      "mean:5.4454145\n",
      "0.7266699410609038\n",
      "0.29862475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=CONFIG.learning_rate, weight_decay=CONFIG.weight_decay)\n",
    "scheduler = fetch_scheduler(optimizer)\n",
    "epoch = 0\n",
    "print(CONFIG.device)\n",
    "print(CONFIG.epochs)\n",
    "\n",
    "gc.collect()\n",
    "train_epoch_loss, acc_score = valid_one_epoch(model, optimizer, scheduler, \n",
    "                                   dataloader=train_loader, \n",
    "                                   device=CONFIG.device, epoch=epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63afb20b",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "278c1dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@logger.catch\n",
    "def run(model, optimizer, scheduler, device, num_epochs):    \n",
    "    start = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_epoch_auc = 0\n",
    "    history = defaultdict(list)\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1): \n",
    "        gc.collect()\n",
    "        train_epoch_loss = train_one_epoch(model, optimizer, scheduler, \n",
    "                                           dataloader=train_loader, \n",
    "                                           device=CONFIG.device, epoch=epoch)\n",
    "        \n",
    "        valid_epoch_loss, acc_score = valid_one_epoch(model, optimizer, scheduler,\n",
    "                                                            dataloader=valid_loader, \n",
    "                                                            device=CONFIG.device, epoch=epoch)\n",
    "    \n",
    "        history['Train Loss'].append(train_epoch_loss)\n",
    "        history['Valid Loss'].append(valid_epoch_loss)\n",
    "        history['Valid AUC'].append(acc_score) #valid_epoch_auc)\n",
    "        \n",
    "        #print(f'Valid AUC: {valid_epoch_auc}')\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        \n",
    "        # deep copy the model\n",
    "        if acc_score >= best_epoch_auc:\n",
    "            print(f\"{b_}Validation AUC Improved ({best_epoch_auc} ---> {acc_score})\")\n",
    "            best_epoch_auc = acc_score\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            PATH = \"AUC{:.4f}_epoch{:.0f}.bin\".format(best_epoch_auc, epoch)\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "            print(\"Model Saved\")\n",
    "            \n",
    "        print()\n",
    "    \n",
    "    end = time.time()\n",
    "    time_elapsed = end - start\n",
    "    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "    print(\"Best AUC: {:.4f}\".format(best_epoch_auc))\n",
    "    \n",
    "    # load best model weights\n",
    "    #model.load_state_dict(best_model_wts)\n",
    "    #print(model.classifier.weight[0:10,0])\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b6db47",
   "metadata": {},
   "source": [
    "### Train fold 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "7023c5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.is_available() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353082af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:19<00:00,  1.36it/s, Epoch=1, LR=1e-5, Train_Loss=0.00477]\n",
      "100%|██████████| 129/129 [00:25<00:00,  5.01it/s, Epoch=1, LR=1e-5, Valid_Loss=0.388]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.7540708  3.3989155  7.411528  ...  4.0649805  4.197875  10.304616 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.48343\n",
      "mean:5.3450212\n",
      "0.6702230843840931\n",
      "0.4500485\n",
      "\u001b[34mValidation AUC Improved (0 ---> 0.6702230843840931)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:18<00:00,  1.36it/s, Epoch=2, LR=9.78e-6, Train_Loss=0.00423]\n",
      "100%|██████████| 129/129 [00:25<00:00,  5.01it/s, Epoch=2, LR=9.78e-6, Valid_Loss=0.39] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.739422   3.3948092  7.350868  ...  4.140256   4.2930045 10.224243 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.357709\n",
      "mean:5.3426456\n",
      "0.6702230843840931\n",
      "0.4471387\n",
      "\u001b[34mValidation AUC Improved (0.6702230843840931 ---> 0.6702230843840931)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:18<00:00,  1.36it/s, Epoch=3, LR=9.14e-6, Train_Loss=0.00387]\n",
      "100%|██████████| 129/129 [00:25<00:00,  5.01it/s, Epoch=3, LR=9.14e-6, Valid_Loss=0.388]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.7920833  3.4171002  7.3116574 ...  4.143195   4.291913  10.316884 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.431038\n",
      "mean:5.3598304\n",
      "0.6673132880698351\n",
      "0.4500485\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:16<00:00,  1.37it/s, Epoch=4, LR=8.15e-6, Train_Loss=0.0037] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.02it/s, Epoch=4, LR=8.15e-6, Valid_Loss=0.389]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.6979475  3.3827474  7.332579  ...  4.1170483  4.28906   10.279778 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.347037\n",
      "mean:5.3279877\n",
      "0.6789524733268671\n",
      "0.4325897\n",
      "\u001b[34mValidation AUC Improved (0.6702230843840931 ---> 0.6789524733268671)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:18<00:00,  1.36it/s, Epoch=5, LR=6.89e-6, Train_Loss=0.00346]\n",
      "100%|██████████| 129/129 [00:26<00:00,  4.94it/s, Epoch=5, LR=6.89e-6, Valid_Loss=0.386]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.8005114  3.4315982  7.328986  ...  4.155705   4.3308215 10.299559 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.395465\n",
      "mean:5.3644896\n",
      "0.6731328806983511\n",
      "0.44422892\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:17<00:00,  1.37it/s, Epoch=6, LR=5.5e-6, Train_Loss=0.00334]\n",
      "100%|██████████| 129/129 [00:25<00:00,  4.99it/s, Epoch=6, LR=5.5e-6, Valid_Loss=0.383]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.7815013  3.4268467  7.3396187 ...  4.142196   4.366044  10.341423 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.443561\n",
      "mean:5.372664\n",
      "0.6702230843840931\n",
      "0.4413191\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:19<00:00,  1.36it/s, Epoch=7, LR=4.11e-6, Train_Loss=0.00338]\n",
      "100%|██████████| 129/129 [00:25<00:00,  5.00it/s, Epoch=7, LR=4.11e-6, Valid_Loss=0.398]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.6386704  3.3503568  7.275329  ...  4.0498962  4.2332797 10.178237 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.298567\n",
      "mean:5.285789\n",
      "0.6682832201745877\n",
      "0.44907856\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:18<00:00,  1.36it/s, Epoch=8, LR=2.85e-6, Train_Loss=0.00325]\n",
      "100%|██████████| 129/129 [00:25<00:00,  5.01it/s, Epoch=8, LR=2.85e-6, Valid_Loss=0.384]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.7921867  3.3998098  7.339486  ...  4.126365   4.363111  10.377405 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.421927\n",
      "mean:5.37039\n",
      "0.6702230843840931\n",
      "0.4413191\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:18<00:00,  1.36it/s, Epoch=9, LR=1.86e-6, Train_Loss=0.00317]\n",
      "100%|██████████| 129/129 [00:25<00:00,  4.96it/s, Epoch=9, LR=1.86e-6, Valid_Loss=0.384]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.804842   3.433349   7.403352  ...  4.158203   4.3948026 10.330835 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.451564\n",
      "mean:5.382047\n",
      "0.6750727449078564\n",
      "0.43937925\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:18<00:00,  1.36it/s, Epoch=10, LR=1.22e-6, Train_Loss=0.00323]\n",
      "100%|██████████| 129/129 [00:25<00:00,  4.99it/s, Epoch=10, LR=1.22e-6, Valid_Loss=0.387]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.7078815  3.406668   7.3766294 ...  4.1328864  4.3426814 10.286626 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.378037\n",
      "mean:5.35807\n",
      "0.6799224054316197\n",
      "0.43452957\n",
      "\u001b[34mValidation AUC Improved (0.6789524733268671 ---> 0.6799224054316197)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:16<00:00,  1.37it/s, Epoch=11, LR=1e-6, Train_Loss=0.00311]\n",
      "100%|██████████| 129/129 [00:26<00:00,  4.96it/s, Epoch=11, LR=1e-6, Valid_Loss=0.39] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.7252536  3.402988   7.2577333 ...  4.1234503  4.307394  10.300544 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.381261\n",
      "mean:5.3433003\n",
      "0.6770126091173618\n",
      "0.43743938\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:18<00:00,  1.36it/s, Epoch=12, LR=1.22e-6, Train_Loss=0.0031] \n",
      "100%|██████████| 129/129 [00:25<00:00,  4.98it/s, Epoch=12, LR=1.22e-6, Valid_Loss=0.389]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.67639    3.3735304  7.320603  ...  4.0817647  4.2976856 10.268105 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.347628\n",
      "mean:5.3259788\n",
      "0.6789524733268671\n",
      "0.43549952\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:19<00:00,  1.36it/s, Epoch=13, LR=1.86e-6, Train_Loss=0.00314]\n",
      "100%|██████████| 129/129 [00:25<00:00,  5.00it/s, Epoch=13, LR=1.86e-6, Valid_Loss=0.392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.717545   3.3853948  7.289568  ...  4.1212373  4.3030066 10.275415 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.333225\n",
      "mean:5.333383\n",
      "0.6779825412221144\n",
      "0.43646944\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:19<00:00,  1.36it/s, Epoch=14, LR=2.85e-6, Train_Loss=0.00305]\n",
      "100%|██████████| 129/129 [00:25<00:00,  4.99it/s, Epoch=14, LR=2.85e-6, Valid_Loss=0.387]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.6833444  3.3753643  7.3004875 ...  4.0998755  4.3427935 10.239875 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.315797\n",
      "mean:5.3238606\n",
      "0.6750727449078564\n",
      "0.43937925\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:17<00:00,  1.37it/s, Epoch=26, LR=5.5e-6, Train_Loss=0.00243]]\n",
      "100%|██████████| 129/129 [00:25<00:00,  4.97it/s, Epoch=26, LR=5.5e-6, Valid_Loss=0.39] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.732145   3.4002771  7.3004336 ...  4.1215177  4.3073606 10.301582 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.422595\n",
      "mean:5.357899\n",
      "0.6731328806983511\n",
      "0.4413191\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:18<00:00,  1.36it/s, Epoch=27, LR=4.11e-6, Train_Loss=0.00255]\n",
      "100%|██████████| 129/129 [00:25<00:00,  5.00it/s, Epoch=27, LR=4.11e-6, Valid_Loss=0.386]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.6683598  3.3679855  7.398256  ...  4.1257753  4.331003  10.332233 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.443013\n",
      "mean:5.3547983\n",
      "0.6847720659553831\n",
      "0.42386034\n",
      "\u001b[34mValidation AUC Improved (0.6808923375363725 ---> 0.6847720659553831)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:19<00:00,  1.36it/s, Epoch=28, LR=2.85e-6, Train_Loss=0.00236]\n",
      "100%|██████████| 129/129 [00:25<00:00,  5.00it/s, Epoch=28, LR=2.85e-6, Valid_Loss=0.392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.6472106  3.343819   7.25678   ...  4.06415    4.296952  10.28902  ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.35234\n",
      "mean:5.3151927\n",
      "0.6779825412221144\n",
      "0.44228905\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:18<00:00,  1.36it/s, Epoch=29, LR=1.86e-6, Train_Loss=0.00235] \n",
      "100%|██████████| 129/129 [00:25<00:00,  4.98it/s, Epoch=29, LR=1.86e-6, Valid_Loss=0.385]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.751461   3.416831   7.366811  ...  4.1777496  4.3648634 10.364505 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.482877\n",
      "mean:5.367734\n",
      "0.6818622696411252\n",
      "0.42677012\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:18<00:00,  1.36it/s, Epoch=30, LR=1.22e-6, Train_Loss=0.00233] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.00it/s, Epoch=30, LR=1.22e-6, Valid_Loss=0.386]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.6745825  3.3872862  7.379012  ...  4.1363883  4.3340654 10.317172 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.445979\n",
      "mean:5.3588037\n",
      "0.6789524733268671\n",
      "0.42967993\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:17<00:00,  1.37it/s, Epoch=31, LR=1e-6, Train_Loss=0.0024]  \n",
      "100%|██████████| 129/129 [00:25<00:00,  4.98it/s, Epoch=31, LR=1e-6, Valid_Loss=0.385]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.780329   3.3713562  7.3905745 ...  4.1256533  4.352226  10.41288  ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.505951\n",
      "mean:5.3574014\n",
      "0.6770126091173618\n",
      "0.43452957\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:17<00:00,  1.37it/s, Epoch=32, LR=1.22e-6, Train_Loss=0.00231] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.01it/s, Epoch=32, LR=1.22e-6, Valid_Loss=0.392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.688496   3.4053104  7.3093944 ...  4.127195   4.2989    10.281754 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.4160185\n",
      "mean:5.3468018\n",
      "0.6750727449078564\n",
      "0.43646944\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:17<00:00,  1.37it/s, Epoch=33, LR=1.86e-6, Train_Loss=0.00229]\n",
      "100%|██████████| 129/129 [00:25<00:00,  4.99it/s, Epoch=33, LR=1.86e-6, Valid_Loss=0.386]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.7339497  3.417321   7.359008  ...  4.185191   4.387826  10.329022 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.441704\n",
      "mean:5.3690624\n",
      "0.6799224054316197\n",
      "0.42870998\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:18<00:00,  1.36it/s, Epoch=34, LR=2.85e-6, Train_Loss=0.00229] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.00it/s, Epoch=34, LR=2.85e-6, Valid_Loss=0.391]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.687224   3.3383603  7.373734  ...  4.0579033  4.2928705 10.302074 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.419638\n",
      "mean:5.3295536\n",
      "0.6760426770126091\n",
      "0.43549952\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:20<00:00,  1.36it/s, Epoch=35, LR=4.11e-6, Train_Loss=0.00239]\n",
      "100%|██████████| 129/129 [00:25<00:00,  4.98it/s, Epoch=35, LR=4.11e-6, Valid_Loss=0.389]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.7057652  3.3675659  7.3705034 ...  4.1222324  4.3754854 10.346544 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.456508\n",
      "mean:5.344878\n",
      "0.6770126091173618\n",
      "0.4316198\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:17<00:00,  1.37it/s, Epoch=36, LR=5.5e-6, Train_Loss=0.00224] \n",
      "100%|██████████| 129/129 [00:25<00:00,  4.98it/s, Epoch=36, LR=5.5e-6, Valid_Loss=0.387]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.737141   3.4130151  7.306236  ...  4.1362967  4.3451233 10.308706 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.48364\n",
      "mean:5.3640223\n",
      "0.6741028128031038\n",
      "0.43743938\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:18<00:00,  1.36it/s, Epoch=37, LR=6.89e-6, Train_Loss=0.00228] \n",
      "100%|██████████| 129/129 [00:25<00:00,  4.99it/s, Epoch=37, LR=6.89e-6, Valid_Loss=0.387]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.7485223  3.4047327  7.363188  ...  4.155101   4.3823743 10.32072  ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.471971\n",
      "mean:5.3534794\n",
      "0.6741028128031038\n",
      "0.4316198\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:21<00:00,  1.35it/s, Epoch=38, LR=8.15e-6, Train_Loss=0.00224] \n",
      "100%|██████████| 129/129 [00:25<00:00,  4.99it/s, Epoch=38, LR=8.15e-6, Valid_Loss=0.388]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.7867885  3.4505792  7.36723   ...  4.1689706  4.396668  10.327638 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.475318\n",
      "mean:5.376959\n",
      "0.6702230843840931\n",
      "0.4384093\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:18<00:00,  1.36it/s, Epoch=39, LR=9.14e-6, Train_Loss=0.00227] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.00it/s, Epoch=39, LR=9.14e-6, Valid_Loss=0.387]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.7179613  3.3621414  7.4022975 ...  4.131786   4.400406  10.31693  ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.4551525\n",
      "mean:5.3351564\n",
      "0.6760426770126091\n",
      "0.4384093\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:19<00:00,  1.36it/s, Epoch=40, LR=9.78e-6, Train_Loss=0.00224]\n",
      "100%|██████████| 129/129 [00:25<00:00,  5.03it/s, Epoch=40, LR=9.78e-6, Valid_Loss=0.39] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.6674542  3.3630717  7.320576  ...  4.11427    4.3455005 10.29122  ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.474516\n",
      "mean:5.3340287\n",
      "0.6770126091173618\n",
      "0.4316198\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:19<00:00,  1.36it/s, Epoch=41, LR=1e-5, Train_Loss=0.00215] \n",
      "100%|██████████| 129/129 [00:25<00:00,  4.97it/s, Epoch=41, LR=1e-5, Valid_Loss=0.393]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.711307   3.3636408  7.378216  ...  4.1290674  4.331415  10.320533 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.430218\n",
      "mean:5.3561096\n",
      "0.6711930164888458\n",
      "0.44325897\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:17<00:00,  1.37it/s, Epoch=42, LR=9.78e-6, Train_Loss=0.00222] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.00it/s, Epoch=42, LR=9.78e-6, Valid_Loss=0.391]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.7255163  3.4026275  7.3554597 ...  4.1813745  4.3979797 10.314397 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.445083\n",
      "mean:5.377757\n",
      "0.6663433559650824\n",
      "0.45101842\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:18<00:00,  1.36it/s, Epoch=43, LR=9.14e-6, Train_Loss=0.00216] \n",
      "100%|██████████| 129/129 [00:25<00:00,  4.98it/s, Epoch=43, LR=9.14e-6, Valid_Loss=0.394]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.663708   3.3669362  7.3097086 ...  4.1012     4.3121014 10.279423 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.400893\n",
      "mean:5.302216\n",
      "0.6711930164888458\n",
      "0.44616878\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:17<00:00,  1.37it/s, Epoch=44, LR=8.15e-6, Train_Loss=0.00219] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.00it/s, Epoch=44, LR=8.15e-6, Valid_Loss=0.398]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.618504   3.3430479  7.309884  ...  4.120005   4.307698  10.304092 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.347497\n",
      "mean:5.322529\n",
      "0.6682832201745877\n",
      "0.44907856\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:17<00:00,  1.37it/s, Epoch=45, LR=6.89e-6, Train_Loss=0.00211] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.01it/s, Epoch=45, LR=6.89e-6, Valid_Loss=0.389]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.720135   3.3817613  7.391586  ...  4.1562014  4.3773923 10.315609 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.446933\n",
      "mean:5.343185\n",
      "0.6760426770126091\n",
      "0.4384093\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:17<00:00,  1.37it/s, Epoch=46, LR=5.5e-6, Train_Loss=0.0021]  \n",
      "100%|██████████| 129/129 [00:25<00:00,  4.99it/s, Epoch=46, LR=5.5e-6, Valid_Loss=0.389]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.6892543  3.3425941  7.4411216 ...  4.1425     4.396345  10.307385 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.422848\n",
      "mean:5.3416605\n",
      "0.6750727449078564\n",
      "0.43937925\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:19<00:00,  1.36it/s, Epoch=47, LR=4.11e-6, Train_Loss=0.00205] \n",
      "100%|██████████| 129/129 [00:25<00:00,  4.98it/s, Epoch=47, LR=4.11e-6, Valid_Loss=0.396]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.7036877  3.3971093  7.4192424 ...  4.203711   4.4362097 10.305718 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.405528\n",
      "mean:5.365822\n",
      "0.6692531522793405\n",
      "0.44810864\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:19<00:00,  1.36it/s, Epoch=48, LR=2.85e-6, Train_Loss=0.00208] \n",
      "100%|██████████| 129/129 [00:25<00:00,  4.99it/s, Epoch=48, LR=2.85e-6, Valid_Loss=0.39] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.691193   3.375066   7.4328017 ...  4.162767   4.4147763 10.280654 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.432398\n",
      "mean:5.3418093\n",
      "0.6799224054316197\n",
      "0.4316198\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:19<00:00,  1.36it/s, Epoch=49, LR=1.86e-6, Train_Loss=0.00208]\n",
      "100%|██████████| 129/129 [00:25<00:00,  4.96it/s, Epoch=49, LR=1.86e-6, Valid_Loss=0.387]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.708913   3.3878279  7.415676  ...  4.171885   4.427388  10.335408 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.464787\n",
      "mean:5.350584\n",
      "0.6741028128031038\n",
      "0.4316198\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:18<00:00,  1.36it/s, Epoch=50, LR=1.22e-6, Train_Loss=0.00204] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.00it/s, Epoch=50, LR=1.22e-6, Valid_Loss=0.398]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.7000227  3.364379   7.362536  ...  4.1419654  4.396925  10.27615  ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.404731\n",
      "mean:5.333291\n",
      "0.6653734238603298\n",
      "0.45198837\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:17<00:00,  1.37it/s, Epoch=51, LR=1e-6, Train_Loss=0.00199]\n",
      "100%|██████████| 129/129 [00:25<00:00,  4.99it/s, Epoch=51, LR=1e-6, Valid_Loss=0.392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.661279   3.342726   7.425661  ...  4.1441116  4.4034104 10.293965 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.434725\n",
      "mean:5.330653\n",
      "0.6808923375363725\n",
      "0.43646944\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:17<00:00,  1.37it/s, Epoch=52, LR=1.22e-6, Train_Loss=0.00205] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.01it/s, Epoch=52, LR=1.22e-6, Valid_Loss=0.391]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.696296   3.3935654  7.41037   ...  4.1777406  4.4198675 10.312386 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.469161\n",
      "mean:5.35478\n",
      "0.6770126091173618\n",
      "0.44034916\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:18<00:00,  1.36it/s, Epoch=53, LR=1.86e-6, Train_Loss=0.00208] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.00it/s, Epoch=53, LR=1.86e-6, Valid_Loss=0.419]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.65957    3.3434596  7.3394623 ...  4.101297   4.3640676 10.301101 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.392034\n",
      "mean:5.342217\n",
      "0.6605237633365665\n",
      "0.45974782\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:17<00:00,  1.37it/s, Epoch=54, LR=2.85e-6, Train_Loss=0.00202]\n",
      "100%|██████████| 129/129 [00:25<00:00,  5.01it/s, Epoch=54, LR=2.85e-6, Valid_Loss=0.393]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.7295775  3.3552682  7.4104066 ...  4.1568775  4.427939  10.329881 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.4012575\n",
      "mean:5.3535967\n",
      "0.6721629485935985\n",
      "0.44519883\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:17<00:00,  1.37it/s, Epoch=55, LR=4.11e-6, Train_Loss=0.00431] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.01it/s, Epoch=55, LR=4.11e-6, Valid_Loss=0.395]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.6819882  3.3560019  7.3911576 ...  4.1208186  4.3619094 10.263217 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.4176655\n",
      "mean:5.313293\n",
      "0.6731328806983511\n",
      "0.44422892\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:21<00:00,  1.35it/s, Epoch=56, LR=5.5e-6, Train_Loss=0.00199] \n",
      "100%|██████████| 129/129 [00:25<00:00,  4.99it/s, Epoch=56, LR=5.5e-6, Valid_Loss=0.386]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.756808  3.382113  7.461086 ...  4.170951  4.442944 10.345708]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.509732\n",
      "mean:5.3604264\n",
      "0.6779825412221144\n",
      "0.42774007\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:19<00:00,  1.36it/s, Epoch=57, LR=6.89e-6, Train_Loss=0.00205] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.00it/s, Epoch=57, LR=6.89e-6, Valid_Loss=0.391]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.769517   3.351615   7.448844  ...  4.1391077  4.387164  10.323402 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.460472\n",
      "mean:5.3389606\n",
      "0.6731328806983511\n",
      "0.4413191\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:19<00:00,  1.36it/s, Epoch=58, LR=8.15e-6, Train_Loss=0.002]   \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.00it/s, Epoch=58, LR=8.15e-6, Valid_Loss=0.396]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.6782837  3.3245134  7.402624  ...  4.0838943  4.340304  10.306136 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.430595\n",
      "mean:5.323228\n",
      "0.6702230843840931\n",
      "0.44422892\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:18<00:00,  1.36it/s, Epoch=59, LR=9.14e-6, Train_Loss=0.002]   \n",
      "100%|██████████| 129/129 [00:25<00:00,  4.96it/s, Epoch=59, LR=9.14e-6, Valid_Loss=0.391]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.702074   3.3524904  7.384734  ...  4.148712   4.40718   10.286736 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.40563\n",
      "mean:5.3350763\n",
      "0.6808923375363725\n",
      "0.43064985\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:20<00:00,  1.36it/s, Epoch=60, LR=9.78e-6, Train_Loss=0.002]   \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.00it/s, Epoch=60, LR=9.78e-6, Valid_Loss=0.393]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.733081   3.3656046  7.4617977 ...  4.130547   4.384616  10.282937 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.456488\n",
      "mean:5.333917\n",
      "0.6741028128031038\n",
      "0.44034916\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:19<00:00,  1.36it/s, Epoch=61, LR=1e-5, Train_Loss=0.00191] \n",
      "100%|██████████| 129/129 [00:26<00:00,  4.95it/s, Epoch=61, LR=1e-5, Valid_Loss=0.392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.682942   3.3822453  7.4223304 ...  4.147717   4.4240904 10.301211 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.496738\n",
      "mean:5.3406262\n",
      "0.6750727449078564\n",
      "0.44228905\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:19<00:00,  1.36it/s, Epoch=62, LR=9.78e-6, Train_Loss=0.00193] \n",
      "100%|██████████| 129/129 [00:25<00:00,  4.98it/s, Epoch=62, LR=9.78e-6, Valid_Loss=0.389]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.796067   3.3857691  7.3957267 ...  4.155001   4.4556246 10.35747  ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.517646\n",
      "mean:5.354876\n",
      "0.6750727449078564\n",
      "0.43937925\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:19<00:00,  1.36it/s, Epoch=63, LR=9.14e-6, Train_Loss=0.00192] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.00it/s, Epoch=63, LR=9.14e-6, Valid_Loss=0.395]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.733392   3.4086075  7.431173  ...  4.1921935  4.436204  10.2983055]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.500763\n",
      "mean:5.3594584\n",
      "0.6721629485935985\n",
      "0.44810864\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:19<00:00,  1.36it/s, Epoch=64, LR=8.15e-6, Train_Loss=0.00188] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.00it/s, Epoch=64, LR=8.15e-6, Valid_Loss=0.393]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.7409725  3.3825734  7.4995747 ...  4.192767   4.428152  10.346868 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.484163\n",
      "mean:5.3511786\n",
      "0.6741028128031038\n",
      "0.44325897\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:17<00:00,  1.37it/s, Epoch=65, LR=6.89e-6, Train_Loss=0.00191] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.00it/s, Epoch=65, LR=6.89e-6, Valid_Loss=0.399]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.7785068  3.4059064  7.395936  ...  4.1663365  4.4033713 10.34149  ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.485707\n",
      "mean:5.346305\n",
      "0.6673132880698351\n",
      "0.4500485\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:18<00:00,  1.36it/s, Epoch=66, LR=5.5e-6, Train_Loss=0.00193] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.00it/s, Epoch=66, LR=5.5e-6, Valid_Loss=0.393]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.732347   3.3883078  7.441917  ...  4.1579814  4.419964  10.283798 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.433807\n",
      "mean:5.338895\n",
      "0.6702230843840931\n",
      "0.4471387\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:18<00:00,  1.36it/s, Epoch=67, LR=4.11e-6, Train_Loss=0.00188] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.00it/s, Epoch=67, LR=4.11e-6, Valid_Loss=0.392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.7409387  3.3530521  7.499901  ...  4.14204    4.432592  10.329131 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.490803\n",
      "mean:5.347516\n",
      "0.6760426770126091\n",
      "0.4413191\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:18<00:00,  1.36it/s, Epoch=68, LR=2.85e-6, Train_Loss=0.00186] \n",
      "100%|██████████| 129/129 [00:25<00:00,  4.96it/s, Epoch=68, LR=2.85e-6, Valid_Loss=0.39] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.7887974  3.4141066  7.503492  ...  4.2175665  4.453096  10.37798  ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.535517\n",
      "mean:5.369667\n",
      "0.6750727449078564\n",
      "0.43937925\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:19<00:00,  1.36it/s, Epoch=69, LR=1.86e-6, Train_Loss=0.00185] \n",
      "100%|██████████| 129/129 [00:25<00:00,  4.97it/s, Epoch=69, LR=1.86e-6, Valid_Loss=0.397]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.685049   3.3674648  7.4252076 ...  4.1267877  4.3832936 10.255815 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.430461\n",
      "mean:5.3220906\n",
      "0.6692531522793405\n",
      "0.44810864\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:18<00:00,  1.36it/s, Epoch=70, LR=1.22e-6, Train_Loss=0.00183] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.00it/s, Epoch=70, LR=1.22e-6, Valid_Loss=0.392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.768049   3.4100013  7.4154572 ...  4.1876545  4.43526   10.3327465]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.484823\n",
      "mean:5.3487344\n",
      "0.6711930164888458\n",
      "0.44325897\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:18<00:00,  1.36it/s, Epoch=71, LR=1e-6, Train_Loss=0.00184] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.02it/s, Epoch=71, LR=1e-6, Valid_Loss=0.392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.739176   3.401116   7.4070897 ...  4.1567664  4.409828  10.31188  ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.502056\n",
      "mean:5.348697\n",
      "0.6711930164888458\n",
      "0.44034916\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:17<00:00,  1.37it/s, Epoch=72, LR=1.22e-6, Train_Loss=0.00183]\n",
      "100%|██████████| 129/129 [00:25<00:00,  5.00it/s, Epoch=72, LR=1.22e-6, Valid_Loss=0.395]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.6549296  3.3667274  7.3785543 ...  4.151425   4.3862424 10.248174 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.3946905\n",
      "mean:5.3174167\n",
      "0.6702230843840931\n",
      "0.4471387\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:18<00:00,  1.36it/s, Epoch=73, LR=1.86e-6, Train_Loss=0.00182] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.01it/s, Epoch=73, LR=1.86e-6, Valid_Loss=0.413]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.7875557  3.4010236  7.457622  ...  4.1980205  4.436604  10.317677 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.489111\n",
      "mean:5.3809056\n",
      "0.6605237633365665\n",
      "0.4655674\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:17<00:00,  1.37it/s, Epoch=74, LR=2.85e-6, Train_Loss=0.0018]  \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.01it/s, Epoch=74, LR=2.85e-6, Valid_Loss=0.394]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.696413   3.3575277  7.4328837 ...  4.1449842  4.3816247 10.293353 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.448395\n",
      "mean:5.325733\n",
      "0.6682832201745877\n",
      "0.44907856\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:19<00:00,  1.36it/s, Epoch=75, LR=4.11e-6, Train_Loss=0.00181] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.01it/s, Epoch=75, LR=4.11e-6, Valid_Loss=0.393]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.720771   3.3782518  7.472308  ...  4.1812897  4.4304037 10.319777 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.472248\n",
      "mean:5.349283\n",
      "0.6741028128031038\n",
      "0.44325897\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:17<00:00,  1.37it/s, Epoch=76, LR=5.5e-6, Train_Loss=0.00184] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.01it/s, Epoch=76, LR=5.5e-6, Valid_Loss=0.393]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.7087417  3.3466728  7.4422326 ...  4.110146   4.37302   10.244171 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.422782\n",
      "mean:5.3278723\n",
      "0.6711930164888458\n",
      "0.44616878\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:18<00:00,  1.36it/s, Epoch=77, LR=6.89e-6, Train_Loss=0.00188]\n",
      "100%|██████████| 129/129 [00:25<00:00,  5.00it/s, Epoch=77, LR=6.89e-6, Valid_Loss=0.39] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.7302017  3.3886795  7.4713597 ...  4.1964297  4.460696  10.337655 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.514495\n",
      "mean:5.374937\n",
      "0.6673132880698351\n",
      "0.4471387\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:18<00:00,  1.36it/s, Epoch=78, LR=8.15e-6, Train_Loss=0.00181] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.01it/s, Epoch=78, LR=8.15e-6, Valid_Loss=0.391]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.7382293  3.3844748  7.4754844 ...  4.176431   4.433811  10.327348 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.506475\n",
      "mean:5.3449817\n",
      "0.6702230843840931\n",
      "0.4413191\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:18<00:00,  1.36it/s, Epoch=79, LR=9.14e-6, Train_Loss=0.00187] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.03it/s, Epoch=79, LR=9.14e-6, Valid_Loss=0.392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.719325   3.3540347  7.4699554 ...  4.161598   4.451719  10.341015 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.512976\n",
      "mean:5.3393\n",
      "0.6711930164888458\n",
      "0.44616878\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:17<00:00,  1.37it/s, Epoch=80, LR=9.78e-6, Train_Loss=0.00183]\n",
      "100%|██████████| 129/129 [00:25<00:00,  5.01it/s, Epoch=80, LR=9.78e-6, Valid_Loss=0.404]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.6682863  3.3465307  7.387752  ...  4.132871   4.423545  10.25709  ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.389473\n",
      "mean:5.3325634\n",
      "0.6653734238603298\n",
      "0.45198837\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:17<00:00,  1.37it/s, Epoch=81, LR=1e-5, Train_Loss=0.00189] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.01it/s, Epoch=81, LR=1e-5, Valid_Loss=0.397]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.7515745  3.3708234  7.4999995 ...  4.207657   4.4648995 10.354949 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.509066\n",
      "mean:5.368387\n",
      "0.6653734238603298\n",
      "0.45489815\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:19<00:00,  1.36it/s, Epoch=82, LR=9.78e-6, Train_Loss=0.00184] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.01it/s, Epoch=82, LR=9.78e-6, Valid_Loss=0.394]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.707682   3.342194   7.483578  ...  4.1808743  4.4519763 10.305635 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.482786\n",
      "mean:5.3391523\n",
      "0.6750727449078564\n",
      "0.44228905\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:18<00:00,  1.36it/s, Epoch=83, LR=9.14e-6, Train_Loss=0.00186]\n",
      "100%|██████████| 129/129 [00:25<00:00,  5.02it/s, Epoch=83, LR=9.14e-6, Valid_Loss=0.389]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.761592   3.3698761  7.062002  ...  4.1544733  4.5120583 10.34617  ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.578497\n",
      "mean:5.3665338\n",
      "0.6692531522793405\n",
      "0.43646944\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:18<00:00,  1.36it/s, Epoch=84, LR=8.15e-6, Train_Loss=0.00182] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.00it/s, Epoch=84, LR=8.15e-6, Valid_Loss=0.394]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.7330933  3.376659   7.45919   ...  4.180612   4.480153  10.374818 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.56734\n",
      "mean:5.3663993\n",
      "0.6682832201745877\n",
      "0.44907856\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:17<00:00,  1.37it/s, Epoch=85, LR=6.89e-6, Train_Loss=0.00178]\n",
      "100%|██████████| 129/129 [00:25<00:00,  5.01it/s, Epoch=85, LR=6.89e-6, Valid_Loss=0.395]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.78587    3.4030066  7.509531  ...  4.203886   4.4639444 10.325023 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.562676\n",
      "mean:5.373638\n",
      "0.6595538312318138\n",
      "0.45780796\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:18<00:00,  1.36it/s, Epoch=86, LR=5.5e-6, Train_Loss=0.00176] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.01it/s, Epoch=86, LR=5.5e-6, Valid_Loss=0.415]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.7175207  3.3649127  7.4371624 ...  4.141861   4.4022555 10.296034 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.479993\n",
      "mean:5.339906\n",
      "0.6566440349175557\n",
      "0.46362755\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:19<00:00,  1.36it/s, Epoch=87, LR=4.11e-6, Train_Loss=0.00178]\n",
      "100%|██████████| 129/129 [00:25<00:00,  5.01it/s, Epoch=87, LR=4.11e-6, Valid_Loss=0.392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.7485433  3.371875   7.520027  ...  4.194331   4.481421  10.341824 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.558741\n",
      "mean:5.359517\n",
      "0.6750727449078564\n",
      "0.44228905\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:19<00:00,  1.36it/s, Epoch=88, LR=2.85e-6, Train_Loss=0.00176]\n",
      "100%|██████████| 129/129 [00:25<00:00,  5.01it/s, Epoch=88, LR=2.85e-6, Valid_Loss=0.393]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.7003107  3.3964658  7.40212   ...  4.200397   4.4486036 10.334604 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.548614\n",
      "mean:5.3432136\n",
      "0.6721629485935985\n",
      "0.44228905\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:17<00:00,  1.37it/s, Epoch=89, LR=1.86e-6, Train_Loss=0.00178] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.01it/s, Epoch=89, LR=1.86e-6, Valid_Loss=0.393]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.7273164  3.3821764  7.484692  ...  4.1656327  4.4454827 10.34231  ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.576815\n",
      "mean:5.34392\n",
      "0.6673132880698351\n",
      "0.4471387\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:19<00:00,  1.36it/s, Epoch=90, LR=1.22e-6, Train_Loss=0.00176]\n",
      "100%|██████████| 129/129 [00:25<00:00,  5.02it/s, Epoch=90, LR=1.22e-6, Valid_Loss=0.398]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.765953  3.373609  7.464744 ...  4.199561  4.482427 10.34261 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.515152\n",
      "mean:5.3521914\n",
      "0.6634335596508244\n",
      "0.45101842\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:18<00:00,  1.36it/s, Epoch=91, LR=1e-6, Train_Loss=0.0017]  \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.01it/s, Epoch=91, LR=1e-6, Valid_Loss=0.395]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.7122974  3.3766909  7.442909  ...  4.181394   4.438657  10.296327 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.47899\n",
      "mean:5.334331\n",
      "0.6682832201745877\n",
      "0.44907856\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:19<00:00,  1.36it/s, Epoch=92, LR=1.22e-6, Train_Loss=0.00168] \n",
      "100%|██████████| 129/129 [00:25<00:00,  4.99it/s, Epoch=92, LR=1.22e-6, Valid_Loss=0.394]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.7240815  3.3882973  7.48689   ...  4.188144   4.4385943 10.295675 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.540273\n",
      "mean:5.343056\n",
      "0.6702230843840931\n",
      "0.44422892\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:19<00:00,  1.36it/s, Epoch=93, LR=1.86e-6, Train_Loss=0.0017]  \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.01it/s, Epoch=93, LR=1.86e-6, Valid_Loss=0.393]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.7459764  3.39586    7.505362  ...  4.162176   4.4388695 10.287685 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.561586\n",
      "mean:5.352092\n",
      "0.6682832201745877\n",
      "0.44907856\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:19<00:00,  1.36it/s, Epoch=94, LR=2.85e-6, Train_Loss=0.00172] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.01it/s, Epoch=94, LR=2.85e-6, Valid_Loss=0.394]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.77159    3.3974996  7.507173  ...  4.2034993  4.489607  10.300563 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.548197\n",
      "mean:5.3625555\n",
      "0.6663433559650824\n",
      "0.45101842\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:19<00:00,  1.36it/s, Epoch=95, LR=4.11e-6, Train_Loss=0.0019]  \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.01it/s, Epoch=95, LR=4.11e-6, Valid_Loss=0.397]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.701624   3.3657546  7.470765  ...  4.181021   4.437619  10.301575 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.548764\n",
      "mean:5.3422956\n",
      "0.6653734238603298\n",
      "0.45198837\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:19<00:00,  1.36it/s, Epoch=96, LR=5.5e-6, Train_Loss=0.00179]\n",
      "100%|██████████| 129/129 [00:25<00:00,  5.00it/s, Epoch=96, LR=5.5e-6, Valid_Loss=0.396]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.721244   3.3860102  7.430711  ...  4.200799   4.452023  10.255366 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.527893\n",
      "mean:5.339107\n",
      "0.6702230843840931\n",
      "0.44422892\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:19<00:00,  1.36it/s, Epoch=97, LR=6.89e-6, Train_Loss=0.00168]\n",
      "100%|██████████| 129/129 [00:25<00:00,  5.01it/s, Epoch=97, LR=6.89e-6, Valid_Loss=0.394]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.758894   3.389884   7.4734507 ...  4.1921453  4.4448833 10.290494 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.554975\n",
      "mean:5.3517275\n",
      "0.6692531522793405\n",
      "0.45101842\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:18<00:00,  1.36it/s, Epoch=98, LR=8.15e-6, Train_Loss=0.00169] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.02it/s, Epoch=98, LR=8.15e-6, Valid_Loss=0.399]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.7418547  3.414899   7.462504  ...  4.2192793  4.456502  10.260063 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.515228\n",
      "mean:5.360142\n",
      "0.6653734238603298\n",
      "0.45198837\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:19<00:00,  1.36it/s, Epoch=99, LR=9.14e-6, Train_Loss=0.00173] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.01it/s, Epoch=99, LR=9.14e-6, Valid_Loss=0.399]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.79928    3.3664176  7.4383245 ...  4.193878   4.4837666 10.354964 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.602887\n",
      "mean:5.359428\n",
      "0.6644034917555771\n",
      "0.4529583\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:19<00:00,  1.36it/s, Epoch=100, LR=9.78e-6, Train_Loss=0.00179] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.01it/s, Epoch=100, LR=9.78e-6, Valid_Loss=0.4]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.73662    3.3609703  7.40722   ...  4.167415   4.4075117 10.295842 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.546927\n",
      "mean:5.310137\n",
      "0.6711930164888458\n",
      "0.44907856\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:19<00:00,  1.36it/s, Epoch=101, LR=1e-5, Train_Loss=0.00177] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.00it/s, Epoch=101, LR=1e-5, Valid_Loss=0.393]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.8121967  3.375361   7.505739  ...  4.2170286  4.5180025 10.365891 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.581574\n",
      "mean:5.3756924\n",
      "0.6673132880698351\n",
      "0.4471387\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:19<00:00,  1.36it/s, Epoch=102, LR=9.78e-6, Train_Loss=0.00176]\n",
      "100%|██████████| 129/129 [00:25<00:00,  5.01it/s, Epoch=102, LR=9.78e-6, Valid_Loss=0.404]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.758847   3.3695915  7.461147  ...  4.208966   4.491046  10.262712 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.459235\n",
      "mean:5.3309965\n",
      "0.6634335596508244\n",
      "0.456838\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:18<00:00,  1.36it/s, Epoch=103, LR=9.14e-6, Train_Loss=0.00177] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.01it/s, Epoch=103, LR=9.14e-6, Valid_Loss=0.395]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.7335806  3.3463633  7.473483  ...  4.1577034  4.4511566 10.297673 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.464721\n",
      "mean:5.3381286\n",
      "0.6702230843840931\n",
      "0.4471387\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:20<00:00,  1.36it/s, Epoch=104, LR=8.15e-6, Train_Loss=0.00175] \n",
      "100%|██████████| 129/129 [00:26<00:00,  4.94it/s, Epoch=104, LR=8.15e-6, Valid_Loss=0.394]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.7938704  3.3778503  7.4980392 ...  4.1785197  4.4756694 10.282467 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.527103\n",
      "mean:5.3527217\n",
      "0.6673132880698351\n",
      "0.4471387\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:19<00:00,  1.36it/s, Epoch=105, LR=6.89e-6, Train_Loss=0.00174] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.00it/s, Epoch=105, LR=6.89e-6, Valid_Loss=0.392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.815102   3.4089382  7.5225363 ...  4.2137384  4.490324  10.309243 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.550427\n",
      "mean:5.3651257\n",
      "0.6682832201745877\n",
      "0.45198837\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:19<00:00,  1.36it/s, Epoch=106, LR=5.5e-6, Train_Loss=0.00166] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.01it/s, Epoch=106, LR=5.5e-6, Valid_Loss=0.396]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.7494774  3.3570156  7.525851  ...  4.165427   4.45801   10.286763 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.525531\n",
      "mean:5.348626\n",
      "0.6711930164888458\n",
      "0.44907856\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:18<00:00,  1.36it/s, Epoch=107, LR=4.11e-6, Train_Loss=0.00171] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.01it/s, Epoch=107, LR=4.11e-6, Valid_Loss=0.394]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.7035937  3.361259   7.5158277 ...  4.1975703  4.474194  10.263917 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.530302\n",
      "mean:5.335482\n",
      "0.6741028128031038\n",
      "0.44616878\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:19<00:00,  1.36it/s, Epoch=108, LR=2.85e-6, Train_Loss=0.00169]\n",
      "100%|██████████| 129/129 [00:25<00:00,  5.01it/s, Epoch=108, LR=2.85e-6, Valid_Loss=0.393]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.8204722  3.3835933  7.5059366 ...  4.2253256  4.5010724 10.317126 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.568311\n",
      "mean:5.3462687\n",
      "0.6711930164888458\n",
      "0.44907856\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:18<00:00,  1.36it/s, Epoch=109, LR=1.86e-6, Train_Loss=0.00166] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.01it/s, Epoch=109, LR=1.86e-6, Valid_Loss=0.393]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.7546844  3.3710897  7.4285727 ...  4.2025137  4.4997315 10.293301 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.562598\n",
      "mean:5.3477616\n",
      "0.6721629485935985\n",
      "0.44228905\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:17<00:00,  1.37it/s, Epoch=110, LR=1.22e-6, Train_Loss=0.0017] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.03it/s, Epoch=110, LR=1.22e-6, Valid_Loss=0.398]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.736419   3.356133   7.4786315 ...  4.1764827  4.443129  10.299344 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.513697\n",
      "mean:5.3367662\n",
      "0.6711930164888458\n",
      "0.44616878\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:18<00:00,  1.36it/s, Epoch=111, LR=1e-6, Train_Loss=0.00169] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.00it/s, Epoch=111, LR=1e-6, Valid_Loss=0.397]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.816326   3.396897   7.520724  ...  4.234851   4.4985313 10.309933 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.570331\n",
      "mean:5.3761005\n",
      "0.6682832201745877\n",
      "0.44616878\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:19<00:00,  1.36it/s, Epoch=112, LR=1.22e-6, Train_Loss=0.00168] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.01it/s, Epoch=112, LR=1.22e-6, Valid_Loss=0.397]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.741452   3.3170562  7.4930067 ...  4.1667104  4.4492445 10.308132 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.439178\n",
      "mean:5.325489\n",
      "0.6721629485935985\n",
      "0.44519883\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:20<00:00,  1.36it/s, Epoch=113, LR=1.86e-6, Train_Loss=0.00166] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.02it/s, Epoch=113, LR=1.86e-6, Valid_Loss=0.394]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.7667565  3.3646817  7.5203953 ...  4.2093787  4.4938974 10.310209 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.577892\n",
      "mean:5.3578625\n",
      "0.6702230843840931\n",
      "0.4471387\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:17<00:00,  1.37it/s, Epoch=114, LR=2.85e-6, Train_Loss=0.00164] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.02it/s, Epoch=114, LR=2.85e-6, Valid_Loss=0.394]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.7934737  3.3702533  7.5009336 ...  4.2230353  4.4913    10.304242 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.520819\n",
      "mean:5.350087\n",
      "0.6711930164888458\n",
      "0.44907856\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:18<00:00,  1.36it/s, Epoch=115, LR=4.11e-6, Train_Loss=0.00168]\n",
      "100%|██████████| 129/129 [00:25<00:00,  5.01it/s, Epoch=115, LR=4.11e-6, Valid_Loss=0.403]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.7965007  3.3940904  7.4783845 ...  4.2272     4.4693923 10.294577 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.5378275\n",
      "mean:5.3504124\n",
      "0.6624636275460718\n",
      "0.45489815\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:17<00:00,  1.37it/s, Epoch=116, LR=5.5e-6, Train_Loss=0.00166] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.01it/s, Epoch=116, LR=5.5e-6, Valid_Loss=0.394]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.795728   3.4010875  7.517422  ...  4.2218213  4.4888744 10.2916355]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.571533\n",
      "mean:5.3538995\n",
      "0.6673132880698351\n",
      "0.4529583\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:19<00:00,  1.36it/s, Epoch=117, LR=6.89e-6, Train_Loss=0.00169] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.01it/s, Epoch=117, LR=6.89e-6, Valid_Loss=0.395]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.8053694  3.381274   7.5741324 ...  4.2261558  4.4987655 10.31071  ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.620248\n",
      "mean:5.352856\n",
      "0.6770126091173618\n",
      "0.44907856\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:18<00:00,  1.36it/s, Epoch=118, LR=8.15e-6, Train_Loss=0.00171] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.02it/s, Epoch=118, LR=8.15e-6, Valid_Loss=0.392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.8473635  3.38516    7.5645423 ...  4.2613525  4.5367928 10.388819 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.653761\n",
      "mean:5.3734674\n",
      "0.6702230843840931\n",
      "0.4471387\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:19<00:00,  1.36it/s, Epoch=119, LR=9.14e-6, Train_Loss=0.00172] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.02it/s, Epoch=119, LR=9.14e-6, Valid_Loss=0.396]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.808983   3.3563497  7.520095  ...  4.219319   4.509498  10.295339 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.551925\n",
      "mean:5.3576913\n",
      "0.6702230843840931\n",
      "0.4471387\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:18<00:00,  1.36it/s, Epoch=120, LR=9.78e-6, Train_Loss=0.00168] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.00it/s, Epoch=120, LR=9.78e-6, Valid_Loss=0.394]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.841507   3.4003134  7.4911394 ...  4.2345624  4.511062  10.287381 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.640089\n",
      "mean:5.3647494\n",
      "0.6702230843840931\n",
      "0.44422892\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:20<00:00,  1.36it/s, Epoch=121, LR=1e-5, Train_Loss=0.0017]  \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.00it/s, Epoch=121, LR=1e-5, Valid_Loss=0.395]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.7639127  3.3887763  7.4963527 ...  4.2377887  4.508834  10.303305 ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.579566\n",
      "mean:5.352259\n",
      "0.6731328806983511\n",
      "0.43549952\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [06:19<00:00,  1.36it/s, Epoch=122, LR=9.78e-6, Train_Loss=0.00169] \n",
      "100%|██████████| 129/129 [00:25<00:00,  5.01it/s, Epoch=122, LR=9.78e-6, Valid_Loss=0.394]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[ 5.7725534  3.3718383  7.514279  ...  4.234131   4.4983063 10.30264  ]\n",
      "target:[ 5.  4.  6. ...  4.  5. 12.]\n",
      "max:12.530774\n",
      "mean:5.3484263\n",
      "0.6731328806983511\n",
      "0.44422892\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 135/516 [01:39<04:33,  1.39it/s, Epoch=123, LR=9.14e-6, Train_Loss=0.00526] "
     ]
    }
   ],
   "source": [
    "def fetch_scheduler(optimizer):\n",
    "    if CONFIG.scheduler == 'CosineAnnealingLR':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=CONFIG.T_max, eta_min=CONFIG.min_lr)\n",
    "    elif CONFIG.scheduler == 'CosineAnnealingWarmRestarts':\n",
    "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=CONFIG.T_0, T_mult=1, eta_min=CONFIG.min_lr)\n",
    "    elif CONFIG.scheduler == None:\n",
    "        return None\n",
    "        \n",
    "    return scheduler\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=CONFIG.learning_rate, weight_decay=CONFIG.weight_decay)\n",
    "scheduler = fetch_scheduler(optimizer)\n",
    "\n",
    "print(CONFIG.device)\n",
    "print(CONFIG.epochs)\n",
    "model, history = run(model, optimizer, scheduler=scheduler, device=CONFIG.device, num_epochs=250) #CONFIG.epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
